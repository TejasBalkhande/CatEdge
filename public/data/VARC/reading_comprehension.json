[
  {
    "id": 1,
    "passage": " Zuckerberg’s efforts began with a 2019 op-ed in the Washington Post, ‘The Internet needs new rules’. The article proposed four specific actions, including things that Facebook was already doing. A few months later, Facebook released a white paper reiterating the ideas. When it was presented to the European Union, the official responsible described it as ‘too low in terms of responsibility’. It is this same set of proposals that are the basis for Facebook’s multimillion-dollar television, print, and digital advertising campaign proclaiming, ‘We support updated internet regulations’. Affirming the need for oversight of digital platforms is a positive step and should be applauded. But for the last 20 years, tech companies such as Facebook have fought government oversight, warning that regulation would break the magic of digital technology and the wonders of ‘permissionless innovation’. Now, however, like other nations, and even states within the U.S., have made differing efforts to mitigate the harms delivered by Big Tech, a common set of national rules no longer seems so onerous. A tried-and-true lobbying strategy is to loudly proclaim support for lofty principles while quietly working to hollow out the implementation of such principles. The key is to move beyond embracing generic concepts to deal with regulatory specifics. The headline on Politico’s report of the March 25 House of Representatives hearing, ‘D.C.’s Silicon Valley crackdown enters the haggling phase’, suggests that such an effort has begun. Being an optimist, I want to take Facebook at its word that it supports updated internet regulations. Being a pragmatist and former regulator, though, I believe we need to know exactly what such regulations would provide. At the March hearing, Zuckerberg was asked by Vermont Rep. Peter Welch, a Democrat,  if he would support creating a new federal agency to regulate digital platforms. The reply was encouraging: ‘The solution that you’re talking about could be very effective and positive for helping out’. Such an agency has been proposed by a group of former regulators of which I am part. If the haggling has begun, it is worthwhile to identify some of the items worth haggling over. First off is the new agency itself. The preponderance of proposals in Congress is to give increased authority to the Federal Trade Commission (FTC). The FTC, its commissioners and staff are dedicated public servants, but the agency is already overburdened with an immense jurisdiction. There is a history of companies seeking to transfer oversight to the FTC in an effort to get its issues lost amid other the issues of other companies. Oversight of digital platforms should not be a bolt-on to an existing agency but requires full-time specialised focus. The European Union has proposed a new regime to regulate platforms that have ‘gatekeeper’ power. The United Kingdom has similarly proposed new oversight for platforms with ‘significant market share.’ The United States, too, needs a focused and specialised government oversight to protect consumers and competition. Digital companies complain (not without some merit) that current regulation with its rigid rules is incompatible with rapid technology developments. To build agile policies capable of evolving with technology, the new agency should take a page from the process used in developing the technology standards that created the digital revolution. In that effort, the companies came together to agree on exactly how things would work. This time, instead of technical standards, there would be behavioural standards. The subject matter of these new standards should be identified by the agency, which would convene industry and public stakeholders to propose a code, much like electric codes and fire codes. Ultimately, the Reading Comprehension – Basic Levelagency would approve or modify the code and enforce it. While there is no doubt that such a new approach is ambitious, the new challenges of the digital giants require new tools.",
    "ImageID": "",
    "question": "The author of this article seems to be arguing from the point of view of:",
    "options": {
      "a": "Digital platforms",
      "b": "Regulating agencies",
      "c": "Mark Zuckerberg",
      "d": "General public"
    },
    "answer": "b",
    "explanation": "‘Being a pragmatist and former regulator, though, I believe…’ this phrase from the third para indicates that the author represents regulating authorities’ point of view here. Also, here and there, he has suggested what companies should do and what agencies should do, so it is evident that he is speaking for a better set of laws.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 2,
    "passage": " Zuckerberg’s efforts began with a 2019 op-ed in the Washington Post, ‘The Internet needs new rules’. The article proposed four specific actions, including things that Facebook was already doing. A few months later, Facebook released a white paper reiterating the ideas. When it was presented to the European Union, the official responsible described it as ‘too low in terms of responsibility’. It is this same set of proposals that are the basis for Facebook’s multimillion-dollar television, print, and digital advertising campaign proclaiming, ‘We support updated internet regulations’. Affirming the need for oversight of digital platforms is a positive step and should be applauded. But for the last 20 years, tech companies such as Facebook have fought government oversight, warning that regulation would break the magic of digital technology and the wonders of ‘permissionless innovation’. Now, however, like other nations, and even states within the U.S., have made differing efforts to mitigate the harms delivered by Big Tech, a common set of national rules no longer seems so onerous. A tried-and-true lobbying strategy is to loudly proclaim support for lofty principles while quietly working to hollow out the implementation of such principles. The key is to move beyond embracing generic concepts to deal with regulatory specifics. The headline on Politico’s report of the March 25 House of Representatives hearing, ‘D.C.’s Silicon Valley crackdown enters the haggling phase’, suggests that such an effort has begun. Being an optimist, I want to take Facebook at its word that it supports updated internet regulations. Being a pragmatist and former regulator, though, I believe we need to know exactly what such regulations would provide. At the March hearing, Zuckerberg was asked by Vermont Rep. Peter Welch, a Democrat,  if he would support creating a new federal agency to regulate digital platforms. The reply was encouraging: ‘The solution that you’re talking about could be very effective and positive for helping out’. Such an agency has been proposed by a group of former regulators of which I am part. If the haggling has begun, it is worthwhile to identify some of the items worth haggling over. First off is the new agency itself. The preponderance of proposals in Congress is to give increased authority to the Federal Trade Commission (FTC). The FTC, its commissioners and staff are dedicated public servants, but the agency is already overburdened with an immense jurisdiction. There is a history of companies seeking to transfer oversight to the FTC in an effort to get its issues lost amid other the issues of other companies. Oversight of digital platforms should not be a bolt-on to an existing agency but requires full-time specialised focus. The European Union has proposed a new regime to regulate platforms that have ‘gatekeeper’ power. The United Kingdom has similarly proposed new oversight for platforms with ‘significant market share.’ The United States, too, needs a focused and specialised government oversight to protect consumers and competition. Digital companies complain (not without some merit) that current regulation with its rigid rules is incompatible with rapid technology developments. To build agile policies capable of evolving with technology, the new agency should take a page from the process used in developing the technology standards that created the digital revolution. In that effort, the companies came together to agree on exactly how things would work. This time, instead of technical standards, there would be behavioural standards. The subject matter of these new standards should be identified by the agency, which would convene industry and public stakeholders to propose a code, much like electric codes and fire codes. Ultimately, the Reading Comprehension – Basic Levelagency would approve or modify the code and enforce it. While there is no doubt that such a new approach is ambitious, the new challenges of the digital giants require new tools.",
    "ImageID": "",
    "question": "Mark Zuckerberg is most likely to support:",
    "options": {
      "a": "A lenient set of regulations.",
      "b": "A stringent set of rules.",
      "c": "An agile and compatible set of regulations.",
      "d": "The existing set of regulations."
    },
    "answer": "c",
    "explanation": "Options B and D are clearly out of the question, as evident after reading the first paragraph only. And though Zuckerberg would like the regulations to be lenient, option A is slightly negative in the given context. So, option C is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 3,
    "passage": " Zuckerberg’s efforts began with a 2019 op-ed in the Washington Post, ‘The Internet needs new rules’. The article proposed four specific actions, including things that Facebook was already doing. A few months later, Facebook released a white paper reiterating the ideas. When it was presented to the European Union, the official responsible described it as ‘too low in terms of responsibility’. It is this same set of proposals that are the basis for Facebook’s multimillion-dollar television, print, and digital advertising campaign proclaiming, ‘We support updated internet regulations’. Affirming the need for oversight of digital platforms is a positive step and should be applauded. But for the last 20 years, tech companies such as Facebook have fought government oversight, warning that regulation would break the magic of digital technology and the wonders of ‘permissionless innovation’. Now, however, like other nations, and even states within the U.S., have made differing efforts to mitigate the harms delivered by Big Tech, a common set of national rules no longer seems so onerous. A tried-and-true lobbying strategy is to loudly proclaim support for lofty principles while quietly working to hollow out the implementation of such principles. The key is to move beyond embracing generic concepts to deal with regulatory specifics. The headline on Politico’s report of the March 25 House of Representatives hearing, ‘D.C.’s Silicon Valley crackdown enters the haggling phase’, suggests that such an effort has begun. Being an optimist, I want to take Facebook at its word that it supports updated internet regulations. Being a pragmatist and former regulator, though, I believe we need to know exactly what such regulations would provide. At the March hearing, Zuckerberg was asked by Vermont Rep. Peter Welch, a Democrat,  if he would support creating a new federal agency to regulate digital platforms. The reply was encouraging: ‘The solution that you’re talking about could be very effective and positive for helping out’. Such an agency has been proposed by a group of former regulators of which I am part. If the haggling has begun, it is worthwhile to identify some of the items worth haggling over. First off is the new agency itself. The preponderance of proposals in Congress is to give increased authority to the Federal Trade Commission (FTC). The FTC, its commissioners and staff are dedicated public servants, but the agency is already overburdened with an immense jurisdiction. There is a history of companies seeking to transfer oversight to the FTC in an effort to get its issues lost amid other the issues of other companies. Oversight of digital platforms should not be a bolt-on to an existing agency but requires full-time specialised focus. The European Union has proposed a new regime to regulate platforms that have ‘gatekeeper’ power. The United Kingdom has similarly proposed new oversight for platforms with ‘significant market share.’ The United States, too, needs a focused and specialised government oversight to protect consumers and competition. Digital companies complain (not without some merit) that current regulation with its rigid rules is incompatible with rapid technology developments. To build agile policies capable of evolving with technology, the new agency should take a page from the process used in developing the technology standards that created the digital revolution. In that effort, the companies came together to agree on exactly how things would work. This time, instead of technical standards, there would be behavioural standards. The subject matter of these new standards should be identified by the agency, which would convene industry and public stakeholders to propose a code, much like electric codes and fire codes. Ultimately, the Reading Comprehension – Basic Levelagency would approve or modify the code and enforce it. While there is no doubt that such a new approach is ambitious, the new challenges of the digital giants require new tools.",
    "ImageID": "",
    "question": "The quote ‘D.C.’s Silicon Valley crack down enters the haggling phase’ is likely about:",
    "options": {
      "a": "Mark Zuckerberg’s efforts to convince the regulatory body for a favourable set of rules.",
      "b": "The actions of digital giants to get a clear set of rules from the regulatory agencies.",
      "c": "Regulating agencies’ efforts to set stringent rules to protect consum ers’ rights.",
      "d": "The talks between government in stitutions and digital platform companies."
    },
    "answer": "b",
    "explanation": "A careful reading of the third paragraph suggests that the given headline talks about the efforts made by tech and digital companies to influence the decisions of the regulating agencies. So, option B is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 4,
    "passage": " Zuckerberg’s efforts began with a 2019 op-ed in the Washington Post, ‘The Internet needs new rules’. The article proposed four specific actions, including things that Facebook was already doing. A few months later, Facebook released a white paper reiterating the ideas. When it was presented to the European Union, the official responsible described it as ‘too low in terms of responsibility’. It is this same set of proposals that are the basis for Facebook’s multimillion-dollar television, print, and digital advertising campaign proclaiming, ‘We support updated internet regulations’. Affirming the need for oversight of digital platforms is a positive step and should be applauded. But for the last 20 years, tech companies such as Facebook have fought government oversight, warning that regulation would break the magic of digital technology and the wonders of ‘permissionless innovation’. Now, however, like other nations, and even states within the U.S., have made differing efforts to mitigate the harms delivered by Big Tech, a common set of national rules no longer seems so onerous. A tried-and-true lobbying strategy is to loudly proclaim support for lofty principles while quietly working to hollow out the implementation of such principles. The key is to move beyond embracing generic concepts to deal with regulatory specifics. The headline on Politico’s report of the March 25 House of Representatives hearing, ‘D.C.’s Silicon Valley crackdown enters the haggling phase’, suggests that such an effort has begun. Being an optimist, I want to take Facebook at its word that it supports updated internet regulations. Being a pragmatist and former regulator, though, I believe we need to know exactly what such regulations would provide. At the March hearing, Zuckerberg was asked by Vermont Rep. Peter Welch, a Democrat,  if he would support creating a new federal agency to regulate digital platforms. The reply was encouraging: ‘The solution that you’re talking about could be very effective and positive for helping out’. Such an agency has been proposed by a group of former regulators of which I am part. If the haggling has begun, it is worthwhile to identify some of the items worth haggling over. First off is the new agency itself. The preponderance of proposals in Congress is to give increased authority to the Federal Trade Commission (FTC). The FTC, its commissioners and staff are dedicated public servants, but the agency is already overburdened with an immense jurisdiction. There is a history of companies seeking to transfer oversight to the FTC in an effort to get its issues lost amid other the issues of other companies. Oversight of digital platforms should not be a bolt-on to an existing agency but requires full-time specialised focus. The European Union has proposed a new regime to regulate platforms that have ‘gatekeeper’ power. The United Kingdom has similarly proposed new oversight for platforms with ‘significant market share.’ The United States, too, needs a focused and specialised government oversight to protect consumers and competition. Digital companies complain (not without some merit) that current regulation with its rigid rules is incompatible with rapid technology developments. To build agile policies capable of evolving with technology, the new agency should take a page from the process used in developing the technology standards that created the digital revolution. In that effort, the companies came together to agree on exactly how things would work. This time, instead of technical standards, there would be behavioural standards. The subject matter of these new standards should be identified by the agency, which would convene industry and public stakeholders to propose a code, much like electric codes and fire codes. Ultimately, the Reading Comprehension – Basic Levelagency would approve or modify the code and enforce it. While there is no doubt that such a new approach is ambitious, the new challenges of the digital giants require new tools.",
    "ImageID": "",
    "question": "The term ‘oversight’, as used in the pas sage, refers to:",
    "options": {
      "a": "The negligence on the part of the regulating agencies.",
      "b": "The ignorance of rules by digital companies.",
      "c": "Review, monitoring, and supervision of digital companies.",
      "d": "Review, monitoring, and supervi sion of regulating agencies by other agencies."
    },
    "answer": "c",
    "explanation": "One doesn’t need to have a very sound understanding of the U.S. congressional system to understand that the term ‘oversight’ has not been used in its literal sense here. Rather, it has got a deeper meaning. And that meaning corresponds to the definition given in option C.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 5,
    "passage": " Zuckerberg’s efforts began with a 2019 op-ed in the Washington Post, ‘The Internet needs new rules’. The article proposed four specific actions, including things that Facebook was already doing. A few months later, Facebook released a white paper reiterating the ideas. When it was presented to the European Union, the official responsible described it as ‘too low in terms of responsibility’. It is this same set of proposals that are the basis for Facebook’s multimillion-dollar television, print, and digital advertising campaign proclaiming, ‘We support updated internet regulations’. Affirming the need for oversight of digital platforms is a positive step and should be applauded. But for the last 20 years, tech companies such as Facebook have fought government oversight, warning that regulation would break the magic of digital technology and the wonders of ‘permissionless innovation’. Now, however, like other nations, and even states within the U.S., have made differing efforts to mitigate the harms delivered by Big Tech, a common set of national rules no longer seems so onerous. A tried-and-true lobbying strategy is to loudly proclaim support for lofty principles while quietly working to hollow out the implementation of such principles. The key is to move beyond embracing generic concepts to deal with regulatory specifics. The headline on Politico’s report of the March 25 House of Representatives hearing, ‘D.C.’s Silicon Valley crackdown enters the haggling phase’, suggests that such an effort has begun. Being an optimist, I want to take Facebook at its word that it supports updated internet regulations. Being a pragmatist and former regulator, though, I believe we need to know exactly what such regulations would provide. At the March hearing, Zuckerberg was asked by Vermont Rep. Peter Welch, a Democrat,  if he would support creating a new federal agency to regulate digital platforms. The reply was encouraging: ‘The solution that you’re talking about could be very effective and positive for helping out’. Such an agency has been proposed by a group of former regulators of which I am part. If the haggling has begun, it is worthwhile to identify some of the items worth haggling over. First off is the new agency itself. The preponderance of proposals in Congress is to give increased authority to the Federal Trade Commission (FTC). The FTC, its commissioners and staff are dedicated public servants, but the agency is already overburdened with an immense jurisdiction. There is a history of companies seeking to transfer oversight to the FTC in an effort to get its issues lost amid other the issues of other companies. Oversight of digital platforms should not be a bolt-on to an existing agency but requires full-time specialised focus. The European Union has proposed a new regime to regulate platforms that have ‘gatekeeper’ power. The United Kingdom has similarly proposed new oversight for platforms with ‘significant market share.’ The United States, too, needs a focused and specialised government oversight to protect consumers and competition. Digital companies complain (not without some merit) that current regulation with its rigid rules is incompatible with rapid technology developments. To build agile policies capable of evolving with technology, the new agency should take a page from the process used in developing the technology standards that created the digital revolution. In that effort, the companies came together to agree on exactly how things would work. This time, instead of technical standards, there would be behavioural standards. The subject matter of these new standards should be identified by the agency, which would convene industry and public stakeholders to propose a code, much like electric codes and fire codes. Ultimately, the Reading Comprehension – Basic Levelagency would approve or modify the code and enforce it. While there is no doubt that such a new approach is ambitious, the new challenges of the digital giants require new tools.",
    "ImageID": "",
    "question": "The author is most likely to suggest that:",
    "options": {
      "a": "Regulating agencies should take the consumers and digital companies into confidence before drafting reg ulations regarding the functioning of digital platforms.",
      "b": "A new agency should be formed to make rules on the functioning of dig ital platforms.",
      "c": "Consumers’ interests should be a top priority while framing the rules for the functioning of digital platforms.",
      "d": "A new regime to regulate platforms with ‘gatekeeper’ power and new oversight for platforms with ‘signifi cant market share’ should be formed."
    },
    "answer": "a",
    "explanation": "This is an inferential question. One needs to understand the tone and flow of the passage. Option D is the proposal made by the European Union and the United States, which the author would most likely agree with. But it is not the suggestion that the author would give. Option B, again, is the suggestion given by the existing agencies and not the author’s suggestion. Option C ignores the interests of the digital companies, and hence the author would not make any such suggestions. The correct answer is option A.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 6,
    "passage": " When I visited my grandmother at the undertakers, an hour or so before her funeral, I was struck by how different death is from sleep. A sleeping individual shimmers with fractional movements. The dead seem to rest in paused animation, so still, they look smaller than in life. It’s almost impossible not to feel as if something very like the soul is no longer present. Yet my grandmother had also died of Alzheimer’s. Even in life, something of who she was had begun to abandon her. And I wondered, as her memories vanished, had she become a little less herself, a little less human? These end-of-life stages prick our imaginations. They confront us with some unsettling ideas. We don’t like to face the possibility that irreversible biological processes in our bodies can snuff out the stunning light of our individual experiences. We prefer to deny our bodies altogether and push away the dark tendrils of a living world we fear. The trouble for us is that this story—that we aren’t really our bodies but some special, separate ‘thing’—has made a muddle of reality. Problems flow from the notion that we’re split between a superior human half and the inferior, mortal body of an animal. In short, we’ve come to believe that our bodies and their feelings are a lesser kind of existence. But what if we’re wrong? What if all parts of us, including our minds, are deeply biological, and our physical experiences are far more meaningful and richer than we’ve been willing to accept? As far as we know, early hunter-gatherer animist societies saw spirit everywhere. All life possessed a special, non-physical essence. In European classical thought, many also believed that every living thing had a soul. But souls were graded. Humans were thought to have a superior soul within a hierarchy. By the time of theologians such as the Italian Dominican friar and philosopher Thomas Aquinas, in the 13th century, this soulful view of life had retreated, leaving humans the only creature still in possession of an immortal one. As beings with unique souls, we were more than mere animals. Our lives were set on a path to salvation. Life was now a great chain of being, with only the angels and God above us. But, as the Middle Ages came to a close in the 16th century, a fresh, apparently rational form of exceptionalism began to spread. The origins of this shift lie in the thinking of René Descartes, who gave the world a new version of dualism. Descartes argued that thought is so different from the physical, machine-like substance of the body that we should see humans as having two parts: the thoughtful mind and the thoughtless, physical body. This was religion refocused through a rational lens. The division between humans and the rest of nature was no longer the soul— or, at least, not only the soul—but rather our intellectual capabilities: our reason, our moral sensibilities, our gifts for abstraction. He assumed, of course, that other animals don’t think. Enlightenment figures such as John Locke and Immanuel Kant in the 17th and 18th centuries developed this further. According to them, it was the fruits of our intelligence that made us truly human. Through mental powers, humans live a more meaningful life than other beings. In other words, we humans have a soulful mind. It was even suggested that we are our thoughts and that these phantasmal mental aspects of humans are more important and even, daringly, separable from the impoverished biology that we share with other animals. In many ways, Darwinism posed a threat to this intensifying vision of the human and our place in nature. Charles Darwin disrupted both the idea of a neat divide between humans and other forms of life and also complicated the possibilities for mindbody dualism. If humans had evolved from earlier ancestral primates, then our minds, Reading Comprehension – Basic Leveltoo, must have emerged through ordinary, evolutionary processes with deep roots in nature. It’s easy to forget today just how shattering Darwinism was for a whole generation. Darwin himself wrote to his friend, the American botanist Asa Gray, to express his acute fear of seeing humans as a fully integrated part of a seemingly amoral natural world, where there’s ‘too much misery’. Perhaps we shouldn’t be surprised, then, to find the redoubling of efforts to assert new forms of human redemption in the years after the publication of On the Origin of Species (1859). One such effort came in the form of the ‘human revolution’—the idea that some kind of cognitive leap took place in the recent evolution of Homo sapiens that forever split us from other species. Another was in the 20th-century reworking of Enlightenment humanism that sought to find scientific proof of human exception and to argue that only these ultimately matter. Modern humanism promised to be about the complete realisation of human personality in an onward march to move farther into space and perhaps inhabit other planets. The history of a global philosophy on humans and other animals might be mischievously summarised as a long study in mental bias.",
    "ImageID": "",
    "question": "What is the theme of the passage?",
    "options": {
      "a": "The dualism of mind and body.",
      "b": "The divide between humans and oth er forms of life.",
      "c": "Altering perception of mind-body dualism through centuries.",
      "d": "The dualism of mind and body and the divide between humans and oth er forms of life."
    },
    "answer": "d",
    "explanation": "Throughout the passage, the author has parallelly discussed the dualism of mind and body and human beings’ effort prov ing their superiority over other life forms. So, option D is the correct theme.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 7,
    "passage": "  When I visited my grandmother at the undertakers, an hour or so before her funeral, I was struck by how different death is from sleep. A sleeping individual shimmers with fractional movements. The dead seem to rest in paused animation, so still, they look smaller than in life. It’s almost impossible not to feel as if something very like the soul is no longer present. Yet my grandmother had also died of Alzheimer’s. Even in life, something of who she was had begun to abandon her. And I wondered, as her memories vanished, had she become a little less herself, a little less human? These end-of-life stages prick our imaginations. They confront us with some unsettling ideas. We don’t like to face the possibility that irreversible biological processes in our bodies can snuff out the stunning light of our individual experiences. We prefer to deny our bodies altogether and push away the dark tendrils of a living world we fear. The trouble for us is that this story—that we aren’t really our bodies but some special, separate ‘thing’—has made a muddle of reality. Problems flow from the notion that we’re split between a superior human half and the inferior, mortal body of an animal. In short, we’ve come to believe that our bodies and their feelings are a lesser kind of existence. But what if we’re wrong? What if all parts of us, including our minds, are deeply biological, and our physical experiences are far more meaningful and richer than we’ve been willing to accept? As far as we know, early hunter-gatherer animist societies saw spirit everywhere. All life possessed a special, non-physical essence. In European classical thought, many also believed that every living thing had a soul. But souls were graded. Humans were thought to have a superior soul within a hierarchy. By the time of theologians such as the Italian Dominican friar and philosopher Thomas Aquinas, in the 13th century, this soulful view of life had retreated, leaving humans the only creature still in possession of an immortal one. As beings with unique souls, we were more than mere animals. Our lives were set on a path to salvation. Life was now a great chain of being, with only the angels and God above us. But, as the Middle Ages came to a close in the 16th century, a fresh, apparently rational form of exceptionalism began to spread. The origins of this shift lie in the thinking of René Descartes, who gave the world a new version of dualism. Descartes argued that thought is so different from the physical, machine-like substance of the body that we should see humans as having two parts: the thoughtful mind and the thoughtless, physical body. This was religion refocused through a rational lens. The division between humans and the rest of nature was no longer the soul— or, at least, not only the soul—but rather our intellectual capabilities: our reason, our moral sensibilities, our gifts for abstraction. He assumed, of course, that other animals don’t think. Enlightenment figures such as John Locke and Immanuel Kant in the 17th and 18th centuries developed this further. According to them, it was the fruits of our intelligence that made us truly human. Through mental powers, humans live a more meaningful life than other beings. In other words, we humans have a soulful mind. It was even suggested that we are our thoughts and that these phantasmal mental aspects of humans are more important and even, daringly, separable from the impoverished biology that we share with other animals. In many ways, Darwinism posed a threat to this intensifying vision of the human and our place in nature. Charles Darwin disrupted both the idea of a neat divide between humans and other forms of life and also complicated the possibilities for mindbody dualism. If humans had evolved from earlier ancestral primates, then our minds, Reading Comprehension – Basic Leveltoo, must have emerged through ordinary, evolutionary processes with deep roots in nature. It’s easy to forget today just how shattering Darwinism was for a whole generation. Darwin himself wrote to his friend, the American botanist Asa Gray, to express his acute fear of seeing humans as a fully integrated part of a seemingly amoral natural world, where there’s ‘too much misery’. Perhaps we shouldn’t be surprised, then, to find the redoubling of efforts to assert new forms of human redemption in the years after the publication of On the Origin of Species (1859). One such effort came in the form of the ‘human revolution’—the idea that some kind of cognitive leap took place in the recent evolution of Homo sapiens that forever split us from other species. Another was in the 20th-century reworking of Enlightenment humanism that sought to find scientific proof of human exception and to argue that only these ultimately matter. Modern humanism promised to be about the complete realisation of human personality in an onward march to move farther into space and perhaps inhabit other planets. The history of a global philosophy on humans and other animals might be mischievously summarised as a long study in mental bias.",
    "ImageID": "",
    "question": "According to theologians of thirteenth- century Italy:",
    "options": {
      "a": "All life possessed a unique, non-phys ical essence.",
      "b": "Every living thing had a soul.",
      "c": "Humans had a superior soul within the hierarchy.",
      "d": "Humans were the only creature in possession of an immortal soul."
    },
    "answer": "d",
    "explanation": "A careful reading of the third para re veals that option D is the correct answer. Thoughts mentioned in other options are the thoughts perceived by the earlier societies.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 8,
    "passage": "  When I visited my grandmother at the undertakers, an hour or so before her funeral, I was struck by how different death is from sleep. A sleeping individual shimmers with fractional movements. The dead seem to rest in paused animation, so still, they look smaller than in life. It’s almost impossible not to feel as if something very like the soul is no longer present. Yet my grandmother had also died of Alzheimer’s. Even in life, something of who she was had begun to abandon her. And I wondered, as her memories vanished, had she become a little less herself, a little less human? These end-of-life stages prick our imaginations. They confront us with some unsettling ideas. We don’t like to face the possibility that irreversible biological processes in our bodies can snuff out the stunning light of our individual experiences. We prefer to deny our bodies altogether and push away the dark tendrils of a living world we fear. The trouble for us is that this story—that we aren’t really our bodies but some special, separate ‘thing’—has made a muddle of reality. Problems flow from the notion that we’re split between a superior human half and the inferior, mortal body of an animal. In short, we’ve come to believe that our bodies and their feelings are a lesser kind of existence. But what if we’re wrong? What if all parts of us, including our minds, are deeply biological, and our physical experiences are far more meaningful and richer than we’ve been willing to accept? As far as we know, early hunter-gatherer animist societies saw spirit everywhere. All life possessed a special, non-physical essence. In European classical thought, many also believed that every living thing had a soul. But souls were graded. Humans were thought to have a superior soul within a hierarchy. By the time of theologians such as the Italian Dominican friar and philosopher Thomas Aquinas, in the 13th century, this soulful view of life had retreated, leaving humans the only creature still in possession of an immortal one. As beings with unique souls, we were more than mere animals. Our lives were set on a path to salvation. Life was now a great chain of being, with only the angels and God above us. But, as the Middle Ages came to a close in the 16th century, a fresh, apparently rational form of exceptionalism began to spread. The origins of this shift lie in the thinking of René Descartes, who gave the world a new version of dualism. Descartes argued that thought is so different from the physical, machine-like substance of the body that we should see humans as having two parts: the thoughtful mind and the thoughtless, physical body. This was religion refocused through a rational lens. The division between humans and the rest of nature was no longer the soul— or, at least, not only the soul—but rather our intellectual capabilities: our reason, our moral sensibilities, our gifts for abstraction. He assumed, of course, that other animals don’t think. Enlightenment figures such as John Locke and Immanuel Kant in the 17th and 18th centuries developed this further. According to them, it was the fruits of our intelligence that made us truly human. Through mental powers, humans live a more meaningful life than other beings. In other words, we humans have a soulful mind. It was even suggested that we are our thoughts and that these phantasmal mental aspects of humans are more important and even, daringly, separable from the impoverished biology that we share with other animals. In many ways, Darwinism posed a threat to this intensifying vision of the human and our place in nature. Charles Darwin disrupted both the idea of a neat divide between humans and other forms of life and also complicated the possibilities for mindbody dualism. If humans had evolved from earlier ancestral primates, then our minds, Reading Comprehension – Basic Leveltoo, must have emerged through ordinary, evolutionary processes with deep roots in nature. It’s easy to forget today just how shattering Darwinism was for a whole generation. Darwin himself wrote to his friend, the American botanist Asa Gray, to express his acute fear of seeing humans as a fully integrated part of a seemingly amoral natural world, where there’s ‘too much misery’. Perhaps we shouldn’t be surprised, then, to find the redoubling of efforts to assert new forms of human redemption in the years after the publication of On the Origin of Species (1859). One such effort came in the form of the ‘human revolution’—the idea that some kind of cognitive leap took place in the recent evolution of Homo sapiens that forever split us from other species. Another was in the 20th-century reworking of Enlightenment humanism that sought to find scientific proof of human exception and to argue that only these ultimately matter. Modern humanism promised to be about the complete realisation of human personality in an onward march to move farther into space and perhaps inhabit other planets. The history of a global philosophy on humans and other animals might be mischievously summarised as a long study in mental bias.",
    "ImageID": "",
    "question": "All of the followings are true according to the passage, except:",
    "options": {
      "a": "René Descartes’ version of dualism was more rational than previous versions.",
      "b": "Descartes argued that we should see humans as having two parts: the thoughtful mind and the thoughtless physical body.",
      "c": "Descartes’ ideology contrasted with the religious view on the dualism of that time.",
      "d": "Descartes had assumed that only hu man beings had the ability to think."
    },
    "answer": "c",
    "explanation": "The question is concerned with the fourth paragraph of the passage. And a careful reading would reveal that state ments written in options A and D can be inferred, while option C is clearly stated in the fourth para. Therefore, option C is the correct answer, as it is the oppo site of the conclusion made in the fourth para.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 9,
    "passage": "  When I visited my grandmother at the undertakers, an hour or so before her funeral, I was struck by how different death is from sleep. A sleeping individual shimmers with fractional movements. The dead seem to rest in paused animation, so still, they look smaller than in life. It’s almost impossible not to feel as if something very like the soul is no longer present. Yet my grandmother had also died of Alzheimer’s. Even in life, something of who she was had begun to abandon her. And I wondered, as her memories vanished, had she become a little less herself, a little less human? These end-of-life stages prick our imaginations. They confront us with some unsettling ideas. We don’t like to face the possibility that irreversible biological processes in our bodies can snuff out the stunning light of our individual experiences. We prefer to deny our bodies altogether and push away the dark tendrils of a living world we fear. The trouble for us is that this story—that we aren’t really our bodies but some special, separate ‘thing’—has made a muddle of reality. Problems flow from the notion that we’re split between a superior human half and the inferior, mortal body of an animal. In short, we’ve come to believe that our bodies and their feelings are a lesser kind of existence. But what if we’re wrong? What if all parts of us, including our minds, are deeply biological, and our physical experiences are far more meaningful and richer than we’ve been willing to accept? As far as we know, early hunter-gatherer animist societies saw spirit everywhere. All life possessed a special, non-physical essence. In European classical thought, many also believed that every living thing had a soul. But souls were graded. Humans were thought to have a superior soul within a hierarchy. By the time of theologians such as the Italian Dominican friar and philosopher Thomas Aquinas, in the 13th century, this soulful view of life had retreated, leaving humans the only creature still in possession of an immortal one. As beings with unique souls, we were more than mere animals. Our lives were set on a path to salvation. Life was now a great chain of being, with only the angels and God above us. But, as the Middle Ages came to a close in the 16th century, a fresh, apparently rational form of exceptionalism began to spread. The origins of this shift lie in the thinking of René Descartes, who gave the world a new version of dualism. Descartes argued that thought is so different from the physical, machine-like substance of the body that we should see humans as having two parts: the thoughtful mind and the thoughtless, physical body. This was religion refocused through a rational lens. The division between humans and the rest of nature was no longer the soul— or, at least, not only the soul—but rather our intellectual capabilities: our reason, our moral sensibilities, our gifts for abstraction. He assumed, of course, that other animals don’t think. Enlightenment figures such as John Locke and Immanuel Kant in the 17th and 18th centuries developed this further. According to them, it was the fruits of our intelligence that made us truly human. Through mental powers, humans live a more meaningful life than other beings. In other words, we humans have a soulful mind. It was even suggested that we are our thoughts and that these phantasmal mental aspects of humans are more important and even, daringly, separable from the impoverished biology that we share with other animals. In many ways, Darwinism posed a threat to this intensifying vision of the human and our place in nature. Charles Darwin disrupted both the idea of a neat divide between humans and other forms of life and also complicated the possibilities for mindbody dualism. If humans had evolved from earlier ancestral primates, then our minds, Reading Comprehension – Basic Leveltoo, must have emerged through ordinary, evolutionary processes with deep roots in nature. It’s easy to forget today just how shattering Darwinism was for a whole generation. Darwin himself wrote to his friend, the American botanist Asa Gray, to express his acute fear of seeing humans as a fully integrated part of a seemingly amoral natural world, where there’s ‘too much misery’. Perhaps we shouldn’t be surprised, then, to find the redoubling of efforts to assert new forms of human redemption in the years after the publication of On the Origin of Species (1859). One such effort came in the form of the ‘human revolution’—the idea that some kind of cognitive leap took place in the recent evolution of Homo sapiens that forever split us from other species. Another was in the 20th-century reworking of Enlightenment humanism that sought to find scientific proof of human exception and to argue that only these ultimately matter. Modern humanism promised to be about the complete realisation of human personality in an onward march to move farther into space and perhaps inhabit other planets. The history of a global philosophy on humans and other animals might be mischievously summarised as a long study in mental bias.",
    "ImageID": "",
    "question": "The author seems to be:",
    "options": {
      "a": "Supporting the idea of the dualism of mind and body.",
      "b": "Negating the idea of the dualism of mind and body.",
      "c": "Neither supporting nor opposing the idea of the dualism of mind and body.",
      "d": "Supporting Darwin’s views on the du alism of mind and body."
    },
    "answer": "c",
    "explanation": "The subject matter of the passage is the dualism of mind and body and our var ying perceptions of that dualism. The death of the author’s grandmother (in the first para) sets these thoughts into motion. But the author is neither sup porting nor negating the idea of dualism. He is only discussing the various phases and patterns of this concept (dualism). Hence, option C is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 10,
    "passage": "  When I visited my grandmother at the undertakers, an hour or so before her funeral, I was struck by how different death is from sleep. A sleeping individual shimmers with fractional movements. The dead seem to rest in paused animation, so still, they look smaller than in life. It’s almost impossible not to feel as if something very like the soul is no longer present. Yet my grandmother had also died of Alzheimer’s. Even in life, something of who she was had begun to abandon her. And I wondered, as her memories vanished, had she become a little less herself, a little less human? These end-of-life stages prick our imaginations. They confront us with some unsettling ideas. We don’t like to face the possibility that irreversible biological processes in our bodies can snuff out the stunning light of our individual experiences. We prefer to deny our bodies altogether and push away the dark tendrils of a living world we fear. The trouble for us is that this story—that we aren’t really our bodies but some special, separate ‘thing’—has made a muddle of reality. Problems flow from the notion that we’re split between a superior human half and the inferior, mortal body of an animal. In short, we’ve come to believe that our bodies and their feelings are a lesser kind of existence. But what if we’re wrong? What if all parts of us, including our minds, are deeply biological, and our physical experiences are far more meaningful and richer than we’ve been willing to accept? As far as we know, early hunter-gatherer animist societies saw spirit everywhere. All life possessed a special, non-physical essence. In European classical thought, many also believed that every living thing had a soul. But souls were graded. Humans were thought to have a superior soul within a hierarchy. By the time of theologians such as the Italian Dominican friar and philosopher Thomas Aquinas, in the 13th century, this soulful view of life had retreated, leaving humans the only creature still in possession of an immortal one. As beings with unique souls, we were more than mere animals. Our lives were set on a path to salvation. Life was now a great chain of being, with only the angels and God above us. But, as the Middle Ages came to a close in the 16th century, a fresh, apparently rational form of exceptionalism began to spread. The origins of this shift lie in the thinking of René Descartes, who gave the world a new version of dualism. Descartes argued that thought is so different from the physical, machine-like substance of the body that we should see humans as having two parts: the thoughtful mind and the thoughtless, physical body. This was religion refocused through a rational lens. The division between humans and the rest of nature was no longer the soul— or, at least, not only the soul—but rather our intellectual capabilities: our reason, our moral sensibilities, our gifts for abstraction. He assumed, of course, that other animals don’t think. Enlightenment figures such as John Locke and Immanuel Kant in the 17th and 18th centuries developed this further. According to them, it was the fruits of our intelligence that made us truly human. Through mental powers, humans live a more meaningful life than other beings. In other words, we humans have a soulful mind. It was even suggested that we are our thoughts and that these phantasmal mental aspects of humans are more important and even, daringly, separable from the impoverished biology that we share with other animals. In many ways, Darwinism posed a threat to this intensifying vision of the human and our place in nature. Charles Darwin disrupted both the idea of a neat divide between humans and other forms of life and also complicated the possibilities for mindbody dualism. If humans had evolved from earlier ancestral primates, then our minds, Reading Comprehension – Basic Leveltoo, must have emerged through ordinary, evolutionary processes with deep roots in nature. It’s easy to forget today just how shattering Darwinism was for a whole generation. Darwin himself wrote to his friend, the American botanist Asa Gray, to express his acute fear of seeing humans as a fully integrated part of a seemingly amoral natural world, where there’s ‘too much misery’. Perhaps we shouldn’t be surprised, then, to find the redoubling of efforts to assert new forms of human redemption in the years after the publication of On the Origin of Species (1859). One such effort came in the form of the ‘human revolution’—the idea that some kind of cognitive leap took place in the recent evolution of Homo sapiens that forever split us from other species. Another was in the 20th-century reworking of Enlightenment humanism that sought to find scientific proof of human exception and to argue that only these ultimately matter. Modern humanism promised to be about the complete realisation of human personality in an onward march to move farther into space and perhaps inhabit other planets. The history of a global philosophy on humans and other animals might be mischievously summarised as a long study in mental bias.",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "Darwin was least likely to support the concept of mind-body dualism.",
      "b": "Darwin’s theory of evolution put an end to the possibilities of the dual ism of mind and body.",
      "c": "A complete realisation of human personality is one of the objectives of modern humanism.",
      "d": "Darwin realised the consequences of his findings and claims."
    },
    "answer": "b",
    "explanation": "Options A and D can be inferred from the sixth para. Option C can be inferred from the last paragraph. Option B is the correct answer here, as it is a wrong in ference. Darwin’s theory only complicat ed the possibility of dualism. It wouldn’t mean that it put an end to the possibility of its existence.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 11,
    "passage": "  Eric S. Maskin, a professor of economics and mathematics at Harvard University, in his 2007 Nobel Prize-winning speech, had said, “As one cynic noted, economists have predicted nine out of the last five recessions”. Predicting how an economy will behave in time to come is a tough business, given that there are so many factors at play. Hence, it is hardly surprising that when the covid pandemic started to spread around 18 months ago, most economists thought that the world would face a deflationary shock, with prices of goods and services falling, as most people stayed at home. But 18 months later, it is fair to say that the economists who predicted deflation got it wrong. Like always, there are exceptions to this as well. In a column in the Financial Times in May last year, Stephen Roach, who teaches at Yale University, had said that consumer spending would remain low only until a covid vaccine arrives. And once a vaccine hits the market, ‘pent-up demand will build as never before’. Roach explained that this would primarily happen because governments of the rich world would continue to support worker incomes until a vaccine became available. The pent-up demand thus released would lead to inflation or a rise in prices. Central banks are now getting ready to fight inflation. The major tool in their armoury to do so is interest rates. When inflationary expectations are high, monetary policy committees of central banks raise interest rates, the idea being that at higher interest rates people will borrow and spend less. This will bring down demand and, in the process, inflation as well. Since the beginning of 2020, central banks of the world, rich and poor, have printed a  lot of money to drive down interest rates in the hope of getting consumers and corporates to spend more. Thanks to very low interest rates, money has found its way into stock markets and other financial markets in search of higher returns. This has led to bubbles all around. As Ruchir Sharma, the chief global strategist at Morgan Stanley pointed out in a column in the Financial Times: ‘My research on the 10 biggest bubbles of the past century… shows that prices typically rise 100 percent in the year before the peak.’ On the basis of this definition, it is easy to conclude that everything, from stocks to cryptocurrencies, has been in a bubbly territory in the recent past. But all this is the benefit of hindsight. The bigger question is: What does the future hold. As usual, there are arguments on both sides. One school of thought is that central banks will have to raise rates to fight inflation. On the flip side, the argument is that if central banks raise interest rates, they will derail the economic recovery process that is currently on throughout much of the Western world. Dylan Grice, in the latest edition of the Popular Delusions newsletter, writes: ‘Central banks would accommodate the inflation, lacking the will or stomach to tame what they had unleashed’. Hence, central banks of the rich world will be ready to ignore inflation and try and maintain interest rates at low levels, in the hope of creating some growth. Nevertheless, higher inflation will drive down the real rate of interest on bank deposits, the safest form of investing, even further. The real rate of interest is obtained by subtracting the rate of inflation from the interest offered on deposits. In this scenario, money should keep coming into stocks in search of higher returns, or as Grice puts it: ‘This would ultimately be supportive/bullish for equities’. Of course, only time will tell which side turns out to be right. ",
    "ImageID": "",
    "question": "According to the passage, predicting the behaviour of the economy is very tough because:",
    "options": {
      "a": "The economy is an elusive and ev er-changing thing.",
      "b": "There are multiple factors that influ ence the economy.",
      "c": "Many unpredictable situations (like COVID 19) also affect the economy.",
      "d": "Different governments pursue differ ent economic policies."
    },
    "answer": "b",
    "explanation": "The first sentence of the second para graph clearly states that there are many factors at play; hence, it is difficult to predict the behaviour of the economy. Clearly, B is the answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 12,
    "passage": "  Eric S. Maskin, a professor of economics and mathematics at Harvard University, in his 2007 Nobel Prize-winning speech, had said, “As one cynic noted, economists have predicted nine out of the last five recessions”. Predicting how an economy will behave in time to come is a tough business, given that there are so many factors at play. Hence, it is hardly surprising that when the covid pandemic started to spread around 18 months ago, most economists thought that the world would face a deflationary shock, with prices of goods and services falling, as most people stayed at home. But 18 months later, it is fair to say that the economists who predicted deflation got it wrong. Like always, there are exceptions to this as well. In a column in the Financial Times in May last year, Stephen Roach, who teaches at Yale University, had said that consumer spending would remain low only until a covid vaccine arrives. And once a vaccine hits the market, ‘pent-up demand will build as never before’. Roach explained that this would primarily happen because governments of the rich world would continue to support worker incomes until a vaccine became available. The pent-up demand thus released would lead to inflation or a rise in prices. Central banks are now getting ready to fight inflation. The major tool in their armoury to do so is interest rates. When inflationary expectations are high, monetary policy committees of central banks raise interest rates, the idea being that at higher interest rates people will borrow and spend less. This will bring down demand and, in the process, inflation as well. Since the beginning of 2020, central banks of the world, rich and poor, have printed a  lot of money to drive down interest rates in the hope of getting consumers and corporates to spend more. Thanks to very low interest rates, money has found its way into stock markets and other financial markets in search of higher returns. This has led to bubbles all around. As Ruchir Sharma, the chief global strategist at Morgan Stanley pointed out in a column in the Financial Times: ‘My research on the 10 biggest bubbles of the past century… shows that prices typically rise 100 percent in the year before the peak.’ On the basis of this definition, it is easy to conclude that everything, from stocks to cryptocurrencies, has been in a bubbly territory in the recent past. But all this is the benefit of hindsight. The bigger question is: What does the future hold. As usual, there are arguments on both sides. One school of thought is that central banks will have to raise rates to fight inflation. On the flip side, the argument is that if central banks raise interest rates, they will derail the economic recovery process that is currently on throughout much of the Western world. Dylan Grice, in the latest edition of the Popular Delusions newsletter, writes: ‘Central banks would accommodate the inflation, lacking the will or stomach to tame what they had unleashed’. Hence, central banks of the rich world will be ready to ignore inflation and try and maintain interest rates at low levels, in the hope of creating some growth. Nevertheless, higher inflation will drive down the real rate of interest on bank deposits, the safest form of investing, even further. The real rate of interest is obtained by subtracting the rate of inflation from the interest offered on deposits. In this scenario, money should keep coming into stocks in search of higher returns, or as Grice puts it: ‘This would ultimately be supportive/bullish for equities’. Of course, only time will tell which side turns out to be right. ",
    "ImageID": "",
    "question": "The second sentence of the third para graph states that—there are exceptions to this as well. This sentence implies that:",
    "options": {
      "a": "Economists had predicted that there would be deflation due to the pan demic situation, but instead, the world faced inflation.",
      "b": "Most economists who had predicted deflation due to the pandemic situa tion got it wrong, but some were also correct.",
      "c": "Most economists had predicted de f lation due to the pandemic situa tion, but some had predicted infla tion also.",
      "d": "First, there would be deflation and then inflation due to the pandemic situation."
    },
    "answer": "c",
    "explanation": "This question can be a bit tricky for a non-observant reader. A meticulous ob servation is required to understand the context of the given sentence. ‘There are exceptions to this as well’. There are exceptions to what? Before this sentence, the author has said that the economists who had predict ed deflation got it wrong. Which means there was no deflation. Hence, B cannot be the correct answer. The statement written in option A is somewhat correct, but it does not relate to the sentence given in the question. The given sentence has not been said in that regard. Hence, A is not the correct answer. After the given sentence, the author cites the example of an economist who had predicted inflation due to the pan demic situation. Hence, ‘there are ex ceptions to this as well’ implies that though most economists had predicted deflation (and they got it wrong), some economists had predicted inflation as well (and they got it correct). Option C states this; hence, it is the correct answer. Option (D) is not concerned with the giv en sentence; it cannot be the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 13,
    "passage": "  Eric S. Maskin, a professor of economics and mathematics at Harvard University, in his 2007 Nobel Prize-winning speech, had said, “As one cynic noted, economists have predicted nine out of the last five recessions”. Predicting how an economy will behave in time to come is a tough business, given that there are so many factors at play. Hence, it is hardly surprising that when the covid pandemic started to spread around 18 months ago, most economists thought that the world would face a deflationary shock, with prices of goods and services falling, as most people stayed at home. But 18 months later, it is fair to say that the economists who predicted deflation got it wrong. Like always, there are exceptions to this as well. In a column in the Financial Times in May last year, Stephen Roach, who teaches at Yale University, had said that consumer spending would remain low only until a covid vaccine arrives. And once a vaccine hits the market, ‘pent-up demand will build as never before’. Roach explained that this would primarily happen because governments of the rich world would continue to support worker incomes until a vaccine became available. The pent-up demand thus released would lead to inflation or a rise in prices. Central banks are now getting ready to fight inflation. The major tool in their armoury to do so is interest rates. When inflationary expectations are high, monetary policy committees of central banks raise interest rates, the idea being that at higher interest rates people will borrow and spend less. This will bring down demand and, in the process, inflation as well. Since the beginning of 2020, central banks of the world, rich and poor, have printed a  lot of money to drive down interest rates in the hope of getting consumers and corporates to spend more. Thanks to very low interest rates, money has found its way into stock markets and other financial markets in search of higher returns. This has led to bubbles all around. As Ruchir Sharma, the chief global strategist at Morgan Stanley pointed out in a column in the Financial Times: ‘My research on the 10 biggest bubbles of the past century… shows that prices typically rise 100 percent in the year before the peak.’ On the basis of this definition, it is easy to conclude that everything, from stocks to cryptocurrencies, has been in a bubbly territory in the recent past. But all this is the benefit of hindsight. The bigger question is: What does the future hold. As usual, there are arguments on both sides. One school of thought is that central banks will have to raise rates to fight inflation. On the flip side, the argument is that if central banks raise interest rates, they will derail the economic recovery process that is currently on throughout much of the Western world. Dylan Grice, in the latest edition of the Popular Delusions newsletter, writes: ‘Central banks would accommodate the inflation, lacking the will or stomach to tame what they had unleashed’. Hence, central banks of the rich world will be ready to ignore inflation and try and maintain interest rates at low levels, in the hope of creating some growth. Nevertheless, higher inflation will drive down the real rate of interest on bank deposits, the safest form of investing, even further. The real rate of interest is obtained by subtracting the rate of inflation from the interest offered on deposits. In this scenario, money should keep coming into stocks in search of higher returns, or as Grice puts it: ‘This would ultimately be supportive/bullish for equities’. Of course, only time will tell which side turns out to be right. ",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "To control inflation, Central banks are likely to raise the interest rates on loans.",
      "b": "Central banks are likely to lower the interest rates on bank deposits to curb inflation.",
      "c": "Central banks are likely to raise the interest rates on loans and bank de posits to control inflation.",
      "d": "If central banks manage to bring down the demands in the market, they can control inflation."
    },
    "answer": "c",
    "explanation": "A large circulation of money in the mar ket increases the purchasing power of consumers and boosts demand. Higher demand leads to increased prices. So, by controlling the flow of money in the market, Central banks can control inflation. If the interest rates on loans are high, people will borrow less. Hence, A is correct. Lower interest rates on deposits mean less money for people; hence, their buy ing capacity will reduce. So, B is also correct. D is correct by definition—refer to the f ifth paragraph. C cannot be inferred. As it states that in terest rates should be increased on loans as well as on deposits, which is incorrect. Rates of interest on loans should be in creased, but the rate of interest on depos its should be lowered in order to control in f lation. Hence, C is the correct choice here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 14,
    "passage": "  Eric S. Maskin, a professor of economics and mathematics at Harvard University, in his 2007 Nobel Prize-winning speech, had said, “As one cynic noted, economists have predicted nine out of the last five recessions”. Predicting how an economy will behave in time to come is a tough business, given that there are so many factors at play. Hence, it is hardly surprising that when the covid pandemic started to spread around 18 months ago, most economists thought that the world would face a deflationary shock, with prices of goods and services falling, as most people stayed at home. But 18 months later, it is fair to say that the economists who predicted deflation got it wrong. Like always, there are exceptions to this as well. In a column in the Financial Times in May last year, Stephen Roach, who teaches at Yale University, had said that consumer spending would remain low only until a covid vaccine arrives. And once a vaccine hits the market, ‘pent-up demand will build as never before’. Roach explained that this would primarily happen because governments of the rich world would continue to support worker incomes until a vaccine became available. The pent-up demand thus released would lead to inflation or a rise in prices. Central banks are now getting ready to fight inflation. The major tool in their armoury to do so is interest rates. When inflationary expectations are high, monetary policy committees of central banks raise interest rates, the idea being that at higher interest rates people will borrow and spend less. This will bring down demand and, in the process, inflation as well. Since the beginning of 2020, central banks of the world, rich and poor, have printed a  lot of money to drive down interest rates in the hope of getting consumers and corporates to spend more. Thanks to very low interest rates, money has found its way into stock markets and other financial markets in search of higher returns. This has led to bubbles all around. As Ruchir Sharma, the chief global strategist at Morgan Stanley pointed out in a column in the Financial Times: ‘My research on the 10 biggest bubbles of the past century… shows that prices typically rise 100 percent in the year before the peak.’ On the basis of this definition, it is easy to conclude that everything, from stocks to cryptocurrencies, has been in a bubbly territory in the recent past. But all this is the benefit of hindsight. The bigger question is: What does the future hold. As usual, there are arguments on both sides. One school of thought is that central banks will have to raise rates to fight inflation. On the flip side, the argument is that if central banks raise interest rates, they will derail the economic recovery process that is currently on throughout much of the Western world. Dylan Grice, in the latest edition of the Popular Delusions newsletter, writes: ‘Central banks would accommodate the inflation, lacking the will or stomach to tame what they had unleashed’. Hence, central banks of the rich world will be ready to ignore inflation and try and maintain interest rates at low levels, in the hope of creating some growth. Nevertheless, higher inflation will drive down the real rate of interest on bank deposits, the safest form of investing, even further. The real rate of interest is obtained by subtracting the rate of inflation from the interest offered on deposits. In this scenario, money should keep coming into stocks in search of higher returns, or as Grice puts it: ‘This would ultimately be supportive/bullish for equities’. Of course, only time will tell which side turns out to be right. ",
    "ImageID": "",
    "question": "The term ‘bubbles’ as used in the last sentence of the sixth paragraph refers to:",
    "options": {
      "a": "A sudden fall in the prices of stocks due to a lack of liquidity in the market.",
      "b": "Instability in the prices of stocks due to fluctuating liquidity in the market.",
      "c": "A sudden rise in the prices of stocks due to increased liquidity in the market.",
      "d": "A sudden rise and then fall in the prices of commodities in the market."
    },
    "answer": "c",
    "explanation": "Refer to the sixth and seventh para graphs. The governments across the world printed a lot of money, and that money ultimately found its way into the stock markets, increasing the prices of the stocks to an absurd level. This situa tion has been referred to as ‘bubbles’ in the market. Hence, C is the answer. Such bubbles are temporary and are likely to burst if the central banks decide to control the flow of money in the mar ket by increasing the interest rates. Some readers might argue that D should be the answer here. But that is not the case because the fall in prices comes later. The ‘bubbles’ specifically refer to the inflated costs of the stocks.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 15,
    "passage": "  Eric S. Maskin, a professor of economics and mathematics at Harvard University, in his 2007 Nobel Prize-winning speech, had said, “As one cynic noted, economists have predicted nine out of the last five recessions”. Predicting how an economy will behave in time to come is a tough business, given that there are so many factors at play. Hence, it is hardly surprising that when the covid pandemic started to spread around 18 months ago, most economists thought that the world would face a deflationary shock, with prices of goods and services falling, as most people stayed at home. But 18 months later, it is fair to say that the economists who predicted deflation got it wrong. Like always, there are exceptions to this as well. In a column in the Financial Times in May last year, Stephen Roach, who teaches at Yale University, had said that consumer spending would remain low only until a covid vaccine arrives. And once a vaccine hits the market, ‘pent-up demand will build as never before’. Roach explained that this would primarily happen because governments of the rich world would continue to support worker incomes until a vaccine became available. The pent-up demand thus released would lead to inflation or a rise in prices. Central banks are now getting ready to fight inflation. The major tool in their armoury to do so is interest rates. When inflationary expectations are high, monetary policy committees of central banks raise interest rates, the idea being that at higher interest rates people will borrow and spend less. This will bring down demand and, in the process, inflation as well. Since the beginning of 2020, central banks of the world, rich and poor, have printed a  lot of money to drive down interest rates in the hope of getting consumers and corporates to spend more. Thanks to very low interest rates, money has found its way into stock markets and other financial markets in search of higher returns. This has led to bubbles all around. As Ruchir Sharma, the chief global strategist at Morgan Stanley pointed out in a column in the Financial Times: ‘My research on the 10 biggest bubbles of the past century… shows that prices typically rise 100 percent in the year before the peak.’ On the basis of this definition, it is easy to conclude that everything, from stocks to cryptocurrencies, has been in a bubbly territory in the recent past. But all this is the benefit of hindsight. The bigger question is: What does the future hold. As usual, there are arguments on both sides. One school of thought is that central banks will have to raise rates to fight inflation. On the flip side, the argument is that if central banks raise interest rates, they will derail the economic recovery process that is currently on throughout much of the Western world. Dylan Grice, in the latest edition of the Popular Delusions newsletter, writes: ‘Central banks would accommodate the inflation, lacking the will or stomach to tame what they had unleashed’. Hence, central banks of the rich world will be ready to ignore inflation and try and maintain interest rates at low levels, in the hope of creating some growth. Nevertheless, higher inflation will drive down the real rate of interest on bank deposits, the safest form of investing, even further. The real rate of interest is obtained by subtracting the rate of inflation from the interest offered on deposits. In this scenario, money should keep coming into stocks in search of higher returns, or as Grice puts it: ‘This would ultimately be supportive/bullish for equities’. Of course, only time will tell which side turns out to be right. ",
    "ImageID": "",
    "question": "What is the main argument of the passage?",
    "options": {
      "a": "It is tough to predict the behaviour of the economy.",
      "b": "By controlling the flow of money in the market, central banks can con trol inflation.",
      "c": "Most of the economists who predict ed deflation due to the pandemic got it wrong.",
      "d": "There are two schools of thought about what policies central banks should adopt to fight inflation."
    },
    "answer": "a",
    "explanation": "Though all the arguments mentioned in options A, B, C, and D are made in the passage, the question is asking for the main argument. The main argument should be the central theme or a point that has been reiterated by the author throughout the passage.  Option A is the main argument made by the author, as he has emphasised it sev eral times in the passage. Point of reference: Throughout the pas sage. Especially the second, the eighth, and tenth paragraphs. The author even closes the passage by saying ‘only time will tell’, which means it cannot be pre dicted now. Other options address narrow issues, which have been discussed only in a par ticular part of the passage.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 16,
    "passage": "  One seemingly simple question we don’t know the answer to is how many people are actually living with dementia and how many are women; because around 50 percent of people living with dementia are undiagnosed, all we have are estimates. A study published in 2013, based on other longitudinal studies, estimated that there are 4.7 million people aged over 65 living with dementia in the United States, and others have estimated that two-thirds of these are women. This number was calculated by extrapolating the prospective Chicago Health and Aging Project (CHAP), where a cohort of almost 4,000 people had repeated cognitive assessments, to the US population. The estimate that two-thirds of people with dementia are women was made despite the original cohort in Chicago having no difference in rates of dementia diagnosis between men and women. This is even more complicated if we look at historical cohorts. Older studies of gender and prevalence identified dementia as being more common in women. In a meta-analysis published in 1999, women over 85 had a far higher risk of being diagnosed with dementia than men. Within this meta-analysis, there were significant differences between countries: in the U.S., there was no difference between the sexes, but women in Europe and Asia were at higher risk. The studies used a variety of methodologies to identify people at risk of dementia, including a screening test called the mini-mental state examination (MMSE), which is heavily influenced by education level. Since women have traditionally had lower levels of education and the study didn’t adjust for this, were these women more likely to have dementia, or were they just bad at the test? While dementia is not a normal part of ageing, the biggest risk for getting dementia is  simply getting older, and since, worldwide, women have a longer life expectancy than men, ranging from 10 extra years in Russia to half a year in Bhutan, more women reach their 80s and 90s when dementia risk rises. Women do have certain biological advantages that explain this improved life expectancy. Since the X chromosome contains many genes that are involved in immunity, women are more resistant to infections than men. The downside to this is that women are more likely to develop autoimmune diseases. Women tend to live longer, but with more chronic diseases and higher levels of disability in older age, as though better able to survive physical challenges—and this is also true of dementia. Since the leading cause of death for men in the UK and Australia is ischaemic heart disease, perhaps men are also dying too soon to be diagnosed with dementia. In a study of people who attended a memory clinic for a dementia diagnosis and then donated their brains in death, men had a lower level of pathology and a shorter time to death after diagnosis. It’s not clear from this study whether men died of dementia or not, but if fewer men live to older age, and men survive fewer years with dementia, that goes a long way to explaining why most people living with dementia are women. Sex hormones also have a role in brain health, with oestrogen having a positive effect on brain function. Oestrogen helps women prepare for motherhood: during pregnancy, women’s brains become more plastic and more able to learn, ready for the challenge of parenting a new-born. Many women in mid-life experience brain fog, or functional cognitive disorder, especially trouble with concentration and memory. Some women do experience a decline in memory and processing speed during the time of menopause, but these changes resolve once the hormonal changes have settled. It’s also a risky assumption to attribute ‘brain fog’ to hormones alone. Menopause Reading Comprehension – Basic Levelcan negatively impact sleep, which impacts cognitive function, and is also a risky time for the onset of depression. So many women who experience this brain fog are terrified that this is the start of dementia, but there’s no evidence that it’s the start of an inexorable decline.",
    "ImageID": "",
    "question": "Why does the author bring up the exam ple of oestrogen in the sixth paragraph?",
    "options": {
      "a": "To strengthen his view that women are mentally powerful, so they are less prone to dementia.",
      "b": "To refute the claims by different studies that women are naturally at a higher risk side of dementia.",
      "c": "To prove that women have high im munity; so they can fight dementia.",
      "d": "To show that oestrogen helps women prepare for motherhood."
    },
    "answer": "b",
    "explanation": "Throughout the passage, the author has given various examples to question the general view that women are more prone to dementia than men. Oestrogen has been used as just another example to support his view. So, option B is the cor rect answer. Option A is incorrect, as the author has never made any such claim in the passage. Option C is incorrect, as oestrogen has got nothing to do with immunity in women. Option D is incorrect, as it has been used only as a distortion.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 17,
    "passage": "  One seemingly simple question we don’t know the answer to is how many people are actually living with dementia and how many are women; because around 50 percent of people living with dementia are undiagnosed, all we have are estimates. A study published in 2013, based on other longitudinal studies, estimated that there are 4.7 million people aged over 65 living with dementia in the United States, and others have estimated that two-thirds of these are women. This number was calculated by extrapolating the prospective Chicago Health and Aging Project (CHAP), where a cohort of almost 4,000 people had repeated cognitive assessments, to the US population. The estimate that two-thirds of people with dementia are women was made despite the original cohort in Chicago having no difference in rates of dementia diagnosis between men and women. This is even more complicated if we look at historical cohorts. Older studies of gender and prevalence identified dementia as being more common in women. In a meta-analysis published in 1999, women over 85 had a far higher risk of being diagnosed with dementia than men. Within this meta-analysis, there were significant differences between countries: in the U.S., there was no difference between the sexes, but women in Europe and Asia were at higher risk. The studies used a variety of methodologies to identify people at risk of dementia, including a screening test called the mini-mental state examination (MMSE), which is heavily influenced by education level. Since women have traditionally had lower levels of education and the study didn’t adjust for this, were these women more likely to have dementia, or were they just bad at the test? While dementia is not a normal part of ageing, the biggest risk for getting dementia is  simply getting older, and since, worldwide, women have a longer life expectancy than men, ranging from 10 extra years in Russia to half a year in Bhutan, more women reach their 80s and 90s when dementia risk rises. Women do have certain biological advantages that explain this improved life expectancy. Since the X chromosome contains many genes that are involved in immunity, women are more resistant to infections than men. The downside to this is that women are more likely to develop autoimmune diseases. Women tend to live longer, but with more chronic diseases and higher levels of disability in older age, as though better able to survive physical challenges—and this is also true of dementia. Since the leading cause of death for men in the UK and Australia is ischaemic heart disease, perhaps men are also dying too soon to be diagnosed with dementia. In a study of people who attended a memory clinic for a dementia diagnosis and then donated their brains in death, men had a lower level of pathology and a shorter time to death after diagnosis. It’s not clear from this study whether men died of dementia or not, but if fewer men live to older age, and men survive fewer years with dementia, that goes a long way to explaining why most people living with dementia are women. Sex hormones also have a role in brain health, with oestrogen having a positive effect on brain function. Oestrogen helps women prepare for motherhood: during pregnancy, women’s brains become more plastic and more able to learn, ready for the challenge of parenting a new-born. Many women in mid-life experience brain fog, or functional cognitive disorder, especially trouble with concentration and memory. Some women do experience a decline in memory and processing speed during the time of menopause, but these changes resolve once the hormonal changes have settled. It’s also a risky assumption to attribute ‘brain fog’ to hormones alone. Menopause Reading Comprehension – Basic Levelcan negatively impact sleep, which impacts cognitive function, and is also a risky time for the onset of depression. So many women who experience this brain fog are terrified that this is the start of dementia, but there’s no evidence that it’s the start of an inexorable decline.",
    "ImageID": "",
    "question": "All of the following are true according to the passage, except:",
    "options": {
      "a": "Menopause impacts cognitive func tion and indicates the start of dementia.",
      "b": "Menopause can negatively impact sleep and is also a difficult time for the onset of depression.",
      "c": "‘Brain fog’ cannot be attributed to hormones alone.",
      "d": "The trouble with concentration and memory and functional cognitive disorder can be attributed to ‘brain fog’."
    },
    "answer": "a",
    "explanation": "The question refers to the last paragraph of the passage. Options B and C are clearly written there, so both are true. Option D can also be confirmed from the f irst line of the last paragraph. Option A is the opposite of what is writ ten in the passage. Hence, option A is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 18,
    "passage": "  One seemingly simple question we don’t know the answer to is how many people are actually living with dementia and how many are women; because around 50 percent of people living with dementia are undiagnosed, all we have are estimates. A study published in 2013, based on other longitudinal studies, estimated that there are 4.7 million people aged over 65 living with dementia in the United States, and others have estimated that two-thirds of these are women. This number was calculated by extrapolating the prospective Chicago Health and Aging Project (CHAP), where a cohort of almost 4,000 people had repeated cognitive assessments, to the US population. The estimate that two-thirds of people with dementia are women was made despite the original cohort in Chicago having no difference in rates of dementia diagnosis between men and women. This is even more complicated if we look at historical cohorts. Older studies of gender and prevalence identified dementia as being more common in women. In a meta-analysis published in 1999, women over 85 had a far higher risk of being diagnosed with dementia than men. Within this meta-analysis, there were significant differences between countries: in the U.S., there was no difference between the sexes, but women in Europe and Asia were at higher risk. The studies used a variety of methodologies to identify people at risk of dementia, including a screening test called the mini-mental state examination (MMSE), which is heavily influenced by education level. Since women have traditionally had lower levels of education and the study didn’t adjust for this, were these women more likely to have dementia, or were they just bad at the test? While dementia is not a normal part of ageing, the biggest risk for getting dementia is  simply getting older, and since, worldwide, women have a longer life expectancy than men, ranging from 10 extra years in Russia to half a year in Bhutan, more women reach their 80s and 90s when dementia risk rises. Women do have certain biological advantages that explain this improved life expectancy. Since the X chromosome contains many genes that are involved in immunity, women are more resistant to infections than men. The downside to this is that women are more likely to develop autoimmune diseases. Women tend to live longer, but with more chronic diseases and higher levels of disability in older age, as though better able to survive physical challenges—and this is also true of dementia. Since the leading cause of death for men in the UK and Australia is ischaemic heart disease, perhaps men are also dying too soon to be diagnosed with dementia. In a study of people who attended a memory clinic for a dementia diagnosis and then donated their brains in death, men had a lower level of pathology and a shorter time to death after diagnosis. It’s not clear from this study whether men died of dementia or not, but if fewer men live to older age, and men survive fewer years with dementia, that goes a long way to explaining why most people living with dementia are women. Sex hormones also have a role in brain health, with oestrogen having a positive effect on brain function. Oestrogen helps women prepare for motherhood: during pregnancy, women’s brains become more plastic and more able to learn, ready for the challenge of parenting a new-born. Many women in mid-life experience brain fog, or functional cognitive disorder, especially trouble with concentration and memory. Some women do experience a decline in memory and processing speed during the time of menopause, but these changes resolve once the hormonal changes have settled. It’s also a risky assumption to attribute ‘brain fog’ to hormones alone. Menopause Reading Comprehension – Basic Levelcan negatively impact sleep, which impacts cognitive function, and is also a risky time for the onset of depression. So many women who experience this brain fog are terrified that this is the start of dementia, but there’s no evidence that it’s the start of an inexorable decline.",
    "ImageID": "",
    "question": "In the fifth paragraph of the passage, the author is most likely suggesting that:",
    "options": {
      "a": "Had men lived longer, the number of men diagnosed with dementia would have been higher.",
      "b": "Men having a shorter time to death after diagnosis is why more women are diagnosed with dementia.",
      "c": "After being diagnosed with dementia, men survive fewer years.",
      "d": "Women diagnosed with dementia live longer than men diagnosed with dementia."
    },
    "answer": "a",
    "explanation": "In that paragraph, the author says it is not clear from the study whether those men died of dementia or not because of either a lower level of pathology or a shorter time to death after diagnosis. This indicates that the author wants to say that if men lived longer after diagno sis, the chances of more men being diag nosed with dementia are higher. This exact thing has been said in option A, so option A is the correct choice. Options C and D agree with what the au thor has said in the passage, but not why the author has said those things. So, op tions C and D are distortions. Option B is irrelevant and doesn’t make sense.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 19,
    "passage": "  One seemingly simple question we don’t know the answer to is how many people are actually living with dementia and how many are women; because around 50 percent of people living with dementia are undiagnosed, all we have are estimates. A study published in 2013, based on other longitudinal studies, estimated that there are 4.7 million people aged over 65 living with dementia in the United States, and others have estimated that two-thirds of these are women. This number was calculated by extrapolating the prospective Chicago Health and Aging Project (CHAP), where a cohort of almost 4,000 people had repeated cognitive assessments, to the US population. The estimate that two-thirds of people with dementia are women was made despite the original cohort in Chicago having no difference in rates of dementia diagnosis between men and women. This is even more complicated if we look at historical cohorts. Older studies of gender and prevalence identified dementia as being more common in women. In a meta-analysis published in 1999, women over 85 had a far higher risk of being diagnosed with dementia than men. Within this meta-analysis, there were significant differences between countries: in the U.S., there was no difference between the sexes, but women in Europe and Asia were at higher risk. The studies used a variety of methodologies to identify people at risk of dementia, including a screening test called the mini-mental state examination (MMSE), which is heavily influenced by education level. Since women have traditionally had lower levels of education and the study didn’t adjust for this, were these women more likely to have dementia, or were they just bad at the test? While dementia is not a normal part of ageing, the biggest risk for getting dementia is  simply getting older, and since, worldwide, women have a longer life expectancy than men, ranging from 10 extra years in Russia to half a year in Bhutan, more women reach their 80s and 90s when dementia risk rises. Women do have certain biological advantages that explain this improved life expectancy. Since the X chromosome contains many genes that are involved in immunity, women are more resistant to infections than men. The downside to this is that women are more likely to develop autoimmune diseases. Women tend to live longer, but with more chronic diseases and higher levels of disability in older age, as though better able to survive physical challenges—and this is also true of dementia. Since the leading cause of death for men in the UK and Australia is ischaemic heart disease, perhaps men are also dying too soon to be diagnosed with dementia. In a study of people who attended a memory clinic for a dementia diagnosis and then donated their brains in death, men had a lower level of pathology and a shorter time to death after diagnosis. It’s not clear from this study whether men died of dementia or not, but if fewer men live to older age, and men survive fewer years with dementia, that goes a long way to explaining why most people living with dementia are women. Sex hormones also have a role in brain health, with oestrogen having a positive effect on brain function. Oestrogen helps women prepare for motherhood: during pregnancy, women’s brains become more plastic and more able to learn, ready for the challenge of parenting a new-born. Many women in mid-life experience brain fog, or functional cognitive disorder, especially trouble with concentration and memory. Some women do experience a decline in memory and processing speed during the time of menopause, but these changes resolve once the hormonal changes have settled. It’s also a risky assumption to attribute ‘brain fog’ to hormones alone. Menopause Reading Comprehension – Basic Levelcan negatively impact sleep, which impacts cognitive function, and is also a risky time for the onset of depression. So many women who experience this brain fog are terrified that this is the start of dementia, but there’s no evidence that it’s the start of an inexorable decline.",
    "ImageID": "",
    "question": "Which of the following is true about the study discussed in the passage’s second paragraph?",
    "options": {
      "a": "The claim that two-thirds of the peo ple who have dementia are women is a judgement in itself on the part of the study.",
      "b": "The claim that two-thirds of the peo ple who have dementia are women is an exaggeration.",
      "c": "The estimate that two-thirds of peo ple with dementia are women is an error on the part of the study.",
      "d": "The cohort size of 4000 people was not sufficient for the study."
    },
    "answer": "a",
    "explanation": "‘This number was calculated by extrap olating the prospective Chicago Health and Aging Project (CHAP).—This line from the paragraph suggests that the number was a judgement made in the study. Hence, option A is the correct answer. Option D is incorrect as it would be an assumption.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 20,
    "passage": "  One seemingly simple question we don’t know the answer to is how many people are actually living with dementia and how many are women; because around 50 percent of people living with dementia are undiagnosed, all we have are estimates. A study published in 2013, based on other longitudinal studies, estimated that there are 4.7 million people aged over 65 living with dementia in the United States, and others have estimated that two-thirds of these are women. This number was calculated by extrapolating the prospective Chicago Health and Aging Project (CHAP), where a cohort of almost 4,000 people had repeated cognitive assessments, to the US population. The estimate that two-thirds of people with dementia are women was made despite the original cohort in Chicago having no difference in rates of dementia diagnosis between men and women. This is even more complicated if we look at historical cohorts. Older studies of gender and prevalence identified dementia as being more common in women. In a meta-analysis published in 1999, women over 85 had a far higher risk of being diagnosed with dementia than men. Within this meta-analysis, there were significant differences between countries: in the U.S., there was no difference between the sexes, but women in Europe and Asia were at higher risk. The studies used a variety of methodologies to identify people at risk of dementia, including a screening test called the mini-mental state examination (MMSE), which is heavily influenced by education level. Since women have traditionally had lower levels of education and the study didn’t adjust for this, were these women more likely to have dementia, or were they just bad at the test? While dementia is not a normal part of ageing, the biggest risk for getting dementia is  simply getting older, and since, worldwide, women have a longer life expectancy than men, ranging from 10 extra years in Russia to half a year in Bhutan, more women reach their 80s and 90s when dementia risk rises. Women do have certain biological advantages that explain this improved life expectancy. Since the X chromosome contains many genes that are involved in immunity, women are more resistant to infections than men. The downside to this is that women are more likely to develop autoimmune diseases. Women tend to live longer, but with more chronic diseases and higher levels of disability in older age, as though better able to survive physical challenges—and this is also true of dementia. Since the leading cause of death for men in the UK and Australia is ischaemic heart disease, perhaps men are also dying too soon to be diagnosed with dementia. In a study of people who attended a memory clinic for a dementia diagnosis and then donated their brains in death, men had a lower level of pathology and a shorter time to death after diagnosis. It’s not clear from this study whether men died of dementia or not, but if fewer men live to older age, and men survive fewer years with dementia, that goes a long way to explaining why most people living with dementia are women. Sex hormones also have a role in brain health, with oestrogen having a positive effect on brain function. Oestrogen helps women prepare for motherhood: during pregnancy, women’s brains become more plastic and more able to learn, ready for the challenge of parenting a new-born. Many women in mid-life experience brain fog, or functional cognitive disorder, especially trouble with concentration and memory. Some women do experience a decline in memory and processing speed during the time of menopause, but these changes resolve once the hormonal changes have settled. It’s also a risky assumption to attribute ‘brain fog’ to hormones alone. Menopause Reading Comprehension – Basic Levelcan negatively impact sleep, which impacts cognitive function, and is also a risky time for the onset of depression. So many women who experience this brain fog are terrified that this is the start of dementia, but there’s no evidence that it’s the start of an inexorable decline.",
    "ImageID": "",
    "question": "The author has mentioned all of the following as the reasons behind more women being diagnosed with dementia, except:",
    "options": {
      "a": "The extrapolated calculation of the prospective Chicago Health and Aging Project (CHAP) by the studies.",
      "b": "The inadequate methodologies to identify people at risk of dementia.",
      "c": "Men dying too soon to be diagnosed with dementia.",
      "d": "Menopause in women negatively im pacts sleep, which impacts cognitive function."
    },
    "answer": "d",
    "explanation": "Option A can be confirmed from the sec ond paragraph. Option B can be inferred from the third paragraph. Option C has been mentioned in the fourth and fifth paragraphs. Option D is irrelevant concerning the greater number of women being diag nosed with dementia. Hence, it is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 21,
    "passage": "  In 2018, Mira Nikolova was at an academic conference in Tucson, Arizona, when it occurred to her: A PhD student is a lot like a saguaro cactus. “The cacti thrive in very challenging conditions in the desert—they blossom with beautiful flowers, and they provide sustenance for pretty much every creature in their ecosystem”, Nikolova said. “PhD students go through challenging and isolating moments—the process is not for the faint of heart. But we have so much potential to make a positive impact, and I think we should give ourselves credit for that”. Nikolova, now wrapping up the sixth and final year of her doctorate in Slavic studies at Brown University, says that the research process can feel solitary even to the most socially engaged graduate students—especially in the time of COVID-19 when social isolation is a universal fact of life. So on Sunday, May 24, when she earns her Brown degree along with 217 other PhD students, she hopes to inspire her classmates to look past today’s isolation and toward tomorrow’s potential. “It’s easy to become overwhelmed by details and lose track of why we’re here,” Nikolova said. “But we have to persevere and remember there are things we can do to positively impact our society and our ecosystem”. Each year, the University’s Graduate Student Council selects one PhD graduate to address the graduating class and their loved ones at the doctoral ceremony during Commencement and Reunion Weekend. Though the COVID-19 pandemic has delayed Commencement from proceeding as planned, the GSC’s tradition lives on: Nikolova, chosen by a panel within the council, will employ her cactus metaphor in an address to her fellow graduates during the Graduate School’s Virtual Degree Conferral ceremony. Nikolova’s affinity for succulent plants dates back to her childhood in Sofia, Bulgaria. Her family’s apartment was too small to accommodate a pet, so she asked her mother if they could keep cacti instead. ‘We still have the cacti at home’, she noted proudly. Nikolova seemed to be headed toward a career in science and technology from an early age: In addition to her early interest in plants, she had chosen to focus on chemistry in high school. But shortly after she began undergraduate studies at Bowdoin College, she surprised everyone—including herself—by pursuing an entirely different area of study. “Going into college, I was looking at neuroscience, art history, English, psychology”, she said. “I had all these interests and ideas, and I was able to explore so many of them— that’s the beauty of a liberal arts education. I ended up discovering classes in Russian and then majoring in Russian”. Nikolova’s passion for Slavic cultures and languages carried her from Bowdoin to Brown, where she had studied the ways in which exiled or condemned Slavic writers depict the condition of physical or social isolation. Her interest in the subject was born from ‘The Condition We Call Exile,’ a 1987 essay by Russian-American poet Joseph Brodsky. “There’s a recording from a conference where he presented this essay, and he’s talking about all kinds of people who live in exile—foreign workers in Germany and the Soviet Union, Mexican refugees in the deserts of Southern California”, she said. “It sends goosebumps down my spine because it feels as if it could have been recorded last year”.",
    "ImageID": "",
    "question": "Which of the following can be inferred from the passage?",
    "options": {
      "a": "Covid 19 did not affect the usual way in which the academic conferences used to happen.",
      "b": "The cactus is a succulent plant. ",
      "c": "Nikolova would have preferred pets to plants had there been enough space in her parent’s house.",
      "d": "Nikolova did not like plants that were not succulent."
    },
    "answer": "b",
    "explanation": "Option A can be cancelled easily, as Covid 19 delayed the Commencement as planned. So, it is clear that it affected the conferences. There is a narrow line between infer ence and assumption. Option C is an assumption. ‘Nikolova’s affinity for succulent plants…’ would mean that Nikolova liked succu lent plants, but it would not mean that she did not like plants that were not succulent. So, option D is incorrect. Nikolova had an affinity for succulent plants, and she kept cacti at home, which clearly means that the cactus is a succulent plant.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 22,
    "passage": "  In 2018, Mira Nikolova was at an academic conference in Tucson, Arizona, when it occurred to her: A PhD student is a lot like a saguaro cactus. “The cacti thrive in very challenging conditions in the desert—they blossom with beautiful flowers, and they provide sustenance for pretty much every creature in their ecosystem”, Nikolova said. “PhD students go through challenging and isolating moments—the process is not for the faint of heart. But we have so much potential to make a positive impact, and I think we should give ourselves credit for that”. Nikolova, now wrapping up the sixth and final year of her doctorate in Slavic studies at Brown University, says that the research process can feel solitary even to the most socially engaged graduate students—especially in the time of COVID-19 when social isolation is a universal fact of life. So on Sunday, May 24, when she earns her Brown degree along with 217 other PhD students, she hopes to inspire her classmates to look past today’s isolation and toward tomorrow’s potential. “It’s easy to become overwhelmed by details and lose track of why we’re here,” Nikolova said. “But we have to persevere and remember there are things we can do to positively impact our society and our ecosystem”. Each year, the University’s Graduate Student Council selects one PhD graduate to address the graduating class and their loved ones at the doctoral ceremony during Commencement and Reunion Weekend. Though the COVID-19 pandemic has delayed Commencement from proceeding as planned, the GSC’s tradition lives on: Nikolova, chosen by a panel within the council, will employ her cactus metaphor in an address to her fellow graduates during the Graduate School’s Virtual Degree Conferral ceremony. Nikolova’s affinity for succulent plants dates back to her childhood in Sofia, Bulgaria. Her family’s apartment was too small to accommodate a pet, so she asked her mother if they could keep cacti instead. ‘We still have the cacti at home’, she noted proudly. Nikolova seemed to be headed toward a career in science and technology from an early age: In addition to her early interest in plants, she had chosen to focus on chemistry in high school. But shortly after she began undergraduate studies at Bowdoin College, she surprised everyone—including herself—by pursuing an entirely different area of study. “Going into college, I was looking at neuroscience, art history, English, psychology”, she said. “I had all these interests and ideas, and I was able to explore so many of them— that’s the beauty of a liberal arts education. I ended up discovering classes in Russian and then majoring in Russian”. Nikolova’s passion for Slavic cultures and languages carried her from Bowdoin to Brown, where she had studied the ways in which exiled or condemned Slavic writers depict the condition of physical or social isolation. Her interest in the subject was born from ‘The Condition We Call Exile,’ a 1987 essay by Russian-American poet Joseph Brodsky. “There’s a recording from a conference where he presented this essay, and he’s talking about all kinds of people who live in exile—foreign workers in Germany and the Soviet Union, Mexican refugees in the deserts of Southern California”, she said. “It sends goosebumps down my spine because it feels as if it could have been recorded last year”.",
    "ImageID": "",
    "question": "Out of the four alternatives given below, which one is most accurate?",
    "options": {
      "a": "Nikolova had a deep interest in neu roscience, art history, English, and psychology.",
      "b": "Nikolova showed affinity toward sci ence and technology, plants, and chemistry.",
      "c": "Nikolova showed interest in science and technology, plants, chemistry, neuroscience, art history, English, and psychology.",
      "d": "Nikolova was deeply interested in Slavic languages and cultures only."
    },
    "answer": "c",
    "explanation": "Option C is the most accurate as it covers all the fields mentioned in the passage. Other options cover only a part of all the f ields that Nikolova was interested in.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 23,
    "passage": "  In 2018, Mira Nikolova was at an academic conference in Tucson, Arizona, when it occurred to her: A PhD student is a lot like a saguaro cactus. “The cacti thrive in very challenging conditions in the desert—they blossom with beautiful flowers, and they provide sustenance for pretty much every creature in their ecosystem”, Nikolova said. “PhD students go through challenging and isolating moments—the process is not for the faint of heart. But we have so much potential to make a positive impact, and I think we should give ourselves credit for that”. Nikolova, now wrapping up the sixth and final year of her doctorate in Slavic studies at Brown University, says that the research process can feel solitary even to the most socially engaged graduate students—especially in the time of COVID-19 when social isolation is a universal fact of life. So on Sunday, May 24, when she earns her Brown degree along with 217 other PhD students, she hopes to inspire her classmates to look past today’s isolation and toward tomorrow’s potential. “It’s easy to become overwhelmed by details and lose track of why we’re here,” Nikolova said. “But we have to persevere and remember there are things we can do to positively impact our society and our ecosystem”. Each year, the University’s Graduate Student Council selects one PhD graduate to address the graduating class and their loved ones at the doctoral ceremony during Commencement and Reunion Weekend. Though the COVID-19 pandemic has delayed Commencement from proceeding as planned, the GSC’s tradition lives on: Nikolova, chosen by a panel within the council, will employ her cactus metaphor in an address to her fellow graduates during the Graduate School’s Virtual Degree Conferral ceremony. Nikolova’s affinity for succulent plants dates back to her childhood in Sofia, Bulgaria. Her family’s apartment was too small to accommodate a pet, so she asked her mother if they could keep cacti instead. ‘We still have the cacti at home’, she noted proudly. Nikolova seemed to be headed toward a career in science and technology from an early age: In addition to her early interest in plants, she had chosen to focus on chemistry in high school. But shortly after she began undergraduate studies at Bowdoin College, she surprised everyone—including herself—by pursuing an entirely different area of study. “Going into college, I was looking at neuroscience, art history, English, psychology”, she said. “I had all these interests and ideas, and I was able to explore so many of them— that’s the beauty of a liberal arts education. I ended up discovering classes in Russian and then majoring in Russian”. Nikolova’s passion for Slavic cultures and languages carried her from Bowdoin to Brown, where she had studied the ways in which exiled or condemned Slavic writers depict the condition of physical or social isolation. Her interest in the subject was born from ‘The Condition We Call Exile,’ a 1987 essay by Russian-American poet Joseph Brodsky. “There’s a recording from a conference where he presented this essay, and he’s talking about all kinds of people who live in exile—foreign workers in Germany and the Soviet Union, Mexican refugees in the deserts of Southern California”, she said. “It sends goosebumps down my spine because it feels as if it could have been recorded last year”.",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "The Slavic writers do not enjoy a f lourishing career.",
      "b": "Nikolova was an enthusiast and a passionate learner.",
      "c": "Socially engaged students are not good candidates for a PhD, as a PhD demands social isolation.",
      "d": "Pursuing a doctorate in Slavic lan guages was not the only career op tion for Nikolova."
    },
    "answer": "c",
    "explanation": "Options B and D are quite easy to infer. The phrase condemned Slavic writers in the second last paragraph suggests what is written in option A. Option C is the correct answer, as it would be an incorrect inference.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 24,
    "passage": "  In 2018, Mira Nikolova was at an academic conference in Tucson, Arizona, when it occurred to her: A PhD student is a lot like a saguaro cactus. “The cacti thrive in very challenging conditions in the desert—they blossom with beautiful flowers, and they provide sustenance for pretty much every creature in their ecosystem”, Nikolova said. “PhD students go through challenging and isolating moments—the process is not for the faint of heart. But we have so much potential to make a positive impact, and I think we should give ourselves credit for that”. Nikolova, now wrapping up the sixth and final year of her doctorate in Slavic studies at Brown University, says that the research process can feel solitary even to the most socially engaged graduate students—especially in the time of COVID-19 when social isolation is a universal fact of life. So on Sunday, May 24, when she earns her Brown degree along with 217 other PhD students, she hopes to inspire her classmates to look past today’s isolation and toward tomorrow’s potential. “It’s easy to become overwhelmed by details and lose track of why we’re here,” Nikolova said. “But we have to persevere and remember there are things we can do to positively impact our society and our ecosystem”. Each year, the University’s Graduate Student Council selects one PhD graduate to address the graduating class and their loved ones at the doctoral ceremony during Commencement and Reunion Weekend. Though the COVID-19 pandemic has delayed Commencement from proceeding as planned, the GSC’s tradition lives on: Nikolova, chosen by a panel within the council, will employ her cactus metaphor in an address to her fellow graduates during the Graduate School’s Virtual Degree Conferral ceremony. Nikolova’s affinity for succulent plants dates back to her childhood in Sofia, Bulgaria. Her family’s apartment was too small to accommodate a pet, so she asked her mother if they could keep cacti instead. ‘We still have the cacti at home’, she noted proudly. Nikolova seemed to be headed toward a career in science and technology from an early age: In addition to her early interest in plants, she had chosen to focus on chemistry in high school. But shortly after she began undergraduate studies at Bowdoin College, she surprised everyone—including herself—by pursuing an entirely different area of study. “Going into college, I was looking at neuroscience, art history, English, psychology”, she said. “I had all these interests and ideas, and I was able to explore so many of them— that’s the beauty of a liberal arts education. I ended up discovering classes in Russian and then majoring in Russian”. Nikolova’s passion for Slavic cultures and languages carried her from Bowdoin to Brown, where she had studied the ways in which exiled or condemned Slavic writers depict the condition of physical or social isolation. Her interest in the subject was born from ‘The Condition We Call Exile,’ a 1987 essay by Russian-American poet Joseph Brodsky. “There’s a recording from a conference where he presented this essay, and he’s talking about all kinds of people who live in exile—foreign workers in Germany and the Soviet Union, Mexican refugees in the deserts of Southern California”, she said. “It sends goosebumps down my spine because it feels as if it could have been recorded last year”.",
    "ImageID": "",
    "question": "Nikolova thinks that a PhD student is a lot like a saguaro cactus:",
    "options": {
      "a": "Because a PhD student, like a cactus, lives an isolated life.",
      "b": "Because like cacti, a PhD student also thrives in challenging condi tions and yet provides sustenance for others.",
      "c": "Because a PhD student is as succu lent as a cactus and he blossoms with beautiful flowers like cacti.",
      "d": "Because Nikolova loved cacti and she wanted to coin a Cactus met aphor to display her affection for cactus."
    },
    "answer": "b",
    "explanation": "Nikolova has used the metaphor to com pare similar and positive traits between a cactus and a PhD student. Option B captures that essence perfectly. Hence option B is the correct answer. Option A conveys the negative side and doesn’t serve the purpose of comparison. Option C is meaningless and option D would be a negative reason, which can’t be true considering Nikolova’s character and personality.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 25,
    "passage": "  Asia is not a predefined fixity; Asia is a journey of co-realisation and pluralisation. Similarly, social theory is not unitary; it is a plural process of reflection on the dynamics of self, culture, and society. But much of social theory as it rules in the academic corridors of Europe, Asia, and the world is Eurocentric. But now, there is an epochal need for realizing social theories as parts of planetary conversations. While some may look at it in terms of the rise of Asia and the decline of Euro-America, our challenge here is not to replace one ethnocentrism and exclusivism with another but to make social theory a field of mutual learning and dialogue of presuppositions. Dominant social theories coming from the West have their own presuppositions, for example, the presupposition about the centrality of power in Weber and Foucault and its justification and application in varieties of critical theory such as that of Jurgen Habermas. But these presuppositions are not universally shared as reigning presuppositions of self, culture, and society. For example, in the Srimad Bhagavadgita, a text in spiritual traditions of India, it is written, ‘Sradhha Maya Ayam Purusha Jo Jat Sraddha Sa Ebasa: This Purusha (the human person) is characterised by sraddha -capacity for love and reverence—; one is what one loves or reveres.’ These lines also offer some presuppositions about self, culture, and society and urge us to realise that it is not only power but also sraddha (reverence or love) which characterises being human in the fields of self, culture, and society. For a fuller realisation of social theory, there need to be dialogues between presuppositions of power and sraddha as important elements in the dynamic of self, culture, and society rather than one-sided assertion and exclusion. We need to open classical and contemporary social theories which are predominantly  Euro-American to multiple dialogues such as Asian dialogues, which then become part of planetary conversations. In planetary conversations, we take part in dialogues without privileging our apriori ethnocentric points of view and open ourselves, our locational insights and presuppositions, to mutual interpenetration, sharing, questioning, and transformations. While much of the East-West dialogue is still imprisoned within the existing logic of apriori fixation and unconscious colonial constitution of our globe, planetary conversations seek to transform these into conditions of mutual dialogues and interpenetration of presuppositions. With this brief prelude, we can begin this dialogue with the concept of the self. In Asian countries, there is a notion of self as a field. This field is not static but dynamic. It is a field of flows of many rivers and streams. Our self is like the rice field. It is a field where chi, dynamic energy, flows. From both the Confucian traditions as well as Kashmiri Saivism we get a view of dynamic energy and consciousness. Recent social theory coming from scholars such as Pierre Bourdieu also emphasises the significance of field in understanding society. At the same time, Srimad Bhagavad Gita also talks about the yoga of the field and the knower of the field. While Bourdieu’s conception of field is primarily socio-political in the Gita, the concept of the field, as well as the knower of the field, is socio-psychological as well as socio-spiritual. It is enriching here to have mutually transforming dialogues between these conceptions of the field and thus deepen our conceptions and realisations of self, culture, and society as fields. Self is neither a peak nor a cliff. In individualism, the self is looked at as a cliff. But in Asian traditions and cultures, there is a relational view of self which is, at the same time, ecological and transcendental. Self is the meeting point of the horizontal and the vertical. ",
    "ImageID": "",
    "question": "Individualism is at the root of modern social theory and society. But dialogues with Asian traditions help us realise the trans-indi vidual dimension of individuals as also a trans-social dimension of society. In his dis cussion of the work of Thai social thinker and Buddhist social theorist, Sulak Sivaraksha, John Clammer tells us that Sivaraksha helps us understand that individuals have a trans-individual dimension. In the words of Clammer: “In much the same way that Louis Dumont has argued that Western in dividualism has its roots in Christianity and that the consequences of this individual ism are profound for the arrangement of society and assumptions about how rela tionships within it work, so Sulak is arguing for a ‘trans-individualism’ that arises from Buddhist roots, and which has profound implications for the ordering of society”. In modern Western society and modern so ciology, both individuals and society are conceptualised and realised in isolation of Nature and transcendence, they are impris oned in isolated black boxes; what Dallmayr calls ‘Enlightenment black boxes.’ Dialogues with Asian traditions enable social theory to conceptualise and realise individuals and societies as at the same time part of Nature and transcendence. There are also streams in Western traditions which look at indi viduals and societies in relationship with Nature and Transcendence, but modern so cial theory has not nurtured itself with such streams of vision and practice. For exam ple, in Goethe, we would find ways of go ing beyond the modern Enlightenment black box and realise self and society as part of Nature and Transcendence, but modern so ciology has followed Newton rather than Goethe. But border-crossing dialogues can contribute to memory work; for example, dialogue between modern social theory and Asian traditions of practices and reflections can contribute to creative memory work and retrieval of traditions of non-dualistic relationships between individual/society and nature and transcendence. What is the theme of the first paragraph of the passage?",
    "options": {
      "a": "Social theory is not unitary; it is a plural process of reflection on the dynamics of self, culture, and society.",
      "b": "European presuppositions are pow er-centric, while Asian presupposi tions are self-centric.",
      "c": "Social theory in the academic corri dors of Europe is that Asia and the world are Eurocentric.",
      "d": "There is a need for realising so cial theories as parts of planetary conversations."
    },
    "answer": "d",
    "explanation": "A theme is the main subject of discus sion, the author’s main point. In the first paragraph, the author asserts the need for dialogue between presuppositions of Europe and Asia. He mentions the need for dialogue twice in the passage. One such form is written in option D. Hence, option D is correct. Options A, B, and C are the reasons why there is a need for dialogue. They won’t serve as a suitable theme for the first paragraph.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 26,
    "passage": "  Asia is not a predefined fixity; Asia is a journey of co-realisation and pluralisation. Similarly, social theory is not unitary; it is a plural process of reflection on the dynamics of self, culture, and society. But much of social theory as it rules in the academic corridors of Europe, Asia, and the world is Eurocentric. But now, there is an epochal need for realizing social theories as parts of planetary conversations. While some may look at it in terms of the rise of Asia and the decline of Euro-America, our challenge here is not to replace one ethnocentrism and exclusivism with another but to make social theory a field of mutual learning and dialogue of presuppositions. Dominant social theories coming from the West have their own presuppositions, for example, the presupposition about the centrality of power in Weber and Foucault and its justification and application in varieties of critical theory such as that of Jurgen Habermas. But these presuppositions are not universally shared as reigning presuppositions of self, culture, and society. For example, in the Srimad Bhagavadgita, a text in spiritual traditions of India, it is written, ‘Sradhha Maya Ayam Purusha Jo Jat Sraddha Sa Ebasa: This Purusha (the human person) is characterised by sraddha -capacity for love and reverence—; one is what one loves or reveres.’ These lines also offer some presuppositions about self, culture, and society and urge us to realise that it is not only power but also sraddha (reverence or love) which characterises being human in the fields of self, culture, and society. For a fuller realisation of social theory, there need to be dialogues between presuppositions of power and sraddha as important elements in the dynamic of self, culture, and society rather than one-sided assertion and exclusion. We need to open classical and contemporary social theories which are predominantly  Euro-American to multiple dialogues such as Asian dialogues, which then become part of planetary conversations. In planetary conversations, we take part in dialogues without privileging our apriori ethnocentric points of view and open ourselves, our locational insights and presuppositions, to mutual interpenetration, sharing, questioning, and transformations. While much of the East-West dialogue is still imprisoned within the existing logic of apriori fixation and unconscious colonial constitution of our globe, planetary conversations seek to transform these into conditions of mutual dialogues and interpenetration of presuppositions. With this brief prelude, we can begin this dialogue with the concept of the self. In Asian countries, there is a notion of self as a field. This field is not static but dynamic. It is a field of flows of many rivers and streams. Our self is like the rice field. It is a field where chi, dynamic energy, flows. From both the Confucian traditions as well as Kashmiri Saivism we get a view of dynamic energy and consciousness. Recent social theory coming from scholars such as Pierre Bourdieu also emphasises the significance of field in understanding society. At the same time, Srimad Bhagavad Gita also talks about the yoga of the field and the knower of the field. While Bourdieu’s conception of field is primarily socio-political in the Gita, the concept of the field, as well as the knower of the field, is socio-psychological as well as socio-spiritual. It is enriching here to have mutually transforming dialogues between these conceptions of the field and thus deepen our conceptions and realisations of self, culture, and society as fields. Self is neither a peak nor a cliff. In individualism, the self is looked at as a cliff. But in Asian traditions and cultures, there is a relational view of self which is, at the same time, ecological and transcendental. Self is the meeting point of the horizontal and the vertical. ",
    "ImageID": "",
    "question": "The author makes all the points in the passage, except:",
    "options": {
      "a": "Classical and contemporary social theories should be open to multi ple dialogues and be incorporated as planetary conversations.",
      "b": "In planetary conversations, East and West should open themselves, their locational insights and pre suppositions, to mutual interpen etration, sharing, questioning, and transformations.",
      "c": "In planetary conversations, East and West should open dialogues while privileging their apriori ethnocentric points of view.",
      "d": "Much of the East-West dialogue today is imprisoned within the unconscious colonial constitution of our globe."
    },
    "answer": "c",
    "explanation": "In the second paragraph of the passage, the author has made the points men tioned in options A, B, and D. Option C is the opposite of what the au thor has said. Hence, option C is the cor rect answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 27,
    "passage": "  Asia is not a predefined fixity; Asia is a journey of co-realisation and pluralisation. Similarly, social theory is not unitary; it is a plural process of reflection on the dynamics of self, culture, and society. But much of social theory as it rules in the academic corridors of Europe, Asia, and the world is Eurocentric. But now, there is an epochal need for realizing social theories as parts of planetary conversations. While some may look at it in terms of the rise of Asia and the decline of Euro-America, our challenge here is not to replace one ethnocentrism and exclusivism with another but to make social theory a field of mutual learning and dialogue of presuppositions. Dominant social theories coming from the West have their own presuppositions, for example, the presupposition about the centrality of power in Weber and Foucault and its justification and application in varieties of critical theory such as that of Jurgen Habermas. But these presuppositions are not universally shared as reigning presuppositions of self, culture, and society. For example, in the Srimad Bhagavadgita, a text in spiritual traditions of India, it is written, ‘Sradhha Maya Ayam Purusha Jo Jat Sraddha Sa Ebasa: This Purusha (the human person) is characterised by sraddha -capacity for love and reverence—; one is what one loves or reveres.’ These lines also offer some presuppositions about self, culture, and society and urge us to realise that it is not only power but also sraddha (reverence or love) which characterises being human in the fields of self, culture, and society. For a fuller realisation of social theory, there need to be dialogues between presuppositions of power and sraddha as important elements in the dynamic of self, culture, and society rather than one-sided assertion and exclusion. We need to open classical and contemporary social theories which are predominantly  Euro-American to multiple dialogues such as Asian dialogues, which then become part of planetary conversations. In planetary conversations, we take part in dialogues without privileging our apriori ethnocentric points of view and open ourselves, our locational insights and presuppositions, to mutual interpenetration, sharing, questioning, and transformations. While much of the East-West dialogue is still imprisoned within the existing logic of apriori fixation and unconscious colonial constitution of our globe, planetary conversations seek to transform these into conditions of mutual dialogues and interpenetration of presuppositions. With this brief prelude, we can begin this dialogue with the concept of the self. In Asian countries, there is a notion of self as a field. This field is not static but dynamic. It is a field of flows of many rivers and streams. Our self is like the rice field. It is a field where chi, dynamic energy, flows. From both the Confucian traditions as well as Kashmiri Saivism we get a view of dynamic energy and consciousness. Recent social theory coming from scholars such as Pierre Bourdieu also emphasises the significance of field in understanding society. At the same time, Srimad Bhagavad Gita also talks about the yoga of the field and the knower of the field. While Bourdieu’s conception of field is primarily socio-political in the Gita, the concept of the field, as well as the knower of the field, is socio-psychological as well as socio-spiritual. It is enriching here to have mutually transforming dialogues between these conceptions of the field and thus deepen our conceptions and realisations of self, culture, and society as fields. Self is neither a peak nor a cliff. In individualism, the self is looked at as a cliff. But in Asian traditions and cultures, there is a relational view of self which is, at the same time, ecological and transcendental. Self is the meeting point of the horizontal and the vertical. ",
    "ImageID": "",
    "question": "The author begins the third paragraph with—‘With this brief prelude…’—what can be understood about the prelude?",
    "options": {
      "a": "East and West should indulge in dialogues without any prejudic es and open their insights and pre suppositions to mutual interpen etration, sharing, questioning, and transformations.",
      "b": "Much of the East-West dialogue is still imprisoned within the existing logic of apriori fixation and the un conscious colonial constitution of our globe. ",
      "c": "Dominant social theories of the West and East need to confront each other, and the predominant Euro American social theories should give way to Eastern social theories.",
      "d": "Western presuppositions are pow er-centric, while eastern presuppo sitions are self-centric."
    },
    "answer": "a",
    "explanation": "In other words, the question is asking the summary of the first two paragraphs. And in the light of that prelude, the author wants a global and inclusive dialogue be tween East and West. Now, only option A contains the elements of the message that the author wanted to convey. Hence, option A is the correct answer. Options B and C serve as distractions. Option D is out of context and doesn’t cover the scope of the question.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 28,
    "passage": "  Asia is not a predefined fixity; Asia is a journey of co-realisation and pluralisation. Similarly, social theory is not unitary; it is a plural process of reflection on the dynamics of self, culture, and society. But much of social theory as it rules in the academic corridors of Europe, Asia, and the world is Eurocentric. But now, there is an epochal need for realizing social theories as parts of planetary conversations. While some may look at it in terms of the rise of Asia and the decline of Euro-America, our challenge here is not to replace one ethnocentrism and exclusivism with another but to make social theory a field of mutual learning and dialogue of presuppositions. Dominant social theories coming from the West have their own presuppositions, for example, the presupposition about the centrality of power in Weber and Foucault and its justification and application in varieties of critical theory such as that of Jurgen Habermas. But these presuppositions are not universally shared as reigning presuppositions of self, culture, and society. For example, in the Srimad Bhagavadgita, a text in spiritual traditions of India, it is written, ‘Sradhha Maya Ayam Purusha Jo Jat Sraddha Sa Ebasa: This Purusha (the human person) is characterised by sraddha -capacity for love and reverence—; one is what one loves or reveres.’ These lines also offer some presuppositions about self, culture, and society and urge us to realise that it is not only power but also sraddha (reverence or love) which characterises being human in the fields of self, culture, and society. For a fuller realisation of social theory, there need to be dialogues between presuppositions of power and sraddha as important elements in the dynamic of self, culture, and society rather than one-sided assertion and exclusion. We need to open classical and contemporary social theories which are predominantly  Euro-American to multiple dialogues such as Asian dialogues, which then become part of planetary conversations. In planetary conversations, we take part in dialogues without privileging our apriori ethnocentric points of view and open ourselves, our locational insights and presuppositions, to mutual interpenetration, sharing, questioning, and transformations. While much of the East-West dialogue is still imprisoned within the existing logic of apriori fixation and unconscious colonial constitution of our globe, planetary conversations seek to transform these into conditions of mutual dialogues and interpenetration of presuppositions. With this brief prelude, we can begin this dialogue with the concept of the self. In Asian countries, there is a notion of self as a field. This field is not static but dynamic. It is a field of flows of many rivers and streams. Our self is like the rice field. It is a field where chi, dynamic energy, flows. From both the Confucian traditions as well as Kashmiri Saivism we get a view of dynamic energy and consciousness. Recent social theory coming from scholars such as Pierre Bourdieu also emphasises the significance of field in understanding society. At the same time, Srimad Bhagavad Gita also talks about the yoga of the field and the knower of the field. While Bourdieu’s conception of field is primarily socio-political in the Gita, the concept of the field, as well as the knower of the field, is socio-psychological as well as socio-spiritual. It is enriching here to have mutually transforming dialogues between these conceptions of the field and thus deepen our conceptions and realisations of self, culture, and society as fields. Self is neither a peak nor a cliff. In individualism, the self is looked at as a cliff. But in Asian traditions and cultures, there is a relational view of self which is, at the same time, ecological and transcendental. Self is the meeting point of the horizontal and the vertical. ",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "Western thinkers put individualism at the centre of their philosophy, while Asian thinkers put the concept of trans-individualism at the centre of their philosophy.",
      "b": "In Western sociology, individuals and society are conceptualised in isolation of Nature and transcend ence, while Eastern sociologists conceptualise and realise individuals and societies as part of Nature and transcendence.",
      "c": "Goethe’s sociology was similar to that of Sulak’s.",
      "d": "Louis Dumont and Sulak have given similar theories regarding the order ing of society."
    },
    "answer": "d",
    "explanation": "From the last paragraph of the passage, options A and C can be inferred. Option B is almost directly written in the last para. Option D is the correct answer here as it would be a wrong inference. Louis Dumont focused on individualism, while Sulak focused on trans-individualism in his philosophy.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 29,
    "passage": "  Asia is not a predefined fixity; Asia is a journey of co-realisation and pluralisation. Similarly, social theory is not unitary; it is a plural process of reflection on the dynamics of self, culture, and society. But much of social theory as it rules in the academic corridors of Europe, Asia, and the world is Eurocentric. But now, there is an epochal need for realizing social theories as parts of planetary conversations. While some may look at it in terms of the rise of Asia and the decline of Euro-America, our challenge here is not to replace one ethnocentrism and exclusivism with another but to make social theory a field of mutual learning and dialogue of presuppositions. Dominant social theories coming from the West have their own presuppositions, for example, the presupposition about the centrality of power in Weber and Foucault and its justification and application in varieties of critical theory such as that of Jurgen Habermas. But these presuppositions are not universally shared as reigning presuppositions of self, culture, and society. For example, in the Srimad Bhagavadgita, a text in spiritual traditions of India, it is written, ‘Sradhha Maya Ayam Purusha Jo Jat Sraddha Sa Ebasa: This Purusha (the human person) is characterised by sraddha -capacity for love and reverence—; one is what one loves or reveres.’ These lines also offer some presuppositions about self, culture, and society and urge us to realise that it is not only power but also sraddha (reverence or love) which characterises being human in the fields of self, culture, and society. For a fuller realisation of social theory, there need to be dialogues between presuppositions of power and sraddha as important elements in the dynamic of self, culture, and society rather than one-sided assertion and exclusion. We need to open classical and contemporary social theories which are predominantly  Euro-American to multiple dialogues such as Asian dialogues, which then become part of planetary conversations. In planetary conversations, we take part in dialogues without privileging our apriori ethnocentric points of view and open ourselves, our locational insights and presuppositions, to mutual interpenetration, sharing, questioning, and transformations. While much of the East-West dialogue is still imprisoned within the existing logic of apriori fixation and unconscious colonial constitution of our globe, planetary conversations seek to transform these into conditions of mutual dialogues and interpenetration of presuppositions. With this brief prelude, we can begin this dialogue with the concept of the self. In Asian countries, there is a notion of self as a field. This field is not static but dynamic. It is a field of flows of many rivers and streams. Our self is like the rice field. It is a field where chi, dynamic energy, flows. From both the Confucian traditions as well as Kashmiri Saivism we get a view of dynamic energy and consciousness. Recent social theory coming from scholars such as Pierre Bourdieu also emphasises the significance of field in understanding society. At the same time, Srimad Bhagavad Gita also talks about the yoga of the field and the knower of the field. While Bourdieu’s conception of field is primarily socio-political in the Gita, the concept of the field, as well as the knower of the field, is socio-psychological as well as socio-spiritual. It is enriching here to have mutually transforming dialogues between these conceptions of the field and thus deepen our conceptions and realisations of self, culture, and society as fields. Self is neither a peak nor a cliff. In individualism, the self is looked at as a cliff. But in Asian traditions and cultures, there is a relational view of self which is, at the same time, ecological and transcendental. Self is the meeting point of the horizontal and the vertical. ",
    "ImageID": "",
    "question": "‘Self is neither a peak nor a cliff’ (second last para)—what could be the best ex planation for this sentence?",
    "options": {
      "a": "Self is not an end in itself.",
      "b": "Realisation of self is neither an achievement nor an obstruction.",
      "c": "Self is the meeting point of the hori zontal and the vertical.",
      "d": "Individualism is worldly, while trans- individualism is transcendental."
    },
    "answer": "b",
    "explanation": "The author explains the importance of the concept of self/individualism in western and eastern cultures. Then he explains how it has been treated differ ently by Asian sociologists. Option B here is the most suitable expla nation of the sentence. Option A is an incomplete definition. Option C is a distraction. Option D is irrelevant.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 30,
    "passage": "  For an empire that collapsed more than 1,500 years ago, ancient Rome maintains a powerful presence. About 1 billion people speak languages derived from Latin; Roman law shapes modern norms; and Roman architecture has been widely imitated. Christianity, which the empire embraced in its sunset years, remains the world’s largest religion. Yet all these enduring influences pale against Rome’s most important legacy: its fall. Had its empire not unravelled, or had it been replaced by a similarly overpowering successor, the world wouldn’t have become modern. This isn’t the way that we ordinarily think about an event that has been lamented pretty much ever since it happened. In the late 18th century, in his monumental work The History of the Decline and Fall of the Roman Empire (1776–1788), the British historian Edward Gibbon called it ‘the greatest, perhaps, and the most awful scene in the history of mankind’. Tankloads of ink have been expended on explaining it. Back in 1984, the German historian Alexander Demandt patiently compiled no fewer than 210 different reasons for Rome’s demise that had been put forward over time. And the flood of books and papers shows no sign of abating: most recently, disease and climate change have been pressed into service. Wouldn’t only a calamity of the first order warrant this kind of attention? It’s true that Rome’s collapse reverberated widely, at least in the western—mostly European—half of its empire. (A shrinking portion of the eastern half, later known as Byzantium, survived for another millennium.) Although some regions were harder hit than others, none escaped unscathed. Monumental structures fell into disrepair; previously thriving cities emptied out; Rome itself turned into a shadow of its former grand self, with shepherds tending their  flocks among the ruins. Trade and coin use thinned out, and the art of writing retreated. Population numbers plummeted. But a few benefits were already being felt at the time. Roman power had fostered immense inequality: its collapse brought down the plutocratic ruling class, releasing the labouring masses from oppressive exploitation. The new Germanic rulers operated with lower overheads and proved less adept at collecting rents and taxes. Forensic archaeology reveals that people grew to be taller, likely thanks to reduced inequality, a better diet, and lower disease loads. Yet these changes didn’t last. The real payoff of Rome’s demise took much longer to emerge. When Goths, Vandals, Franks, Lombards, and Anglo-Saxons carved up the empire, they broke the imperial order so thoroughly that it never returned. Their fifth-century takeover was only the beginning: in a very real sense, Rome’s decline continued well after its fall—turning Gibbon’s title on its head. When the Germans took charge, they initially relied on Roman institutions of governance to run their new kingdoms. But they did a poor job of maintaining that vital infrastructure. Before long, nobles and warriors made themselves at home on the lands whose yield kings had assigned to them. While these relieved rulers of the onerous need to count and tax the peasantry, it also starved them of revenue and made it harder for them to control their supporters. When, in the year 800, the Frankish king Charlemagne decided that he was a new Roman emperor, it was already too late. In the following centuries, royal power declined as aristocrats asserted ever greater autonomy and knights set up their own castles. The Holy Roman Empire, established in Germany and northern Italy in 962, never properly functioned as a unified state. For much of the Middle Ages, power was widely dispersed among different groups. Kings claimed political supremacy but often found it hard to exercise control beyond their own domains. Reading Comprehension – Basic LevelNobles and their armed vassals wielded the bulk of military power. The Catholic Church, increasingly centralised under an ascendant papacy, had a lock on the dominant belief system. Bishops and abbots cooperated with secular authorities, but carefully guarded their prerogatives. Economic power was concentrated among feudal lords and in autonomous cities dominated by assertive associations of artisans and merchants.",
    "ImageID": "",
    "question": "The author considers the fall of the Roman Empire:",
    "options": {
      "a": "A boon in disguise.",
      "b": "A calamity of the first order.",
      "c": "A natural course of history.",
      "d": "The end of the persecutions of the Roman Emperors."
    },
    "answer": "a",
    "explanation": "After reading the first passage and un derstanding the tone and flow of the passage, it becomes obvious that the author considers the fall of the Roman Empire a boon in disguise as it paved the way for the modern world. Option B represents the view of other historians. Option C is out of the scope of the passage. Option D was just an outcome of the fall of the Roman Empire.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 31,
    "passage": "  For an empire that collapsed more than 1,500 years ago, ancient Rome maintains a powerful presence. About 1 billion people speak languages derived from Latin; Roman law shapes modern norms; and Roman architecture has been widely imitated. Christianity, which the empire embraced in its sunset years, remains the world’s largest religion. Yet all these enduring influences pale against Rome’s most important legacy: its fall. Had its empire not unravelled, or had it been replaced by a similarly overpowering successor, the world wouldn’t have become modern. This isn’t the way that we ordinarily think about an event that has been lamented pretty much ever since it happened. In the late 18th century, in his monumental work The History of the Decline and Fall of the Roman Empire (1776–1788), the British historian Edward Gibbon called it ‘the greatest, perhaps, and the most awful scene in the history of mankind’. Tankloads of ink have been expended on explaining it. Back in 1984, the German historian Alexander Demandt patiently compiled no fewer than 210 different reasons for Rome’s demise that had been put forward over time. And the flood of books and papers shows no sign of abating: most recently, disease and climate change have been pressed into service. Wouldn’t only a calamity of the first order warrant this kind of attention? It’s true that Rome’s collapse reverberated widely, at least in the western—mostly European—half of its empire. (A shrinking portion of the eastern half, later known as Byzantium, survived for another millennium.) Although some regions were harder hit than others, none escaped unscathed. Monumental structures fell into disrepair; previously thriving cities emptied out; Rome itself turned into a shadow of its former grand self, with shepherds tending their  flocks among the ruins. Trade and coin use thinned out, and the art of writing retreated. Population numbers plummeted. But a few benefits were already being felt at the time. Roman power had fostered immense inequality: its collapse brought down the plutocratic ruling class, releasing the labouring masses from oppressive exploitation. The new Germanic rulers operated with lower overheads and proved less adept at collecting rents and taxes. Forensic archaeology reveals that people grew to be taller, likely thanks to reduced inequality, a better diet, and lower disease loads. Yet these changes didn’t last. The real payoff of Rome’s demise took much longer to emerge. When Goths, Vandals, Franks, Lombards, and Anglo-Saxons carved up the empire, they broke the imperial order so thoroughly that it never returned. Their fifth-century takeover was only the beginning: in a very real sense, Rome’s decline continued well after its fall—turning Gibbon’s title on its head. When the Germans took charge, they initially relied on Roman institutions of governance to run their new kingdoms. But they did a poor job of maintaining that vital infrastructure. Before long, nobles and warriors made themselves at home on the lands whose yield kings had assigned to them. While these relieved rulers of the onerous need to count and tax the peasantry, it also starved them of revenue and made it harder for them to control their supporters. When, in the year 800, the Frankish king Charlemagne decided that he was a new Roman emperor, it was already too late. In the following centuries, royal power declined as aristocrats asserted ever greater autonomy and knights set up their own castles. The Holy Roman Empire, established in Germany and northern Italy in 962, never properly functioned as a unified state. For much of the Middle Ages, power was widely dispersed among different groups. Kings claimed political supremacy but often found it hard to exercise control beyond their own domains. Reading Comprehension – Basic LevelNobles and their armed vassals wielded the bulk of military power. The Catholic Church, increasingly centralised under an ascendant papacy, had a lock on the dominant belief system. Bishops and abbots cooperated with secular authorities, but carefully guarded their prerogatives. Economic power was concentrated among feudal lords and in autonomous cities dominated by assertive associations of artisans and merchants.",
    "ImageID": "",
    "question": "The author has discussed all of the fol lowing in the passage, except:",
    "options": {
      "a": "Ramifications of the fall of the Roman Empire.",
      "b": "Reasons behind the fall of the Roman Empire.",
      "c": "The emergence of new ruling powers after the fall of the Roman Empire.",
      "d": "Inefficient Roman emperors in later years."
    },
    "answer": "b",
    "explanation": "The author has discussed the ramifica tions in the first and fourth paragraphs of the passage. The emergence of new ruling power has been discussed in the f ifth paragraph. And inefficient Roman emperors have been discussed in the last paragraph of the passage. Only the reasons behind the fall of the Roman Empire have not been discussed in the passage; so option B is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 32,
    "passage": "  For an empire that collapsed more than 1,500 years ago, ancient Rome maintains a powerful presence. About 1 billion people speak languages derived from Latin; Roman law shapes modern norms; and Roman architecture has been widely imitated. Christianity, which the empire embraced in its sunset years, remains the world’s largest religion. Yet all these enduring influences pale against Rome’s most important legacy: its fall. Had its empire not unravelled, or had it been replaced by a similarly overpowering successor, the world wouldn’t have become modern. This isn’t the way that we ordinarily think about an event that has been lamented pretty much ever since it happened. In the late 18th century, in his monumental work The History of the Decline and Fall of the Roman Empire (1776–1788), the British historian Edward Gibbon called it ‘the greatest, perhaps, and the most awful scene in the history of mankind’. Tankloads of ink have been expended on explaining it. Back in 1984, the German historian Alexander Demandt patiently compiled no fewer than 210 different reasons for Rome’s demise that had been put forward over time. And the flood of books and papers shows no sign of abating: most recently, disease and climate change have been pressed into service. Wouldn’t only a calamity of the first order warrant this kind of attention? It’s true that Rome’s collapse reverberated widely, at least in the western—mostly European—half of its empire. (A shrinking portion of the eastern half, later known as Byzantium, survived for another millennium.) Although some regions were harder hit than others, none escaped unscathed. Monumental structures fell into disrepair; previously thriving cities emptied out; Rome itself turned into a shadow of its former grand self, with shepherds tending their  flocks among the ruins. Trade and coin use thinned out, and the art of writing retreated. Population numbers plummeted. But a few benefits were already being felt at the time. Roman power had fostered immense inequality: its collapse brought down the plutocratic ruling class, releasing the labouring masses from oppressive exploitation. The new Germanic rulers operated with lower overheads and proved less adept at collecting rents and taxes. Forensic archaeology reveals that people grew to be taller, likely thanks to reduced inequality, a better diet, and lower disease loads. Yet these changes didn’t last. The real payoff of Rome’s demise took much longer to emerge. When Goths, Vandals, Franks, Lombards, and Anglo-Saxons carved up the empire, they broke the imperial order so thoroughly that it never returned. Their fifth-century takeover was only the beginning: in a very real sense, Rome’s decline continued well after its fall—turning Gibbon’s title on its head. When the Germans took charge, they initially relied on Roman institutions of governance to run their new kingdoms. But they did a poor job of maintaining that vital infrastructure. Before long, nobles and warriors made themselves at home on the lands whose yield kings had assigned to them. While these relieved rulers of the onerous need to count and tax the peasantry, it also starved them of revenue and made it harder for them to control their supporters. When, in the year 800, the Frankish king Charlemagne decided that he was a new Roman emperor, it was already too late. In the following centuries, royal power declined as aristocrats asserted ever greater autonomy and knights set up their own castles. The Holy Roman Empire, established in Germany and northern Italy in 962, never properly functioned as a unified state. For much of the Middle Ages, power was widely dispersed among different groups. Kings claimed political supremacy but often found it hard to exercise control beyond their own domains. Reading Comprehension – Basic LevelNobles and their armed vassals wielded the bulk of military power. The Catholic Church, increasingly centralised under an ascendant papacy, had a lock on the dominant belief system. Bishops and abbots cooperated with secular authorities, but carefully guarded their prerogatives. Economic power was concentrated among feudal lords and in autonomous cities dominated by assertive associations of artisans and merchants.",
    "ImageID": "",
    "question": "In the first sentence of the second para graph, the author says, “This isn’t the way that we ordinarily think about an event that has been lamented pretty much ever since it happened”.—What way of thinking is the author referring to here?",
    "options": {
      "a": "We don’t usually ridicule such tragic events.",
      "b": "We don’t usually call such tragic events grand.",
      "c": "We don’t usually discuss the positive sides of such tragic events.",
      "d": "We usually lament excessively over such tragic events."
    },
    "answer": "c",
    "explanation": "In the first paragraph of the passage, the author has highlighted the positive as pects of the fall of the Roman Empire. So, he continues by saying that ordinar ily, we don’t think about the positive as pects of such tragic events. Rather we spend all the time lamenting over them. Hence, option C is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 33,
    "passage": "  For an empire that collapsed more than 1,500 years ago, ancient Rome maintains a powerful presence. About 1 billion people speak languages derived from Latin; Roman law shapes modern norms; and Roman architecture has been widely imitated. Christianity, which the empire embraced in its sunset years, remains the world’s largest religion. Yet all these enduring influences pale against Rome’s most important legacy: its fall. Had its empire not unravelled, or had it been replaced by a similarly overpowering successor, the world wouldn’t have become modern. This isn’t the way that we ordinarily think about an event that has been lamented pretty much ever since it happened. In the late 18th century, in his monumental work The History of the Decline and Fall of the Roman Empire (1776–1788), the British historian Edward Gibbon called it ‘the greatest, perhaps, and the most awful scene in the history of mankind’. Tankloads of ink have been expended on explaining it. Back in 1984, the German historian Alexander Demandt patiently compiled no fewer than 210 different reasons for Rome’s demise that had been put forward over time. And the flood of books and papers shows no sign of abating: most recently, disease and climate change have been pressed into service. Wouldn’t only a calamity of the first order warrant this kind of attention? It’s true that Rome’s collapse reverberated widely, at least in the western—mostly European—half of its empire. (A shrinking portion of the eastern half, later known as Byzantium, survived for another millennium.) Although some regions were harder hit than others, none escaped unscathed. Monumental structures fell into disrepair; previously thriving cities emptied out; Rome itself turned into a shadow of its former grand self, with shepherds tending their  flocks among the ruins. Trade and coin use thinned out, and the art of writing retreated. Population numbers plummeted. But a few benefits were already being felt at the time. Roman power had fostered immense inequality: its collapse brought down the plutocratic ruling class, releasing the labouring masses from oppressive exploitation. The new Germanic rulers operated with lower overheads and proved less adept at collecting rents and taxes. Forensic archaeology reveals that people grew to be taller, likely thanks to reduced inequality, a better diet, and lower disease loads. Yet these changes didn’t last. The real payoff of Rome’s demise took much longer to emerge. When Goths, Vandals, Franks, Lombards, and Anglo-Saxons carved up the empire, they broke the imperial order so thoroughly that it never returned. Their fifth-century takeover was only the beginning: in a very real sense, Rome’s decline continued well after its fall—turning Gibbon’s title on its head. When the Germans took charge, they initially relied on Roman institutions of governance to run their new kingdoms. But they did a poor job of maintaining that vital infrastructure. Before long, nobles and warriors made themselves at home on the lands whose yield kings had assigned to them. While these relieved rulers of the onerous need to count and tax the peasantry, it also starved them of revenue and made it harder for them to control their supporters. When, in the year 800, the Frankish king Charlemagne decided that he was a new Roman emperor, it was already too late. In the following centuries, royal power declined as aristocrats asserted ever greater autonomy and knights set up their own castles. The Holy Roman Empire, established in Germany and northern Italy in 962, never properly functioned as a unified state. For much of the Middle Ages, power was widely dispersed among different groups. Kings claimed political supremacy but often found it hard to exercise control beyond their own domains. Reading Comprehension – Basic LevelNobles and their armed vassals wielded the bulk of military power. The Catholic Church, increasingly centralised under an ascendant papacy, had a lock on the dominant belief system. Bishops and abbots cooperated with secular authorities, but carefully guarded their prerogatives. Economic power was concentrated among feudal lords and in autonomous cities dominated by assertive associations of artisans and merchants.",
    "ImageID": "",
    "question": "All of the following have been cited as the benefits of the fall of the Roman Empire, except:",
    "options": {
      "a": "The plutocratic ruling class was brought down.",
      "b": "People grew to be taller.",
      "c": "Masses were released from the op pressive exploitation.",
      "d": "The takeover of the empire by Goths, Vandals, Franks, Lombards, and Anglo-Saxons."
    },
    "answer": "d",
    "explanation": "Options A, B, and C can be found in the fourth paragraph. But option D was the aftermath of the fall, which further re sulted in some other benefits.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 34,
    "passage": "  For an empire that collapsed more than 1,500 years ago, ancient Rome maintains a powerful presence. About 1 billion people speak languages derived from Latin; Roman law shapes modern norms; and Roman architecture has been widely imitated. Christianity, which the empire embraced in its sunset years, remains the world’s largest religion. Yet all these enduring influences pale against Rome’s most important legacy: its fall. Had its empire not unravelled, or had it been replaced by a similarly overpowering successor, the world wouldn’t have become modern. This isn’t the way that we ordinarily think about an event that has been lamented pretty much ever since it happened. In the late 18th century, in his monumental work The History of the Decline and Fall of the Roman Empire (1776–1788), the British historian Edward Gibbon called it ‘the greatest, perhaps, and the most awful scene in the history of mankind’. Tankloads of ink have been expended on explaining it. Back in 1984, the German historian Alexander Demandt patiently compiled no fewer than 210 different reasons for Rome’s demise that had been put forward over time. And the flood of books and papers shows no sign of abating: most recently, disease and climate change have been pressed into service. Wouldn’t only a calamity of the first order warrant this kind of attention? It’s true that Rome’s collapse reverberated widely, at least in the western—mostly European—half of its empire. (A shrinking portion of the eastern half, later known as Byzantium, survived for another millennium.) Although some regions were harder hit than others, none escaped unscathed. Monumental structures fell into disrepair; previously thriving cities emptied out; Rome itself turned into a shadow of its former grand self, with shepherds tending their  flocks among the ruins. Trade and coin use thinned out, and the art of writing retreated. Population numbers plummeted. But a few benefits were already being felt at the time. Roman power had fostered immense inequality: its collapse brought down the plutocratic ruling class, releasing the labouring masses from oppressive exploitation. The new Germanic rulers operated with lower overheads and proved less adept at collecting rents and taxes. Forensic archaeology reveals that people grew to be taller, likely thanks to reduced inequality, a better diet, and lower disease loads. Yet these changes didn’t last. The real payoff of Rome’s demise took much longer to emerge. When Goths, Vandals, Franks, Lombards, and Anglo-Saxons carved up the empire, they broke the imperial order so thoroughly that it never returned. Their fifth-century takeover was only the beginning: in a very real sense, Rome’s decline continued well after its fall—turning Gibbon’s title on its head. When the Germans took charge, they initially relied on Roman institutions of governance to run their new kingdoms. But they did a poor job of maintaining that vital infrastructure. Before long, nobles and warriors made themselves at home on the lands whose yield kings had assigned to them. While these relieved rulers of the onerous need to count and tax the peasantry, it also starved them of revenue and made it harder for them to control their supporters. When, in the year 800, the Frankish king Charlemagne decided that he was a new Roman emperor, it was already too late. In the following centuries, royal power declined as aristocrats asserted ever greater autonomy and knights set up their own castles. The Holy Roman Empire, established in Germany and northern Italy in 962, never properly functioned as a unified state. For much of the Middle Ages, power was widely dispersed among different groups. Kings claimed political supremacy but often found it hard to exercise control beyond their own domains. Reading Comprehension – Basic LevelNobles and their armed vassals wielded the bulk of military power. The Catholic Church, increasingly centralised under an ascendant papacy, had a lock on the dominant belief system. Bishops and abbots cooperated with secular authorities, but carefully guarded their prerogatives. Economic power was concentrated among feudal lords and in autonomous cities dominated by assertive associations of artisans and merchants.",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "The Romans were more efficient rul ers than the Germans that came af ter them.",
      "b": "The new Germanic rulers were kind and compassionate as compared to their predecessors.",
      "c": "The Romans taxed their subjects heavily.",
      "d": "The Catholic Church somehow man aged to maintain its control over so ciety long after the fall of the Roman Empire."
    },
    "answer": "b",
    "explanation": "Option A can be inferred from the fourth paragraph. The term oppressive exploitation sug gests that option C can also be inferred from the same paragraph. Also, it says that Germans were less adept in col lecting taxes, which further implies the fact mentioned in option C. Option D can be inferred from the last paragraph of the passage. Option B is the correct answer here as it cannot be inferred from the passage.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 35,
    "passage": "  The living landscape all around us is just a thin veneer atop the vast, little-understood bulk of the Earth’s interior. A widespread misconception about the deep subsurface is that this realm consists of a continuous mass of uniform compressed solid rock. Few are aware that this mass of rock is heavily fractured, and water runs in many of these fractures and faults, down to depths of many kilometres. The deep Earth supports an entire biosphere, largely cut off from the surface world, and is still only beginning to be explored and understood. The amount of water in the subsurface is considerable. Globally, the freshwater reservoir in the subsurface is estimated to be up to 100 times as great as all the available fresh water in the rivers, lakes, and swamps combined. This water, ranging in ages from seven years to 2 billion years, is being intensely studied by researchers because it defines the location and scope of deep life. We know now that the deep terrestrial subsurface is home to one quintillion simple (prokaryotic) cells. That is two to 20 times as many cells as live in all the open ocean. By some estimates, the deep biosphere could contain up to one-third of Earth’s entire biomass. To comprehend the deep biosphere, we must look past the familiar rules of biology. On the surface, life without the Sun for an extended period of time is dangerous or deadly. Without daylight, no plants or crops can grow. Temperatures get colder and colder. Few organisms, including human beings, can long tolerate such conditions. For instance, people living within the Arctic Circle—as well as the maintenance staff at Antarctic research stations during winter—experience 24-hour darkness for several months each year. They are more vulnerable to health issues such as depression. They find ways to adapt and get through the long, dark, cold winter, but it isn’t easy. Now imagine the challenges in places that have been isolated from sunlight and organic compounds derived from light-dependent reactions for millions or even billions of years. It seems incomprehensible that anything could survive there. Yet scientists, including the members of our team at Princeton University in New Jersey, have found surprisingly diverse microorganisms in the deep Earth, adapted to a lifestyle independent of the Sun. Sunlight can filter down to depths of about 1,000 metres in ocean water, but light penetrates no more than a few centimetres into soils or rocks. Cold is not a problem down there, however. Quite the opposite: rainwater that percolates kilometres deep into the crust along fractures and faults between rocks can reach temperatures of 60°C (140°F) or higher. The further down you go from the surface, the closer you are to the mantle. Heat rising from the inner Earth is what warms the fissure water. Additionally, the water is under high pressure, contains very little or no oxygen, and is bombarded by radiation from natural radioactive elements in the rocks. Within this hellish environment, though, are crucial ingredients for nurturing life. Underground water reacts with minerals in the continental crust, and the longer the water has been trapped down there, the more time there has been for the results of those reactions to accumulate along the flow path. The slow reactions between water and rock dissolve minerals into the water, and break up some of the water molecules, producing molecular hydrogen. This hydrogen is an important fuel for microorganisms in the deep subsurface. We are also beginning to map the different ecosystems and populations of the deep Earth. Generally speaking, the older subterranean fissure water is; brinier (saltier) and has higher concentrations of dissolved hydrogen. Our studies and those by some of our colleagues have shown an apparent trend that the microbes living in older, more brackish water are distinctly different from ones in the younger, less saline water. Old-water ecosystems are dominated by hydrogen-utilising microorganisms such as sulphate-reducing bacteria and methane-producing archaea. Those methane-producing archaea, or methanogens, are microbes that visually resemble bacteria but are so structurally and genetically distinct that they belong to a completely separate domain of life. Sulphate-reducing bacteria and methanogens are among the life forms that appeared earlier in evolutionary history. In contrast, young-water ecosystems are dominated by metabolically diverse and versatile bacteria of the phylum proteobacteria.",
    "ImageID": "",
    "question": "The living landscape all around us is just a thin veneer atop the vast, little-un derstood bulk of the Earth’s interior. The primary purpose of this statement is to emphasise that:",
    "options": {
      "a": "The subterranean ecosystem is very vast.",
      "b": "We know very little about the Earth’s interior.",
      "c": "Our ecosystem is nothing compared to the subterranean ecosystem.",
      "d": "All of the above."
    },
    "answer": "a",
    "explanation": "Though the author has said all of the above in the given sentence, the pri mary purpose could be just one. Here, the primary purpose is to emphasise the vastness of the subterranean ecosystem. Also, the vastness of the deep ecosys tem has been the subject of discussion throughout the passage. Hence, option A is the correct choice here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 36,
    "passage": "  The living landscape all around us is just a thin veneer atop the vast, little-understood bulk of the Earth’s interior. A widespread misconception about the deep subsurface is that this realm consists of a continuous mass of uniform compressed solid rock. Few are aware that this mass of rock is heavily fractured, and water runs in many of these fractures and faults, down to depths of many kilometres. The deep Earth supports an entire biosphere, largely cut off from the surface world, and is still only beginning to be explored and understood. The amount of water in the subsurface is considerable. Globally, the freshwater reservoir in the subsurface is estimated to be up to 100 times as great as all the available fresh water in the rivers, lakes, and swamps combined. This water, ranging in ages from seven years to 2 billion years, is being intensely studied by researchers because it defines the location and scope of deep life. We know now that the deep terrestrial subsurface is home to one quintillion simple (prokaryotic) cells. That is two to 20 times as many cells as live in all the open ocean. By some estimates, the deep biosphere could contain up to one-third of Earth’s entire biomass. To comprehend the deep biosphere, we must look past the familiar rules of biology. On the surface, life without the Sun for an extended period of time is dangerous or deadly. Without daylight, no plants or crops can grow. Temperatures get colder and colder. Few organisms, including human beings, can long tolerate such conditions. For instance, people living within the Arctic Circle—as well as the maintenance staff at Antarctic research stations during winter—experience 24-hour darkness for several months each year. They are more vulnerable to health issues such as depression. They find ways to adapt and get through the long, dark, cold winter, but it isn’t easy. Now imagine the challenges in places that have been isolated from sunlight and organic compounds derived from light-dependent reactions for millions or even billions of years. It seems incomprehensible that anything could survive there. Yet scientists, including the members of our team at Princeton University in New Jersey, have found surprisingly diverse microorganisms in the deep Earth, adapted to a lifestyle independent of the Sun. Sunlight can filter down to depths of about 1,000 metres in ocean water, but light penetrates no more than a few centimetres into soils or rocks. Cold is not a problem down there, however. Quite the opposite: rainwater that percolates kilometres deep into the crust along fractures and faults between rocks can reach temperatures of 60°C (140°F) or higher. The further down you go from the surface, the closer you are to the mantle. Heat rising from the inner Earth is what warms the fissure water. Additionally, the water is under high pressure, contains very little or no oxygen, and is bombarded by radiation from natural radioactive elements in the rocks. Within this hellish environment, though, are crucial ingredients for nurturing life. Underground water reacts with minerals in the continental crust, and the longer the water has been trapped down there, the more time there has been for the results of those reactions to accumulate along the flow path. The slow reactions between water and rock dissolve minerals into the water, and break up some of the water molecules, producing molecular hydrogen. This hydrogen is an important fuel for microorganisms in the deep subsurface. We are also beginning to map the different ecosystems and populations of the deep Earth. Generally speaking, the older subterranean fissure water is; brinier (saltier) and has higher concentrations of dissolved hydrogen. Our studies and those by some of our colleagues have shown an apparent trend that the microbes living in older, more brackish water are distinctly different from ones in the younger, less saline water. Old-water ecosystems are dominated by hydrogen-utilising microorganisms such as sulphate-reducing bacteria and methane-producing archaea. Those methane-producing archaea, or methanogens, are microbes that visually resemble bacteria but are so structurally and genetically distinct that they belong to a completely separate domain of life. Sulphate-reducing bacteria and methanogens are among the life forms that appeared earlier in evolutionary history. In contrast, young-water ecosystems are dominated by metabolically diverse and versatile bacteria of the phylum proteobacteria.",
    "ImageID": "",
    "question": "Which of the following is not true re garding the freshwater reservoir under the surface?",
    "options": {
      "a": "The freshwater reservoir in the sub surface is approximately 100 times larger than the available fresh water on the surface.",
      "b": "The ages of underground water res ervoirs range from seven years to two billion years.",
      "c": "Deep terrestrial subsurface is home to two to twenty times as many prokaryotic cells as living on all the open surfaces.",
      "d": "The deep biosphere could contain up to one-third of the Earth’s entire biomass."
    },
    "answer": "c",
    "explanation": "On reading the second paragraph of the passage, it is evident that the facts men tioned in statements A, B, and D are all true. Statement C is not true, the passage has mentioned that the deep terrestrial sub surface is home to two to twenty times as many prokaryotic cells as living in all the open ocean. Option C says on all the open surfaces,which is incorrect. So, option C is the answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 37,
    "passage": "  The living landscape all around us is just a thin veneer atop the vast, little-understood bulk of the Earth’s interior. A widespread misconception about the deep subsurface is that this realm consists of a continuous mass of uniform compressed solid rock. Few are aware that this mass of rock is heavily fractured, and water runs in many of these fractures and faults, down to depths of many kilometres. The deep Earth supports an entire biosphere, largely cut off from the surface world, and is still only beginning to be explored and understood. The amount of water in the subsurface is considerable. Globally, the freshwater reservoir in the subsurface is estimated to be up to 100 times as great as all the available fresh water in the rivers, lakes, and swamps combined. This water, ranging in ages from seven years to 2 billion years, is being intensely studied by researchers because it defines the location and scope of deep life. We know now that the deep terrestrial subsurface is home to one quintillion simple (prokaryotic) cells. That is two to 20 times as many cells as live in all the open ocean. By some estimates, the deep biosphere could contain up to one-third of Earth’s entire biomass. To comprehend the deep biosphere, we must look past the familiar rules of biology. On the surface, life without the Sun for an extended period of time is dangerous or deadly. Without daylight, no plants or crops can grow. Temperatures get colder and colder. Few organisms, including human beings, can long tolerate such conditions. For instance, people living within the Arctic Circle—as well as the maintenance staff at Antarctic research stations during winter—experience 24-hour darkness for several months each year. They are more vulnerable to health issues such as depression. They find ways to adapt and get through the long, dark, cold winter, but it isn’t easy. Now imagine the challenges in places that have been isolated from sunlight and organic compounds derived from light-dependent reactions for millions or even billions of years. It seems incomprehensible that anything could survive there. Yet scientists, including the members of our team at Princeton University in New Jersey, have found surprisingly diverse microorganisms in the deep Earth, adapted to a lifestyle independent of the Sun. Sunlight can filter down to depths of about 1,000 metres in ocean water, but light penetrates no more than a few centimetres into soils or rocks. Cold is not a problem down there, however. Quite the opposite: rainwater that percolates kilometres deep into the crust along fractures and faults between rocks can reach temperatures of 60°C (140°F) or higher. The further down you go from the surface, the closer you are to the mantle. Heat rising from the inner Earth is what warms the fissure water. Additionally, the water is under high pressure, contains very little or no oxygen, and is bombarded by radiation from natural radioactive elements in the rocks. Within this hellish environment, though, are crucial ingredients for nurturing life. Underground water reacts with minerals in the continental crust, and the longer the water has been trapped down there, the more time there has been for the results of those reactions to accumulate along the flow path. The slow reactions between water and rock dissolve minerals into the water, and break up some of the water molecules, producing molecular hydrogen. This hydrogen is an important fuel for microorganisms in the deep subsurface. We are also beginning to map the different ecosystems and populations of the deep Earth. Generally speaking, the older subterranean fissure water is; brinier (saltier) and has higher concentrations of dissolved hydrogen. Our studies and those by some of our colleagues have shown an apparent trend that the microbes living in older, more brackish water are distinctly different from ones in the younger, less saline water. Old-water ecosystems are dominated by hydrogen-utilising microorganisms such as sulphate-reducing bacteria and methane-producing archaea. Those methane-producing archaea, or methanogens, are microbes that visually resemble bacteria but are so structurally and genetically distinct that they belong to a completely separate domain of life. Sulphate-reducing bacteria and methanogens are among the life forms that appeared earlier in evolutionary history. In contrast, young-water ecosystems are dominated by metabolically diverse and versatile bacteria of the phylum proteobacteria.",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "Sunlight is essential for survival on the surface.",
      "b": "A very long absence of sunlight can cause depression in human beings.",
      "c": "Nothing can survive without sunlight.",
      "d": "Life within the Arctic Circle and the Antarctic is very challenging."
    },
    "answer": "c",
    "explanation": "Statements written in options A, B, and D can be inferred from the third paragraph of the passage. Statement C is a wrong inference, as it contradicts the facts mentioned in the fourth paragraph of the passage. Point of reference: Scientists, including the members of our team at Princeton University in New Jersey, have found sur prisingly diverse microorganisms in the deep Earth, adapted to a lifestyle inde pendent of the Sun (fourth paragraph).",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 38,
    "passage": "  The living landscape all around us is just a thin veneer atop the vast, little-understood bulk of the Earth’s interior. A widespread misconception about the deep subsurface is that this realm consists of a continuous mass of uniform compressed solid rock. Few are aware that this mass of rock is heavily fractured, and water runs in many of these fractures and faults, down to depths of many kilometres. The deep Earth supports an entire biosphere, largely cut off from the surface world, and is still only beginning to be explored and understood. The amount of water in the subsurface is considerable. Globally, the freshwater reservoir in the subsurface is estimated to be up to 100 times as great as all the available fresh water in the rivers, lakes, and swamps combined. This water, ranging in ages from seven years to 2 billion years, is being intensely studied by researchers because it defines the location and scope of deep life. We know now that the deep terrestrial subsurface is home to one quintillion simple (prokaryotic) cells. That is two to 20 times as many cells as live in all the open ocean. By some estimates, the deep biosphere could contain up to one-third of Earth’s entire biomass. To comprehend the deep biosphere, we must look past the familiar rules of biology. On the surface, life without the Sun for an extended period of time is dangerous or deadly. Without daylight, no plants or crops can grow. Temperatures get colder and colder. Few organisms, including human beings, can long tolerate such conditions. For instance, people living within the Arctic Circle—as well as the maintenance staff at Antarctic research stations during winter—experience 24-hour darkness for several months each year. They are more vulnerable to health issues such as depression. They find ways to adapt and get through the long, dark, cold winter, but it isn’t easy. Now imagine the challenges in places that have been isolated from sunlight and organic compounds derived from light-dependent reactions for millions or even billions of years. It seems incomprehensible that anything could survive there. Yet scientists, including the members of our team at Princeton University in New Jersey, have found surprisingly diverse microorganisms in the deep Earth, adapted to a lifestyle independent of the Sun. Sunlight can filter down to depths of about 1,000 metres in ocean water, but light penetrates no more than a few centimetres into soils or rocks. Cold is not a problem down there, however. Quite the opposite: rainwater that percolates kilometres deep into the crust along fractures and faults between rocks can reach temperatures of 60°C (140°F) or higher. The further down you go from the surface, the closer you are to the mantle. Heat rising from the inner Earth is what warms the fissure water. Additionally, the water is under high pressure, contains very little or no oxygen, and is bombarded by radiation from natural radioactive elements in the rocks. Within this hellish environment, though, are crucial ingredients for nurturing life. Underground water reacts with minerals in the continental crust, and the longer the water has been trapped down there, the more time there has been for the results of those reactions to accumulate along the flow path. The slow reactions between water and rock dissolve minerals into the water, and break up some of the water molecules, producing molecular hydrogen. This hydrogen is an important fuel for microorganisms in the deep subsurface. We are also beginning to map the different ecosystems and populations of the deep Earth. Generally speaking, the older subterranean fissure water is; brinier (saltier) and has higher concentrations of dissolved hydrogen. Our studies and those by some of our colleagues have shown an apparent trend that the microbes living in older, more brackish water are distinctly different from ones in the younger, less saline water. Old-water ecosystems are dominated by hydrogen-utilising microorganisms such as sulphate-reducing bacteria and methane-producing archaea. Those methane-producing archaea, or methanogens, are microbes that visually resemble bacteria but are so structurally and genetically distinct that they belong to a completely separate domain of life. Sulphate-reducing bacteria and methanogens are among the life forms that appeared earlier in evolutionary history. In contrast, young-water ecosystems are dominated by metabolically diverse and versatile bacteria of the phylum proteobacteria.",
    "ImageID": "",
    "question": "Which of the following has been cited as the main reason behind the possibility of life in the subterranean ecosystem?",
    "options": {
      "a": "Sunlight",
      "b": "Presence of hot water",
      "c": "Molecular hydrogen",
      "d": "Radiation from natural radioactive elements in the rocks."
    },
    "answer": "c",
    "explanation": "The sixth paragraph mentions molecular hydrogen as the main ingredient of life in the subterranean ecosystem. Other options, on the contrary, are the factors making life almost impossible in the subterranean ecosystem. Hence, option C is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 39,
    "passage": "  The living landscape all around us is just a thin veneer atop the vast, little-understood bulk of the Earth’s interior. A widespread misconception about the deep subsurface is that this realm consists of a continuous mass of uniform compressed solid rock. Few are aware that this mass of rock is heavily fractured, and water runs in many of these fractures and faults, down to depths of many kilometres. The deep Earth supports an entire biosphere, largely cut off from the surface world, and is still only beginning to be explored and understood. The amount of water in the subsurface is considerable. Globally, the freshwater reservoir in the subsurface is estimated to be up to 100 times as great as all the available fresh water in the rivers, lakes, and swamps combined. This water, ranging in ages from seven years to 2 billion years, is being intensely studied by researchers because it defines the location and scope of deep life. We know now that the deep terrestrial subsurface is home to one quintillion simple (prokaryotic) cells. That is two to 20 times as many cells as live in all the open ocean. By some estimates, the deep biosphere could contain up to one-third of Earth’s entire biomass. To comprehend the deep biosphere, we must look past the familiar rules of biology. On the surface, life without the Sun for an extended period of time is dangerous or deadly. Without daylight, no plants or crops can grow. Temperatures get colder and colder. Few organisms, including human beings, can long tolerate such conditions. For instance, people living within the Arctic Circle—as well as the maintenance staff at Antarctic research stations during winter—experience 24-hour darkness for several months each year. They are more vulnerable to health issues such as depression. They find ways to adapt and get through the long, dark, cold winter, but it isn’t easy. Now imagine the challenges in places that have been isolated from sunlight and organic compounds derived from light-dependent reactions for millions or even billions of years. It seems incomprehensible that anything could survive there. Yet scientists, including the members of our team at Princeton University in New Jersey, have found surprisingly diverse microorganisms in the deep Earth, adapted to a lifestyle independent of the Sun. Sunlight can filter down to depths of about 1,000 metres in ocean water, but light penetrates no more than a few centimetres into soils or rocks. Cold is not a problem down there, however. Quite the opposite: rainwater that percolates kilometres deep into the crust along fractures and faults between rocks can reach temperatures of 60°C (140°F) or higher. The further down you go from the surface, the closer you are to the mantle. Heat rising from the inner Earth is what warms the fissure water. Additionally, the water is under high pressure, contains very little or no oxygen, and is bombarded by radiation from natural radioactive elements in the rocks. Within this hellish environment, though, are crucial ingredients for nurturing life. Underground water reacts with minerals in the continental crust, and the longer the water has been trapped down there, the more time there has been for the results of those reactions to accumulate along the flow path. The slow reactions between water and rock dissolve minerals into the water, and break up some of the water molecules, producing molecular hydrogen. This hydrogen is an important fuel for microorganisms in the deep subsurface. We are also beginning to map the different ecosystems and populations of the deep Earth. Generally speaking, the older subterranean fissure water is; brinier (saltier) and has higher concentrations of dissolved hydrogen. Our studies and those by some of our colleagues have shown an apparent trend that the microbes living in older, more brackish water are distinctly different from ones in the younger, less saline water. Old-water ecosystems are dominated by hydrogen-utilising microorganisms such as sulphate-reducing bacteria and methane-producing archaea. Those methane-producing archaea, or methanogens, are microbes that visually resemble bacteria but are so structurally and genetically distinct that they belong to a completely separate domain of life. Sulphate-reducing bacteria and methanogens are among the life forms that appeared earlier in evolutionary history. In contrast, young-water ecosystems are dominated by metabolically diverse and versatile bacteria of the phylum proteobacteria.",
    "ImageID": "",
    "question": "Which of the following correctly points out the contrast between the old-wa ter ecosystem and the new-water ecosystem?",
    "options": {
      "a": "The methane-producing archaea, or methanogens, are microbes that vis ually resemble bacteria but are so structurally and genetically distinct that they belong to a separate do main of life.",
      "b": "Old-water ecosystems are dominat ed by hydrogen-utilising microor ganisms such as sulphate-reducing bacteria and methane-producing ar chaea, whereas young-water ecosys tems are dominated by metabolically diverse and versatile bacteria of the phylum proteobacteria.",
      "c": "Young-water ecosystems are dom inated by hydrogen-utilising micro organisms such as sulphate-reduc ing bacteria and methane-producing archaea, whereas old-water ecosys tems are dominated by metabolically diverse and versatile bacteria of the phylum proteobacteria.",
      "d": "Sulphate-reducing bacteria and methanogens are among the life forms that appeared earlier in evolutionary history. In contrast, young-water ecosystems are dom inated by metabolically diverse and versatile bacteria of the phylum proteobacteria."
    },
    "answer": "b",
    "explanation": "Option B states the correct contrast be tween the old-water ecosystem and the young-water ecosystem. Other options are irrelevant in this con text. Options A and D say nothing about the contrast between the two. And op tion C states the opposite. Point of reference: Last paragraph Option B is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 40,
    "passage": "  The voices told him that he was God, and Oliver believed them. Only 17 years old, he was special, chosen, a higher being whose wisdom and intelligence were beyond compare. Psychiatrists, however, labelled these voices as auditory hallucinations, his first psychotic episode. A diagnosis of schizophrenia soon followed. For the next five years, Oliver would spend weeks in mental institutions and hospitals in northern England where he lived. When he was deemed too aggressive for one facility, he was injected with sedatives, bundled into the back of a van, and driven to a higher-security institution. The drugs made the voices distant. Oliver felt subdued and heavy as he fell back to Earth. Five years have passed. Although he is unemployed, Oliver is now able to live at home with his wife and young daughter. He takes clozapine, an antipsychotic that’s prescribed to patients who don’t respond to two firstline drugs such as olanzapine and quetiapine. It’s the last resort for a reason: clozapine is a toxic medicine that reduces the number of white blood cells in his body, so Oliver has regular blood tests to make sure he isn’t immune-compromised, a concern that has grown during the COVID-19 pandemic. I haven’t seen Oliver in all this time. I only know what’s been happening to him via his father, my uncle. We’re cousins with just two years between us in age, yet Oliver and I have lived through different—often opposing—experiences of mental disorder. While Oliver felt lifted to the heights, I believed that I was worthless, guilty of ruining the lives of others. Far from being heavenly, I felt I was better off dead and buried. This suicidal ideation, combined with a lack of motivation and baseless guilt, is typical of a mood disorder such as depression. Accordingly, doctors prescribed me antidepressants that adjust the neurotransmitter serotonin in my  brain, rather than clozapine or another antipsychotic, which targets a different brain chemical, dopamine. I’ve never been institutionalised or injected with sedatives (although I am prescribed them). I’ve never heard voices in my head. From its symptoms to its treatment, my depression is a gulf apart from Oliver’s schizophrenia. Mine is a mood disorder, not a psychotic disorder. Like the split between animals and plants in biology, these two fundamental categories have been a cornerstone of psychiatry since the work of the German psychiatrist Emil Kraepelin in the late-19th and early 20th centuries. His textbooks laid the foundations for the DSM-5 and the ICD-11—the latest editions of two reference manuals published by the American Psychiatric Association and the World Health Organisation, respectively—that are used by psychiatrists to diagnose hundreds of different mental disorders, each grouped into 20 or so categories: disorders of personality, psychosis, substance use, anxiety, depression, eating, sexual dysfunction and so on. Since the publication of the DSM-III in 1980, psychiatric diagnosis has helped to select the right treatment for a person’s symptoms. It’s also made the tracking of diagnoses over time and space possible, a field known as ‘psychiatric epidemiology’. However, while these diagnostic guides might be useful for doctors who must make daily decisions about care and treatment, some critics argue that diagnostic systems have actually stymied the progress of psychiatry. While other specialities of medicine have drastically reduced mortality rates from heart disease, cancer, and stroke, there haven’t been similar successes in mental healthcare. As a paper from 2013 put it, ‘mortality has not decreased for any mental illness, prevalence rates are similarly unchanged, there are no clinical tests for diagnosis, detection of disorders is delayed well beyond generally accepted onset of pathology, and there are no well-developed preventive interventions’. In short, psychiatry appears stuck. Perhaps it’s because the diagnostic system is faulty. Indeed, the fact that around half of patients with one mental disorder also fulfil the requirement for a second disorder has been well documented since the 1990s: major depression and generalised anxiety disorder (GAD), substance use disorders and attention deficit hyperactivity disorder (ADHD), bipolar disorder, and schizophrenia. Either mental disorders really do tend to aggregate or, perhaps more likely and more worryingly, our classification system is drawing lines in unnatural places, carving nature far from its joints.",
    "ImageID": "",
    "question": "The primary purpose of the passage is to highlight:",
    "options": {
      "a": "The similarity between the author’s and his cousin’s mental disorders.",
      "b": "The differences between the author’s and his cousin’s mental disorders.",
      "c": "The symptoms and diagnosis of psy chiatric disorders.",
      "d": "The difference between symptoms and diagnoses of the two fundamen tal categories of psychiatry."
    },
    "answer": "d",
    "explanation": "The author’s and his cousin’s mental conditions serve as the examples cited by the author. But options A and B are not the main purpose of the passage. They are just examples. Option C covers a very vast domain, which is beyond the scope of this passage. Option D defines the purpose of this pas sage accurately. Hence, D is the answer. Point of reference: Paragraph 4",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 41,
    "passage": "  The voices told him that he was God, and Oliver believed them. Only 17 years old, he was special, chosen, a higher being whose wisdom and intelligence were beyond compare. Psychiatrists, however, labelled these voices as auditory hallucinations, his first psychotic episode. A diagnosis of schizophrenia soon followed. For the next five years, Oliver would spend weeks in mental institutions and hospitals in northern England where he lived. When he was deemed too aggressive for one facility, he was injected with sedatives, bundled into the back of a van, and driven to a higher-security institution. The drugs made the voices distant. Oliver felt subdued and heavy as he fell back to Earth. Five years have passed. Although he is unemployed, Oliver is now able to live at home with his wife and young daughter. He takes clozapine, an antipsychotic that’s prescribed to patients who don’t respond to two firstline drugs such as olanzapine and quetiapine. It’s the last resort for a reason: clozapine is a toxic medicine that reduces the number of white blood cells in his body, so Oliver has regular blood tests to make sure he isn’t immune-compromised, a concern that has grown during the COVID-19 pandemic. I haven’t seen Oliver in all this time. I only know what’s been happening to him via his father, my uncle. We’re cousins with just two years between us in age, yet Oliver and I have lived through different—often opposing—experiences of mental disorder. While Oliver felt lifted to the heights, I believed that I was worthless, guilty of ruining the lives of others. Far from being heavenly, I felt I was better off dead and buried. This suicidal ideation, combined with a lack of motivation and baseless guilt, is typical of a mood disorder such as depression. Accordingly, doctors prescribed me antidepressants that adjust the neurotransmitter serotonin in my  brain, rather than clozapine or another antipsychotic, which targets a different brain chemical, dopamine. I’ve never been institutionalised or injected with sedatives (although I am prescribed them). I’ve never heard voices in my head. From its symptoms to its treatment, my depression is a gulf apart from Oliver’s schizophrenia. Mine is a mood disorder, not a psychotic disorder. Like the split between animals and plants in biology, these two fundamental categories have been a cornerstone of psychiatry since the work of the German psychiatrist Emil Kraepelin in the late-19th and early 20th centuries. His textbooks laid the foundations for the DSM-5 and the ICD-11—the latest editions of two reference manuals published by the American Psychiatric Association and the World Health Organisation, respectively—that are used by psychiatrists to diagnose hundreds of different mental disorders, each grouped into 20 or so categories: disorders of personality, psychosis, substance use, anxiety, depression, eating, sexual dysfunction and so on. Since the publication of the DSM-III in 1980, psychiatric diagnosis has helped to select the right treatment for a person’s symptoms. It’s also made the tracking of diagnoses over time and space possible, a field known as ‘psychiatric epidemiology’. However, while these diagnostic guides might be useful for doctors who must make daily decisions about care and treatment, some critics argue that diagnostic systems have actually stymied the progress of psychiatry. While other specialities of medicine have drastically reduced mortality rates from heart disease, cancer, and stroke, there haven’t been similar successes in mental healthcare. As a paper from 2013 put it, ‘mortality has not decreased for any mental illness, prevalence rates are similarly unchanged, there are no clinical tests for diagnosis, detection of disorders is delayed well beyond generally accepted onset of pathology, and there are no well-developed preventive interventions’. In short, psychiatry appears stuck. Perhaps it’s because the diagnostic system is faulty. Indeed, the fact that around half of patients with one mental disorder also fulfil the requirement for a second disorder has been well documented since the 1990s: major depression and generalised anxiety disorder (GAD), substance use disorders and attention deficit hyperactivity disorder (ADHD), bipolar disorder, and schizophrenia. Either mental disorders really do tend to aggregate or, perhaps more likely and more worryingly, our classification system is drawing lines in unnatural places, carving nature far from its joints.",
    "ImageID": "",
    "question": "Choose the set that correctly defines the symptoms, diagnosis, and treatment:",
    "options": {
      "a": "Auditory hallucinations–schizophre nia–clozapine",
      "b": "Auditory hallucinations–schizophre nia–antidepressants",
      "c": "Suicidal tendencies–anti depressants– dopamine",
      "d": "Suicidal tendencies–antidepressants– serotonin"
    },
    "answer": "a",
    "explanation": "We have to choose a set that defines a sequence of symptoms – diagnosis –treatment. Options C and D can be cancelled, as an tidepressants and dopamine/serotonin are not diagnoses and treatments. Option A defines the correct set of symp toms (auditory hallucination) – diagnosis (schizophrenia) – clozapine (treatment). Point of reference: Paragraphs 1 and 2",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 42,
    "passage": "  The voices told him that he was God, and Oliver believed them. Only 17 years old, he was special, chosen, a higher being whose wisdom and intelligence were beyond compare. Psychiatrists, however, labelled these voices as auditory hallucinations, his first psychotic episode. A diagnosis of schizophrenia soon followed. For the next five years, Oliver would spend weeks in mental institutions and hospitals in northern England where he lived. When he was deemed too aggressive for one facility, he was injected with sedatives, bundled into the back of a van, and driven to a higher-security institution. The drugs made the voices distant. Oliver felt subdued and heavy as he fell back to Earth. Five years have passed. Although he is unemployed, Oliver is now able to live at home with his wife and young daughter. He takes clozapine, an antipsychotic that’s prescribed to patients who don’t respond to two firstline drugs such as olanzapine and quetiapine. It’s the last resort for a reason: clozapine is a toxic medicine that reduces the number of white blood cells in his body, so Oliver has regular blood tests to make sure he isn’t immune-compromised, a concern that has grown during the COVID-19 pandemic. I haven’t seen Oliver in all this time. I only know what’s been happening to him via his father, my uncle. We’re cousins with just two years between us in age, yet Oliver and I have lived through different—often opposing—experiences of mental disorder. While Oliver felt lifted to the heights, I believed that I was worthless, guilty of ruining the lives of others. Far from being heavenly, I felt I was better off dead and buried. This suicidal ideation, combined with a lack of motivation and baseless guilt, is typical of a mood disorder such as depression. Accordingly, doctors prescribed me antidepressants that adjust the neurotransmitter serotonin in my  brain, rather than clozapine or another antipsychotic, which targets a different brain chemical, dopamine. I’ve never been institutionalised or injected with sedatives (although I am prescribed them). I’ve never heard voices in my head. From its symptoms to its treatment, my depression is a gulf apart from Oliver’s schizophrenia. Mine is a mood disorder, not a psychotic disorder. Like the split between animals and plants in biology, these two fundamental categories have been a cornerstone of psychiatry since the work of the German psychiatrist Emil Kraepelin in the late-19th and early 20th centuries. His textbooks laid the foundations for the DSM-5 and the ICD-11—the latest editions of two reference manuals published by the American Psychiatric Association and the World Health Organisation, respectively—that are used by psychiatrists to diagnose hundreds of different mental disorders, each grouped into 20 or so categories: disorders of personality, psychosis, substance use, anxiety, depression, eating, sexual dysfunction and so on. Since the publication of the DSM-III in 1980, psychiatric diagnosis has helped to select the right treatment for a person’s symptoms. It’s also made the tracking of diagnoses over time and space possible, a field known as ‘psychiatric epidemiology’. However, while these diagnostic guides might be useful for doctors who must make daily decisions about care and treatment, some critics argue that diagnostic systems have actually stymied the progress of psychiatry. While other specialities of medicine have drastically reduced mortality rates from heart disease, cancer, and stroke, there haven’t been similar successes in mental healthcare. As a paper from 2013 put it, ‘mortality has not decreased for any mental illness, prevalence rates are similarly unchanged, there are no clinical tests for diagnosis, detection of disorders is delayed well beyond generally accepted onset of pathology, and there are no well-developed preventive interventions’. In short, psychiatry appears stuck. Perhaps it’s because the diagnostic system is faulty. Indeed, the fact that around half of patients with one mental disorder also fulfil the requirement for a second disorder has been well documented since the 1990s: major depression and generalised anxiety disorder (GAD), substance use disorders and attention deficit hyperactivity disorder (ADHD), bipolar disorder, and schizophrenia. Either mental disorders really do tend to aggregate or, perhaps more likely and more worryingly, our classification system is drawing lines in unnatural places, carving nature far from its joints.",
    "ImageID": "",
    "question": "Choose the correct chronological ar rangement of the following works.",
    "options": {
      "a": "DSM-5, ICD-11, DSM-III",
      "b": "DSM-III, DSM-5, ICD-11",
      "c": "DSM-III, ICD-11, DSM-5",
      "d": "Cannot be determined from the passage."
    },
    "answer": "d",
    "explanation": "Nothing has been said about the pub lishing years of DSM-5, and ICD-11. So the chronological order of these works cannot be decided. Option D is correct. Point of reference: Paragraph 4",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 43,
    "passage": "  The voices told him that he was God, and Oliver believed them. Only 17 years old, he was special, chosen, a higher being whose wisdom and intelligence were beyond compare. Psychiatrists, however, labelled these voices as auditory hallucinations, his first psychotic episode. A diagnosis of schizophrenia soon followed. For the next five years, Oliver would spend weeks in mental institutions and hospitals in northern England where he lived. When he was deemed too aggressive for one facility, he was injected with sedatives, bundled into the back of a van, and driven to a higher-security institution. The drugs made the voices distant. Oliver felt subdued and heavy as he fell back to Earth. Five years have passed. Although he is unemployed, Oliver is now able to live at home with his wife and young daughter. He takes clozapine, an antipsychotic that’s prescribed to patients who don’t respond to two firstline drugs such as olanzapine and quetiapine. It’s the last resort for a reason: clozapine is a toxic medicine that reduces the number of white blood cells in his body, so Oliver has regular blood tests to make sure he isn’t immune-compromised, a concern that has grown during the COVID-19 pandemic. I haven’t seen Oliver in all this time. I only know what’s been happening to him via his father, my uncle. We’re cousins with just two years between us in age, yet Oliver and I have lived through different—often opposing—experiences of mental disorder. While Oliver felt lifted to the heights, I believed that I was worthless, guilty of ruining the lives of others. Far from being heavenly, I felt I was better off dead and buried. This suicidal ideation, combined with a lack of motivation and baseless guilt, is typical of a mood disorder such as depression. Accordingly, doctors prescribed me antidepressants that adjust the neurotransmitter serotonin in my  brain, rather than clozapine or another antipsychotic, which targets a different brain chemical, dopamine. I’ve never been institutionalised or injected with sedatives (although I am prescribed them). I’ve never heard voices in my head. From its symptoms to its treatment, my depression is a gulf apart from Oliver’s schizophrenia. Mine is a mood disorder, not a psychotic disorder. Like the split between animals and plants in biology, these two fundamental categories have been a cornerstone of psychiatry since the work of the German psychiatrist Emil Kraepelin in the late-19th and early 20th centuries. His textbooks laid the foundations for the DSM-5 and the ICD-11—the latest editions of two reference manuals published by the American Psychiatric Association and the World Health Organisation, respectively—that are used by psychiatrists to diagnose hundreds of different mental disorders, each grouped into 20 or so categories: disorders of personality, psychosis, substance use, anxiety, depression, eating, sexual dysfunction and so on. Since the publication of the DSM-III in 1980, psychiatric diagnosis has helped to select the right treatment for a person’s symptoms. It’s also made the tracking of diagnoses over time and space possible, a field known as ‘psychiatric epidemiology’. However, while these diagnostic guides might be useful for doctors who must make daily decisions about care and treatment, some critics argue that diagnostic systems have actually stymied the progress of psychiatry. While other specialities of medicine have drastically reduced mortality rates from heart disease, cancer, and stroke, there haven’t been similar successes in mental healthcare. As a paper from 2013 put it, ‘mortality has not decreased for any mental illness, prevalence rates are similarly unchanged, there are no clinical tests for diagnosis, detection of disorders is delayed well beyond generally accepted onset of pathology, and there are no well-developed preventive interventions’. In short, psychiatry appears stuck. Perhaps it’s because the diagnostic system is faulty. Indeed, the fact that around half of patients with one mental disorder also fulfil the requirement for a second disorder has been well documented since the 1990s: major depression and generalised anxiety disorder (GAD), substance use disorders and attention deficit hyperactivity disorder (ADHD), bipolar disorder, and schizophrenia. Either mental disorders really do tend to aggregate or, perhaps more likely and more worryingly, our classification system is drawing lines in unnatural places, carving nature far from its joints.",
    "ImageID": "",
    "question": "The last sentence of the passage—our classification system is drawing lines in unnatural places, carving nature far from its joints—implies that:",
    "options": {
      "a": "Around half of the patients with one mental disorder also fulfil the re quirement for a second disorder.",
      "b": "Our diagnostic system is faulty.",
      "c": "Sometimes, it is tough to differen tiate between two psychiatric disor ders due to overlapping symptoms.",
      "d": "Psychiatric and psychotic disorders are not the same."
    },
    "answer": "c",
    "explanation": "The facts mentioned in options A and B are given by the author to support the claim made in option C. Hence, C is the correct inference. D is a distortion. Point of reference: Last paragraph",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 44,
    "passage": "  The voices told him that he was God, and Oliver believed them. Only 17 years old, he was special, chosen, a higher being whose wisdom and intelligence were beyond compare. Psychiatrists, however, labelled these voices as auditory hallucinations, his first psychotic episode. A diagnosis of schizophrenia soon followed. For the next five years, Oliver would spend weeks in mental institutions and hospitals in northern England where he lived. When he was deemed too aggressive for one facility, he was injected with sedatives, bundled into the back of a van, and driven to a higher-security institution. The drugs made the voices distant. Oliver felt subdued and heavy as he fell back to Earth. Five years have passed. Although he is unemployed, Oliver is now able to live at home with his wife and young daughter. He takes clozapine, an antipsychotic that’s prescribed to patients who don’t respond to two firstline drugs such as olanzapine and quetiapine. It’s the last resort for a reason: clozapine is a toxic medicine that reduces the number of white blood cells in his body, so Oliver has regular blood tests to make sure he isn’t immune-compromised, a concern that has grown during the COVID-19 pandemic. I haven’t seen Oliver in all this time. I only know what’s been happening to him via his father, my uncle. We’re cousins with just two years between us in age, yet Oliver and I have lived through different—often opposing—experiences of mental disorder. While Oliver felt lifted to the heights, I believed that I was worthless, guilty of ruining the lives of others. Far from being heavenly, I felt I was better off dead and buried. This suicidal ideation, combined with a lack of motivation and baseless guilt, is typical of a mood disorder such as depression. Accordingly, doctors prescribed me antidepressants that adjust the neurotransmitter serotonin in my  brain, rather than clozapine or another antipsychotic, which targets a different brain chemical, dopamine. I’ve never been institutionalised or injected with sedatives (although I am prescribed them). I’ve never heard voices in my head. From its symptoms to its treatment, my depression is a gulf apart from Oliver’s schizophrenia. Mine is a mood disorder, not a psychotic disorder. Like the split between animals and plants in biology, these two fundamental categories have been a cornerstone of psychiatry since the work of the German psychiatrist Emil Kraepelin in the late-19th and early 20th centuries. His textbooks laid the foundations for the DSM-5 and the ICD-11—the latest editions of two reference manuals published by the American Psychiatric Association and the World Health Organisation, respectively—that are used by psychiatrists to diagnose hundreds of different mental disorders, each grouped into 20 or so categories: disorders of personality, psychosis, substance use, anxiety, depression, eating, sexual dysfunction and so on. Since the publication of the DSM-III in 1980, psychiatric diagnosis has helped to select the right treatment for a person’s symptoms. It’s also made the tracking of diagnoses over time and space possible, a field known as ‘psychiatric epidemiology’. However, while these diagnostic guides might be useful for doctors who must make daily decisions about care and treatment, some critics argue that diagnostic systems have actually stymied the progress of psychiatry. While other specialities of medicine have drastically reduced mortality rates from heart disease, cancer, and stroke, there haven’t been similar successes in mental healthcare. As a paper from 2013 put it, ‘mortality has not decreased for any mental illness, prevalence rates are similarly unchanged, there are no clinical tests for diagnosis, detection of disorders is delayed well beyond generally accepted onset of pathology, and there are no well-developed preventive interventions’. In short, psychiatry appears stuck. Perhaps it’s because the diagnostic system is faulty. Indeed, the fact that around half of patients with one mental disorder also fulfil the requirement for a second disorder has been well documented since the 1990s: major depression and generalised anxiety disorder (GAD), substance use disorders and attention deficit hyperactivity disorder (ADHD), bipolar disorder, and schizophrenia. Either mental disorders really do tend to aggregate or, perhaps more likely and more worryingly, our classification system is drawing lines in unnatural places, carving nature far from its joints.",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "Auditory hallucination may be a sign of schizophrenia.",
      "b": "Consumption of clozapine may dam age the immunity system of a patient.",
      "c": "Olanzapine and quetiapine are safer drugs than clozapine.",
      "d": "Megalomaniac patients show a ten dency not to respond to the first-line drugs."
    },
    "answer": "d",
    "explanation": "Option A can be inferred from the first paragraph. Options B and C can be in ferred from the second paragraph. Option D would be a wrong inference as it has not been described as a general tendency shown by megalomaniacs. So, option D is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 45,
    "passage": "  Archaeologists and other scientists are beginning to unravel the story of our most intimate technology: clothing. They’re learning when and why our ancestors first started to wear clothes and how their adoption was crucial to the evolutionary success of our ancestors when they faced climate change on a massive scale during the Pleistocene ice ages. These investigations have revealed a new twist to the story, assigning a much more prominent role to clothing than previously imagined. After the last ice age, global warming prompted people in many areas to change their clothes, from animal hides to textiles. This change in clothing material, I suspect, could be what triggered one of the greatest changes in the life of humanity. Not food but clothing led to the agricultural revolution. My recent work shows that clothing wasn’t just the unique adaptation of a more-or-less hairless mammal to the changing natural environments. The development of clothing led to innovations with many repercussions for humanity, beyond survival in cold climates. A need for portable insulation from the cold in the Palaeolithic promoted major technological transitions. These include stone toolkits for working animal hides and, subsequently, bone tools such as pointed awls and needles to make tailored garments. Later, during the coldest stage of the last ice age, Homo sapiens in middle latitudes devised multilayered outfits with an inner layer of underwear. Equipped with effective protection from wind chill, our species could penetrate the frigid Arctic Circle, further north than cold-adapted Neanderthals had managed to venture. From the north-eastern corner of Siberia, modern humans strolled across an exposed land bridge to enter Alaska by 15,000 years ago, if not earlier, to likely become the first hominins to set foot in the Americas. At the Broken Mammoth site in Alaska, archaeologists have unearthed the fragile technology that made the journey possible: a 13,000-year-old eyed needle. Until recently, the scientific study of clothing was largely the work of physiologists who have explored its thermal properties, which are now well understood. The physiology of clothing allows us to say precisely how much clothing people must wear to survive at sub-freezing temperatures and at differing wind-chill levels. Early hominins in Africa had begun to harness fire between 1 and 2 million years ago, perhaps for cooking more than warmth. Fire was utilised as hominins spread into Europe and northern China, where Homo erectus retreated into caves to escape wind chill. However, even if earlier hominins were hairier than modern humans, whenever they found themselves in cold conditions beyond certain well-defined survival thresholds, they needed to carry portable insulation while out in the open. For modern humans, exposure times for frostbite can be less than an hour, and life-threatening hypothermia can develop overnight, even in cities. From a thermal perspective, two aspects of clothing are important. First is the number of layers, with each extra layer increasing the total insulation value. The second aspect is whether garments are fitted, or tailored, to enclose the body, especially the limbs. Fitted garments offer superior protection from wind chill, a major risk factor for frostbite and hypothermia. While clothing is one of the most visible of all human technologies, in the field of archaeology it’s almost invisible. Compared with stone tools surviving from the Lower Palaeolithic more than 3 million years ago, clothes perish rapidly and rarely survive beyond a single millennium. Among the notable exceptions are a pair of 3,000-year-old trousers worn by nomadic horse-riders in Central Asia, and a 5,000-year-old linen tunic from ancient Egypt. We have only a few precious cloth fragments from the early Neolithic in Peru and Turkey. Not a shred of clothing survives from the Pleistocene, with just a few Reading Comprehension – Basic Leveltwisted flax fibres—used perhaps for strings or thread—found at a 34,000-year-old site in Georgia. All the evidence we have for ice-age clothing is indirect but, nonetheless, the available evidence shows that people had tailored clothes in the last ice age. The world’s oldest eyed needles are found in southern Russia 40,000 years ago, and one needle in Denisova Cave is said to be 50,000 years old. In the vicinity of Moscow at a site called Sunghir, 30,000-year-old human burials have thousands of beads neatly arranged on the skeletons. Russian archaeologists think that these beads were sewn onto fitted garments, including trousers with legs and shirts with sleeves. Some of the skeletons appear to have two layers of garments, indicating the presence of multiple layers, so the Sunghir burials document the world’s oldest underwear. Artworks across Eurasia begin to show people wearing clothes from that time, including the so-called ‘Venus’ figurines.",
    "ImageID": "",
    "question": "‘Not food but clothing led to the agri cultural revolution.’—What is the ground behind the author’s claim?",
    "options": {
      "a": "Because the author believes clothing to be the greatest invention in the history of mankind.",
      "b": "Because the author believes clothing to be the reason behind the inventions of many tools in the prehistoric era.",
      "c": "Because the author believes that humans invented fire to keep them selves warm before they invented clothes.",
      "d": "According to the author, clothing was the primary concern of Homo sapi ens for their survival, not food."
    },
    "answer": "b",
    "explanation": "The author believes that to fulfil their clothing requirements, humans invented many tools that might have helped them later in the field of agriculture. So, option B is the correct reason behind the claim made by the author. Other options are either distortions or irrelevant. Point of reference: Second paragraph",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 46,
    "passage": "  Archaeologists and other scientists are beginning to unravel the story of our most intimate technology: clothing. They’re learning when and why our ancestors first started to wear clothes and how their adoption was crucial to the evolutionary success of our ancestors when they faced climate change on a massive scale during the Pleistocene ice ages. These investigations have revealed a new twist to the story, assigning a much more prominent role to clothing than previously imagined. After the last ice age, global warming prompted people in many areas to change their clothes, from animal hides to textiles. This change in clothing material, I suspect, could be what triggered one of the greatest changes in the life of humanity. Not food but clothing led to the agricultural revolution. My recent work shows that clothing wasn’t just the unique adaptation of a more-or-less hairless mammal to the changing natural environments. The development of clothing led to innovations with many repercussions for humanity, beyond survival in cold climates. A need for portable insulation from the cold in the Palaeolithic promoted major technological transitions. These include stone toolkits for working animal hides and, subsequently, bone tools such as pointed awls and needles to make tailored garments. Later, during the coldest stage of the last ice age, Homo sapiens in middle latitudes devised multilayered outfits with an inner layer of underwear. Equipped with effective protection from wind chill, our species could penetrate the frigid Arctic Circle, further north than cold-adapted Neanderthals had managed to venture. From the north-eastern corner of Siberia, modern humans strolled across an exposed land bridge to enter Alaska by 15,000 years ago, if not earlier, to likely become the first hominins to set foot in the Americas. At the Broken Mammoth site in Alaska, archaeologists have unearthed the fragile technology that made the journey possible: a 13,000-year-old eyed needle. Until recently, the scientific study of clothing was largely the work of physiologists who have explored its thermal properties, which are now well understood. The physiology of clothing allows us to say precisely how much clothing people must wear to survive at sub-freezing temperatures and at differing wind-chill levels. Early hominins in Africa had begun to harness fire between 1 and 2 million years ago, perhaps for cooking more than warmth. Fire was utilised as hominins spread into Europe and northern China, where Homo erectus retreated into caves to escape wind chill. However, even if earlier hominins were hairier than modern humans, whenever they found themselves in cold conditions beyond certain well-defined survival thresholds, they needed to carry portable insulation while out in the open. For modern humans, exposure times for frostbite can be less than an hour, and life-threatening hypothermia can develop overnight, even in cities. From a thermal perspective, two aspects of clothing are important. First is the number of layers, with each extra layer increasing the total insulation value. The second aspect is whether garments are fitted, or tailored, to enclose the body, especially the limbs. Fitted garments offer superior protection from wind chill, a major risk factor for frostbite and hypothermia. While clothing is one of the most visible of all human technologies, in the field of archaeology it’s almost invisible. Compared with stone tools surviving from the Lower Palaeolithic more than 3 million years ago, clothes perish rapidly and rarely survive beyond a single millennium. Among the notable exceptions are a pair of 3,000-year-old trousers worn by nomadic horse-riders in Central Asia, and a 5,000-year-old linen tunic from ancient Egypt. We have only a few precious cloth fragments from the early Neolithic in Peru and Turkey. Not a shred of clothing survives from the Pleistocene, with just a few Reading Comprehension – Basic Leveltwisted flax fibres—used perhaps for strings or thread—found at a 34,000-year-old site in Georgia. All the evidence we have for ice-age clothing is indirect but, nonetheless, the available evidence shows that people had tailored clothes in the last ice age. The world’s oldest eyed needles are found in southern Russia 40,000 years ago, and one needle in Denisova Cave is said to be 50,000 years old. In the vicinity of Moscow at a site called Sunghir, 30,000-year-old human burials have thousands of beads neatly arranged on the skeletons. Russian archaeologists think that these beads were sewn onto fitted garments, including trousers with legs and shirts with sleeves. Some of the skeletons appear to have two layers of garments, indicating the presence of multiple layers, so the Sunghir burials document the world’s oldest underwear. Artworks across Eurasia begin to show people wearing clothes from that time, including the so-called ‘Venus’ figurines.",
    "ImageID": "",
    "question": "‘At the Broken Mammoth site in Alaska, archaeologists have unearthed the frag ile technology that made the journey possible: a 13,000-year-old eyed nee dle.’—What is the author indicating here?",
    "options": {
      "a": "The invention of the needle became crucial for the first hominins to set",
      "b": "The humans started stitching clothes before they reached the Americas for the first time.",
      "c": "The hominins started using cloth ing according to their climatic needs even before 13000 years, which was essential for their survival.",
      "d": "Humans moved from the cold north-eastern corners of Siberia to Alaska to find warmer weather conditions."
    },
    "answer": "c",
    "explanation": "The author has mentioned eyed needles as a reason behind the survival of hu mans in challenging climates of Siberia to indicate that humans started making clothing suitable for their needs before 13000 years, which was very crucial for their survival in those climatic conditions. Option C captures this essence; hence it is the correct choice. Options A, B, and D, though somewhat correct, do not cap ture the essence of the statement made by the author.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 47,
    "passage": "  Archaeologists and other scientists are beginning to unravel the story of our most intimate technology: clothing. They’re learning when and why our ancestors first started to wear clothes and how their adoption was crucial to the evolutionary success of our ancestors when they faced climate change on a massive scale during the Pleistocene ice ages. These investigations have revealed a new twist to the story, assigning a much more prominent role to clothing than previously imagined. After the last ice age, global warming prompted people in many areas to change their clothes, from animal hides to textiles. This change in clothing material, I suspect, could be what triggered one of the greatest changes in the life of humanity. Not food but clothing led to the agricultural revolution. My recent work shows that clothing wasn’t just the unique adaptation of a more-or-less hairless mammal to the changing natural environments. The development of clothing led to innovations with many repercussions for humanity, beyond survival in cold climates. A need for portable insulation from the cold in the Palaeolithic promoted major technological transitions. These include stone toolkits for working animal hides and, subsequently, bone tools such as pointed awls and needles to make tailored garments. Later, during the coldest stage of the last ice age, Homo sapiens in middle latitudes devised multilayered outfits with an inner layer of underwear. Equipped with effective protection from wind chill, our species could penetrate the frigid Arctic Circle, further north than cold-adapted Neanderthals had managed to venture. From the north-eastern corner of Siberia, modern humans strolled across an exposed land bridge to enter Alaska by 15,000 years ago, if not earlier, to likely become the first hominins to set foot in the Americas. At the Broken Mammoth site in Alaska, archaeologists have unearthed the fragile technology that made the journey possible: a 13,000-year-old eyed needle. Until recently, the scientific study of clothing was largely the work of physiologists who have explored its thermal properties, which are now well understood. The physiology of clothing allows us to say precisely how much clothing people must wear to survive at sub-freezing temperatures and at differing wind-chill levels. Early hominins in Africa had begun to harness fire between 1 and 2 million years ago, perhaps for cooking more than warmth. Fire was utilised as hominins spread into Europe and northern China, where Homo erectus retreated into caves to escape wind chill. However, even if earlier hominins were hairier than modern humans, whenever they found themselves in cold conditions beyond certain well-defined survival thresholds, they needed to carry portable insulation while out in the open. For modern humans, exposure times for frostbite can be less than an hour, and life-threatening hypothermia can develop overnight, even in cities. From a thermal perspective, two aspects of clothing are important. First is the number of layers, with each extra layer increasing the total insulation value. The second aspect is whether garments are fitted, or tailored, to enclose the body, especially the limbs. Fitted garments offer superior protection from wind chill, a major risk factor for frostbite and hypothermia. While clothing is one of the most visible of all human technologies, in the field of archaeology it’s almost invisible. Compared with stone tools surviving from the Lower Palaeolithic more than 3 million years ago, clothes perish rapidly and rarely survive beyond a single millennium. Among the notable exceptions are a pair of 3,000-year-old trousers worn by nomadic horse-riders in Central Asia, and a 5,000-year-old linen tunic from ancient Egypt. We have only a few precious cloth fragments from the early Neolithic in Peru and Turkey. Not a shred of clothing survives from the Pleistocene, with just a few Reading Comprehension – Basic Leveltwisted flax fibres—used perhaps for strings or thread—found at a 34,000-year-old site in Georgia. All the evidence we have for ice-age clothing is indirect but, nonetheless, the available evidence shows that people had tailored clothes in the last ice age. The world’s oldest eyed needles are found in southern Russia 40,000 years ago, and one needle in Denisova Cave is said to be 50,000 years old. In the vicinity of Moscow at a site called Sunghir, 30,000-year-old human burials have thousands of beads neatly arranged on the skeletons. Russian archaeologists think that these beads were sewn onto fitted garments, including trousers with legs and shirts with sleeves. Some of the skeletons appear to have two layers of garments, indicating the presence of multiple layers, so the Sunghir burials document the world’s oldest underwear. Artworks across Eurasia begin to show people wearing clothes from that time, including the so-called ‘Venus’ figurines.",
    "ImageID": "",
    "question": "Which of the following can be inferred from the passage?",
    "options": {
      "a": "The hominins in the ice age had a good understanding of the physiolo gy of clothing.",
      "b": "The hominins had begun to harness f ire before they knew anything about the clothing.",
      "c": "For early hominins, the only purpose of harnessing fire was cooking, not warmth.",
      "d": "While out in the open, hominins might have carried some portable in sulation to protect themselves from the chill."
    },
    "answer": "d",
    "explanation": "After reading the third paragraph, it is ev ident that statements written in options A, B, and C are not correct inferences. Option D is the correct inference, as it has been clearly indicated in the third paragraph.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 48,
    "passage": "  Archaeologists and other scientists are beginning to unravel the story of our most intimate technology: clothing. They’re learning when and why our ancestors first started to wear clothes and how their adoption was crucial to the evolutionary success of our ancestors when they faced climate change on a massive scale during the Pleistocene ice ages. These investigations have revealed a new twist to the story, assigning a much more prominent role to clothing than previously imagined. After the last ice age, global warming prompted people in many areas to change their clothes, from animal hides to textiles. This change in clothing material, I suspect, could be what triggered one of the greatest changes in the life of humanity. Not food but clothing led to the agricultural revolution. My recent work shows that clothing wasn’t just the unique adaptation of a more-or-less hairless mammal to the changing natural environments. The development of clothing led to innovations with many repercussions for humanity, beyond survival in cold climates. A need for portable insulation from the cold in the Palaeolithic promoted major technological transitions. These include stone toolkits for working animal hides and, subsequently, bone tools such as pointed awls and needles to make tailored garments. Later, during the coldest stage of the last ice age, Homo sapiens in middle latitudes devised multilayered outfits with an inner layer of underwear. Equipped with effective protection from wind chill, our species could penetrate the frigid Arctic Circle, further north than cold-adapted Neanderthals had managed to venture. From the north-eastern corner of Siberia, modern humans strolled across an exposed land bridge to enter Alaska by 15,000 years ago, if not earlier, to likely become the first hominins to set foot in the Americas. At the Broken Mammoth site in Alaska, archaeologists have unearthed the fragile technology that made the journey possible: a 13,000-year-old eyed needle. Until recently, the scientific study of clothing was largely the work of physiologists who have explored its thermal properties, which are now well understood. The physiology of clothing allows us to say precisely how much clothing people must wear to survive at sub-freezing temperatures and at differing wind-chill levels. Early hominins in Africa had begun to harness fire between 1 and 2 million years ago, perhaps for cooking more than warmth. Fire was utilised as hominins spread into Europe and northern China, where Homo erectus retreated into caves to escape wind chill. However, even if earlier hominins were hairier than modern humans, whenever they found themselves in cold conditions beyond certain well-defined survival thresholds, they needed to carry portable insulation while out in the open. For modern humans, exposure times for frostbite can be less than an hour, and life-threatening hypothermia can develop overnight, even in cities. From a thermal perspective, two aspects of clothing are important. First is the number of layers, with each extra layer increasing the total insulation value. The second aspect is whether garments are fitted, or tailored, to enclose the body, especially the limbs. Fitted garments offer superior protection from wind chill, a major risk factor for frostbite and hypothermia. While clothing is one of the most visible of all human technologies, in the field of archaeology it’s almost invisible. Compared with stone tools surviving from the Lower Palaeolithic more than 3 million years ago, clothes perish rapidly and rarely survive beyond a single millennium. Among the notable exceptions are a pair of 3,000-year-old trousers worn by nomadic horse-riders in Central Asia, and a 5,000-year-old linen tunic from ancient Egypt. We have only a few precious cloth fragments from the early Neolithic in Peru and Turkey. Not a shred of clothing survives from the Pleistocene, with just a few Reading Comprehension – Basic Leveltwisted flax fibres—used perhaps for strings or thread—found at a 34,000-year-old site in Georgia. All the evidence we have for ice-age clothing is indirect but, nonetheless, the available evidence shows that people had tailored clothes in the last ice age. The world’s oldest eyed needles are found in southern Russia 40,000 years ago, and one needle in Denisova Cave is said to be 50,000 years old. In the vicinity of Moscow at a site called Sunghir, 30,000-year-old human burials have thousands of beads neatly arranged on the skeletons. Russian archaeologists think that these beads were sewn onto fitted garments, including trousers with legs and shirts with sleeves. Some of the skeletons appear to have two layers of garments, indicating the presence of multiple layers, so the Sunghir burials document the world’s oldest underwear. Artworks across Eurasia begin to show people wearing clothes from that time, including the so-called ‘Venus’ figurines.",
    "ImageID": "",
    "question": "Which of the following is true regarding the archaeological evidence of clothing in the prehistoric era?",
    "options": {
      "a": "We do not have much archaeological evidence of clothing because clothes perish rapidly and do not survive be yond a single millennium.",
      "b": "A pair of 3,000-year-old trousers worn by nomadic horse-riders in Central Asia and a 5,000-year-old linen tunic from ancient Egypt is the only archaeological evidence of clothing from that era.",
      "c": "The evidence for ice-age clothing is not direct, but it is enough to prove that people had tailored clothes in the last ice age.",
      "d": "Most archaeological sites are in Russia because, in cold places, fab rics survive longer."
    },
    "answer": "c",
    "explanation": "Option A is not true because the passage says clothes perish rapidly and bare ly survive beyond a single millennium, while option A says do not survive. Option B is not true, as it says … only available archaeological evidence… which is not the case. Option C is the correct answer, as found in the last paragraph. Option D is irrelevant. Point of reference: Last paragraph",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 49,
    "passage": "  Aviation deaths once looked like an intractable problem. Then the federal government began probing every plane crash to prevent future loss of life. Our skies got much safer as a result. A similar approach could reduce police killings. A federal agency should investigate every single killing and significant injury caused by American police officers, who have long killed people at higher rates than cops in many other wealthy democracies. Police killings and protests against them have loomed large in United States politics for at least the past seven years. Right now the nation is focused most closely on the trial of Derek Chauvin, who infamously knelt on George Floyd’s neck, even as new protests erupt in Minneapolis over the killing of Daunte Wright, who was shot to death by a police officer who says she intended to discharge her taser. On Thursday, the city of Chicago released footage of the fatal police shooting of 13-year-old Adam Toledo. The number of police killings of unarmed people appears to have dropped since The Washington Post began keeping track in",
    "ImageID": "",
    "question": "The author draws an analogy between aviation deaths and police killings to point out:",
    "options": {
      "a": "That both are very hard to investigate and intractable.",
      "b": "That in both, innocent people lose their lives.",
      "c": "That both attract federal investigation.",
      "d": "That in both, investigations should be done with a preventive approach rather than a punitive approach."
    },
    "answer": "d",
    "explanation": "Option D is the correct answer here, as it is the main point of the passage. Other options are weak arguments and are not the author’s views.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 50,
    "passage": "  Aviation deaths once looked like an intractable problem. Then the federal government began probing every plane crash to prevent future loss of life. Our skies got much safer as a result. A similar approach could reduce police killings. A federal agency should investigate every single killing and significant injury caused by American police officers, who have long killed people at higher rates than cops in many other wealthy democracies. Police killings and protests against them have loomed large in United States politics for at least the past seven years. Right now the nation is focused most closely on the trial of Derek Chauvin, who infamously knelt on George Floyd’s neck, even as new protests erupt in Minneapolis over the killing of Daunte Wright, who was shot to death by a police officer who says she intended to discharge her taser. On Thursday, the city of Chicago released footage of the fatal police shooting of 13-year-old Adam Toledo. The number of police killings of unarmed people appears to have dropped since The Washington Post began keeping track in",
    "ImageID": "",
    "question": "From the passage, it can be inferred that:",
    "options": {
      "a": "Black people are likely to be the vic tims of police killings.",
      "b": "Mass protests help curb the fatal killings of innocent people by the police.",
      "c": "Keeping track of such killings would reduce the number of police killings.",
      "d": "Some police officers may get en gaged in violent encounters with un armed citizens."
    },
    "answer": "d",
    "explanation": "A federal agency should investigate every single killing and significant inju ry caused by American police officers, who have long killed people at higher rates than cops in many other wealthy democracies. This statement from the first paragraph suggests what is written in option D. Hence, option D is the correct answer. Option C is incorrect as in the third par agraph it says—The drop might represent progress; it might also be a fluke. Option B is incorrect as in the passage, it says—The most egregious police kill ings renew protests that succeed in generating attention, statements of con cern from corporations, and gestures of solidarity from progressives, but not in reducing police killings. Option A is misleading and is a distraction.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 51,
    "passage": "  Aviation deaths once looked like an intractable problem. Then the federal government began probing every plane crash to prevent future loss of life. Our skies got much safer as a result. A similar approach could reduce police killings. A federal agency should investigate every single killing and significant injury caused by American police officers, who have long killed people at higher rates than cops in many other wealthy democracies. Police killings and protests against them have loomed large in United States politics for at least the past seven years. Right now the nation is focused most closely on the trial of Derek Chauvin, who infamously knelt on George Floyd’s neck, even as new protests erupt in Minneapolis over the killing of Daunte Wright, who was shot to death by a police officer who says she intended to discharge her taser. On Thursday, the city of Chicago released footage of the fatal police shooting of 13-year-old Adam Toledo. The number of police killings of unarmed people appears to have dropped since The Washington Post began keeping track in",
    "ImageID": "",
    "question": "The author is likely to agree to all of the following, except:",
    "options": {
      "a": "Potential policy changes should be made at the local level.",
      "b": "More restrictive policies towards the use of force should be made.",
      "c": "The police should be defunded in order to curb the number of violent incidents.",
      "d": "All police killings should be investi gated thoroughly."
    },
    "answer": "c",
    "explanation": "Option D is almost the main argument of the author. Hence the author would cer tainly agree with it. Options A and B are the points made by the author in the fifth paragraph. Option C is contrary to the point made in the passage. Hence, it is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 52,
    "passage": "  Aviation deaths once looked like an intractable problem. Then the federal government began probing every plane crash to prevent future loss of life. Our skies got much safer as a result. A similar approach could reduce police killings. A federal agency should investigate every single killing and significant injury caused by American police officers, who have long killed people at higher rates than cops in many other wealthy democracies. Police killings and protests against them have loomed large in United States politics for at least the past seven years. Right now the nation is focused most closely on the trial of Derek Chauvin, who infamously knelt on George Floyd’s neck, even as new protests erupt in Minneapolis over the killing of Daunte Wright, who was shot to death by a police officer who says she intended to discharge her taser. On Thursday, the city of Chicago released footage of the fatal police shooting of 13-year-old Adam Toledo. The number of police killings of unarmed people appears to have dropped since The Washington Post began keeping track in",
    "ImageID": "",
    "question": "The author advocates a thorough inves tigation of all police killings:",
    "options": {
      "a": "So that all the wrongdoers can be brought to justice.",
      "b": "So that the exact reason behind every encounter could be traced.",
      "c": "So that such incidents can be avoid ed in the future.",
      "d": "So that the deaths of innocent peo ple could be compensated."
    },
    "answer": "c",
    "explanation": "The author supports a preventive ap proach to investigation. So, option C is the correct answer. Other options are irrelevant and are be yond the scope of this passage.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 53,
    "passage": "  Over the past few decades, American parents have been pressured into making a costly wager: If they sacrifice their hobbies, interests, and friendships to devote as much time and as many resources as possible to parenting, they might be able to launch their children into stable adulthood. While this gamble sometimes pays off, parents who give themselves over to this intensive form of child-rearing may find themselves at a loss when their children are grown and don’t need them as much. Prior generations didn’t need to be as preoccupied with their children’s well-being or future. Growing up in Dayton, Ohio, in the 1960s, my brothers and I were as luxuriously removed from our parents’ minds as they were from ours. It was the gilded age of childhood freedom. My brothers and I consumed hours of television and ate staggering amounts of sugar—for breakfast. We vanished each summer morning, biked back for lunch, and then disappeared again ’til dusk. My parents also had a life. My mother played mah-jongg weekly with ‘the girls’ and went out every weekend with my father without calling it ‘date night’. My dad played squash on weekends at the downtown YMCA and didn’t seem to worry about whether my brothers and I felt neglected. The amount of time they spent on activities and with people outside the family was common for that era. The sociologist Paul Amato has found that couples in my parents’ generation ‘had 51 percent more friends, were 39 percent more likely to share friends with their spouse, had 168 percent more organisational memberships, and were 133 percent more likely to share those affiliations with their spouse’ than those born in 1960 and after. My parents were likely more relaxed than the generations that followed them because they could assume that their kids would do better than they did, just as they were doing better than their own parents. ‘From 1950 to 1970, the yearly income of the median worker more than doubled, and those at the bottom of the earnings distribution saw their earnings increase even more’, writes the Stanford sociologist Marianne Cooper in her book, Cut Adrift: Families in Insecure Times. In addition, ‘the number of low-income students attending universities nearly doubled between 1965 and 1971’. There was still poverty in rural areas, and racial discrimination still restricted opportunities for many. However, segregation was slowly decreasing, and income distribution was becoming more equal. Outside agriculture and temporary-work industries, employers typically provided health insurance, and many jobs guaranteed a pension. But as inflation, economic stagnation, and fears of communism rose in the 1970s, notions of restructuring the economy took hold, including a free market unhindered by government regulation. By the 1980s, businesses and the government were well on their way to ending the social contract that benefited Baby Boomers’ parents. The Yale political scientist Jacob Hacker described this transformation as the ‘great risk shift’— where economic and health risks were ‘offloaded by government and corporations onto the increasingly fragile balance sheets of workers and their families’. For example, from 1980 to 2004, ‘the number of workers covered by a traditional … retirement pension decreased from 60 percent to 11 percent’, Cooper writes in Cut Adrift. Job-based health coverage provides far less protection to U.S. workers and their dependents than it once did. Today, the average middle-class married couple with children in the U.S. works an additional 15 weeks of full-time employment each year compared with couples in 1975. ‘The financial and emotional burden on families has grown in ways that were almost Reading Comprehension – Basic Levelunimaginable just a half-century ago’, writes the University of Pennsylvania sociologist Frank Furstenberg. Parents’ anxiety about financial security and the world that awaits their kids pushed American households into a frenzy of work and parenting, seemingly causing many to jettison friendships and activities to create more time to supervise and advance their kids.",
    "ImageID": "",
    "question": "The primary argument of the passage is that:",
    "options": {
      "a": "The parents in the 1960s enjoyed a more luxurious and relaxed life than today’s parents.",
      "b": "The children in the 1960s enjoyed a more luxurious and relaxed life than today’s children.",
      "c": "Inequality has seemingly caused many American parents to jettison friendships and activities to invest more resources in their kids.",
      "d": "The financial and emotional burden on families has grown in ways that were almost unimaginable just a half-century ago."
    },
    "answer": "c",
    "explanation": "Points made in options A, B, and D are the arguments made to support the main argument of the passage, which is men tioned in option C. The author compares parenting in the 1960s and 70s with modern-day parent ing, only to prove that modern-day par ents are losing a slice of their own life while raising their children. Hence, option C is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 54,
    "passage": "  Over the past few decades, American parents have been pressured into making a costly wager: If they sacrifice their hobbies, interests, and friendships to devote as much time and as many resources as possible to parenting, they might be able to launch their children into stable adulthood. While this gamble sometimes pays off, parents who give themselves over to this intensive form of child-rearing may find themselves at a loss when their children are grown and don’t need them as much. Prior generations didn’t need to be as preoccupied with their children’s well-being or future. Growing up in Dayton, Ohio, in the 1960s, my brothers and I were as luxuriously removed from our parents’ minds as they were from ours. It was the gilded age of childhood freedom. My brothers and I consumed hours of television and ate staggering amounts of sugar—for breakfast. We vanished each summer morning, biked back for lunch, and then disappeared again ’til dusk. My parents also had a life. My mother played mah-jongg weekly with ‘the girls’ and went out every weekend with my father without calling it ‘date night’. My dad played squash on weekends at the downtown YMCA and didn’t seem to worry about whether my brothers and I felt neglected. The amount of time they spent on activities and with people outside the family was common for that era. The sociologist Paul Amato has found that couples in my parents’ generation ‘had 51 percent more friends, were 39 percent more likely to share friends with their spouse, had 168 percent more organisational memberships, and were 133 percent more likely to share those affiliations with their spouse’ than those born in 1960 and after. My parents were likely more relaxed than the generations that followed them because they could assume that their kids would do better than they did, just as they were doing better than their own parents. ‘From 1950 to 1970, the yearly income of the median worker more than doubled, and those at the bottom of the earnings distribution saw their earnings increase even more’, writes the Stanford sociologist Marianne Cooper in her book, Cut Adrift: Families in Insecure Times. In addition, ‘the number of low-income students attending universities nearly doubled between 1965 and 1971’. There was still poverty in rural areas, and racial discrimination still restricted opportunities for many. However, segregation was slowly decreasing, and income distribution was becoming more equal. Outside agriculture and temporary-work industries, employers typically provided health insurance, and many jobs guaranteed a pension. But as inflation, economic stagnation, and fears of communism rose in the 1970s, notions of restructuring the economy took hold, including a free market unhindered by government regulation. By the 1980s, businesses and the government were well on their way to ending the social contract that benefited Baby Boomers’ parents. The Yale political scientist Jacob Hacker described this transformation as the ‘great risk shift’— where economic and health risks were ‘offloaded by government and corporations onto the increasingly fragile balance sheets of workers and their families’. For example, from 1980 to 2004, ‘the number of workers covered by a traditional … retirement pension decreased from 60 percent to 11 percent’, Cooper writes in Cut Adrift. Job-based health coverage provides far less protection to U.S. workers and their dependents than it once did. Today, the average middle-class married couple with children in the U.S. works an additional 15 weeks of full-time employment each year compared with couples in 1975. ‘The financial and emotional burden on families has grown in ways that were almost Reading Comprehension – Basic Levelunimaginable just a half-century ago’, writes the University of Pennsylvania sociologist Frank Furstenberg. Parents’ anxiety about financial security and the world that awaits their kids pushed American households into a frenzy of work and parenting, seemingly causing many to jettison friendships and activities to create more time to supervise and advance their kids.",
    "ImageID": "",
    "question": "All of the following are mentioned as reasons behind the more relaxed and tension free life of the parents as well as children in the 1960s, except:",
    "options": {
      "a": "The parents in those days assumed that their kids would naturally do better than they themselves had done at that age.",
      "b": "In that era, the earnings of the low er-income group and median work ers increased significantly.",
      "c": "Employers typically provided health insurance, and many jobs were guar anteed a pension.",
      "d": "Parents in that era had 51 percent more friends, were 39 percent more likely to share friends with their spouse, had 168 percent more organ isational memberships, and were 133 percent more likely to share those"
    },
    "answer": "d",
    "explanation": "Statements in options A, B, and C defi nitely serve as reasons behind a more fulfilled life of parents and children in those days, as indicated in the fourth paragraph of the passage. Option D, though true, isn’t the reason but the outcome itself. Because of the reasons mentioned in options A, B, and C, the outcome men tioned in option D was possible.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 55,
    "passage": "  Over the past few decades, American parents have been pressured into making a costly wager: If they sacrifice their hobbies, interests, and friendships to devote as much time and as many resources as possible to parenting, they might be able to launch their children into stable adulthood. While this gamble sometimes pays off, parents who give themselves over to this intensive form of child-rearing may find themselves at a loss when their children are grown and don’t need them as much. Prior generations didn’t need to be as preoccupied with their children’s well-being or future. Growing up in Dayton, Ohio, in the 1960s, my brothers and I were as luxuriously removed from our parents’ minds as they were from ours. It was the gilded age of childhood freedom. My brothers and I consumed hours of television and ate staggering amounts of sugar—for breakfast. We vanished each summer morning, biked back for lunch, and then disappeared again ’til dusk. My parents also had a life. My mother played mah-jongg weekly with ‘the girls’ and went out every weekend with my father without calling it ‘date night’. My dad played squash on weekends at the downtown YMCA and didn’t seem to worry about whether my brothers and I felt neglected. The amount of time they spent on activities and with people outside the family was common for that era. The sociologist Paul Amato has found that couples in my parents’ generation ‘had 51 percent more friends, were 39 percent more likely to share friends with their spouse, had 168 percent more organisational memberships, and were 133 percent more likely to share those affiliations with their spouse’ than those born in 1960 and after. My parents were likely more relaxed than the generations that followed them because they could assume that their kids would do better than they did, just as they were doing better than their own parents. ‘From 1950 to 1970, the yearly income of the median worker more than doubled, and those at the bottom of the earnings distribution saw their earnings increase even more’, writes the Stanford sociologist Marianne Cooper in her book, Cut Adrift: Families in Insecure Times. In addition, ‘the number of low-income students attending universities nearly doubled between 1965 and 1971’. There was still poverty in rural areas, and racial discrimination still restricted opportunities for many. However, segregation was slowly decreasing, and income distribution was becoming more equal. Outside agriculture and temporary-work industries, employers typically provided health insurance, and many jobs guaranteed a pension. But as inflation, economic stagnation, and fears of communism rose in the 1970s, notions of restructuring the economy took hold, including a free market unhindered by government regulation. By the 1980s, businesses and the government were well on their way to ending the social contract that benefited Baby Boomers’ parents. The Yale political scientist Jacob Hacker described this transformation as the ‘great risk shift’— where economic and health risks were ‘offloaded by government and corporations onto the increasingly fragile balance sheets of workers and their families’. For example, from 1980 to 2004, ‘the number of workers covered by a traditional … retirement pension decreased from 60 percent to 11 percent’, Cooper writes in Cut Adrift. Job-based health coverage provides far less protection to U.S. workers and their dependents than it once did. Today, the average middle-class married couple with children in the U.S. works an additional 15 weeks of full-time employment each year compared with couples in 1975. ‘The financial and emotional burden on families has grown in ways that were almost Reading Comprehension – Basic Levelunimaginable just a half-century ago’, writes the University of Pennsylvania sociologist Frank Furstenberg. Parents’ anxiety about financial security and the world that awaits their kids pushed American households into a frenzy of work and parenting, seemingly causing many to jettison friendships and activities to create more time to supervise and advance their kids.",
    "ImageID": "",
    "question": "According to the passage, which of the following could possibly be the reasons for the challenging financial conditions of the parents after the 70s? I. II. Rise of capitalism and loosening grip of the government on the corporate. Businesses and government ending the social contract that benefited parents.",
    "options": {
      "a": "Only I",
      "b": "Only II",
      "c": "Both I and II",
      "d": "Neither I nor II"
    },
    "answer": "c",
    "explanation": "Both the reasons are mentioned in the f ifth paragraph of the passage. While the f irst reason has to be inferred, the sec ond reason has been mentioned directly.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 56,
    "passage": "  Over the past few decades, American parents have been pressured into making a costly wager: If they sacrifice their hobbies, interests, and friendships to devote as much time and as many resources as possible to parenting, they might be able to launch their children into stable adulthood. While this gamble sometimes pays off, parents who give themselves over to this intensive form of child-rearing may find themselves at a loss when their children are grown and don’t need them as much. Prior generations didn’t need to be as preoccupied with their children’s well-being or future. Growing up in Dayton, Ohio, in the 1960s, my brothers and I were as luxuriously removed from our parents’ minds as they were from ours. It was the gilded age of childhood freedom. My brothers and I consumed hours of television and ate staggering amounts of sugar—for breakfast. We vanished each summer morning, biked back for lunch, and then disappeared again ’til dusk. My parents also had a life. My mother played mah-jongg weekly with ‘the girls’ and went out every weekend with my father without calling it ‘date night’. My dad played squash on weekends at the downtown YMCA and didn’t seem to worry about whether my brothers and I felt neglected. The amount of time they spent on activities and with people outside the family was common for that era. The sociologist Paul Amato has found that couples in my parents’ generation ‘had 51 percent more friends, were 39 percent more likely to share friends with their spouse, had 168 percent more organisational memberships, and were 133 percent more likely to share those affiliations with their spouse’ than those born in 1960 and after. My parents were likely more relaxed than the generations that followed them because they could assume that their kids would do better than they did, just as they were doing better than their own parents. ‘From 1950 to 1970, the yearly income of the median worker more than doubled, and those at the bottom of the earnings distribution saw their earnings increase even more’, writes the Stanford sociologist Marianne Cooper in her book, Cut Adrift: Families in Insecure Times. In addition, ‘the number of low-income students attending universities nearly doubled between 1965 and 1971’. There was still poverty in rural areas, and racial discrimination still restricted opportunities for many. However, segregation was slowly decreasing, and income distribution was becoming more equal. Outside agriculture and temporary-work industries, employers typically provided health insurance, and many jobs guaranteed a pension. But as inflation, economic stagnation, and fears of communism rose in the 1970s, notions of restructuring the economy took hold, including a free market unhindered by government regulation. By the 1980s, businesses and the government were well on their way to ending the social contract that benefited Baby Boomers’ parents. The Yale political scientist Jacob Hacker described this transformation as the ‘great risk shift’— where economic and health risks were ‘offloaded by government and corporations onto the increasingly fragile balance sheets of workers and their families’. For example, from 1980 to 2004, ‘the number of workers covered by a traditional … retirement pension decreased from 60 percent to 11 percent’, Cooper writes in Cut Adrift. Job-based health coverage provides far less protection to U.S. workers and their dependents than it once did. Today, the average middle-class married couple with children in the U.S. works an additional 15 weeks of full-time employment each year compared with couples in 1975. ‘The financial and emotional burden on families has grown in ways that were almost Reading Comprehension – Basic Levelunimaginable just a half-century ago’, writes the University of Pennsylvania sociologist Frank Furstenberg. Parents’ anxiety about financial security and the world that awaits their kids pushed American households into a frenzy of work and parenting, seemingly causing many to jettison friendships and activities to create more time to supervise and advance their kids.",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "Parents 60 years ago felt more secure f inancially than do today’s parents.",
      "b": "Sixty years ago, parents did not take child-rearing seriously.",
      "c": "Inflation, economic stagnation, and fears of communism resulted in un equal distribution of income.",
      "d": "Parents sacrificing their hobbies, in terests, and friendships don’t guar antee stable adulthood for their children."
    },
    "answer": "b",
    "explanation": "Option D can be inferred from the first paragraph. Option C can be inferred from the fifth paragraph. Option A can be inferred from the fourth paragraph. And though parents in the 1960s were more relaxed, option B would make a negative inference. Hence, option B is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 57,
    "passage": "  What’s your favourite Woody Allen movie’? Dylan Farrow asked the readers of The New York Times, before giving her account of Allen molesting her when she was seven years old. She challenged the continued acclaim for Allen’s movies: ‘Imagine your seven-year-old daughter being led into an attic by Woody Allen … Are you imagining that? Now, what’s your favourite Woody Allen movie’? Farrow’s essay, published in 2014, presaged the #MeToo era when sexual offences committed by film and entertainment stars such as Bill Cosby, Harvey Weinstein, Louis CK, and others burst into larger public awareness. The grossness of their crimes, combined with the celebratedness of their art, prompted vociferous debate. In the words of the television critic Emily Nussbaum: ‘What should we do with the art of terrible men’? What’s your favourite Ronald Fisher paper? Before you answer, you should know: Fisher, a British statistician, and geneticist, served on the Committee for Legalising Eugenic Sterilisation, and advocated for the involuntary sterilisation of the ‘feeble-minded’. In 1948, he wrote a letter of support for a German colleague, Otmar von Verschuer, a Nazi scientist who received human body parts from twins murdered by Josef Mengele at Auschwitz. It’s clear from the letter that the atrocities of the Nazi regime hadn’t dampened Fisher’s enthusiasm for eugenics. Now, what’s your favourite Ronald Fisher paper? Mine is ‘The Correlation Between Relatives on the Supposition of Mendelian Inheritance’ (1918). In it, Fisher proposed that human characteristics are influenced by many different genetic factors, each of which has a small effect. He was right about that, even as he was so terribly wrong about the evils of Nazism. The grossness of Fisher’s eugenic beliefs, combined with the brilliance of his  scientific observations, raises the question: what do we do with the science of terrible men? This question is personal. My research is in the area of social science genetics, which aims to use information about people’s DNA in order to understand why their lives turn out differently. Every day, every paper, every calculation of my professional life (and, indeed, of any working scientist who uses basic statistical concepts such as variance) has been spent using scientific tools created by the same people who worked to bring violence and suffering to vulnerable people’s lives. For decades, the primary tool of social science genetics was the twin study, which compares identical twins to fraternal twins in order to make inferences about how much of the variation between people is due to the genetic differences between them. Twin studies, however, make some simplifying assumptions, such as the assumption that identical twins are not treated more similarly than fraternal twins just because their parents know they are identical. Despite being debated ad nauseam for decades, these assumptions are still controversial. More recently, then, researchers have begun to rely more on a method called the genome-wide association study (GWAS), which directly measures part of a person’s DNA sequence. A GWAS aims to identify specific bits of DNA that are associated with being higher or lower on some characteristic you can measure about a person (such as their height). For the most part, GWASs have been largely limited to people whose recent genetic ancestors all lived on the European continent and who therefore are very likely to identify as white according to the social rules by which racial identity is assigned. Some researchers use the tools of twin studies and GWAS to study how genetic differences are related to physical health outcomes, such as cataracts or cancer. Others study mental health disorders, such as Reading Comprehension – Basic Levelschizophrenia or anorexia nervosa. In contrast, my lab—like other groups doing work in social science genetics—uses these methods to study inequalities between people in outcomes that are socially valued and often moralised.",
    "ImageID": "",
    "question": "The author’s primary purpose is to:",
    "options": {
      "a": "Highlight the negative side of the art ists and scientists.",
      "b": "Discuss the domain of social science genetics.",
      "c": "Compare twin study and genome- wide association study",
      "d": "Discuss the effect of genetics on hu man characteristics."
    },
    "answer": "d",
    "explanation": "Option A has been used as the point of reference for the author’s main argu ment, but it is not the main argument in itself. Social science genetics, again, is not the subject of discussion here but just a means to analyse human characteristics. So, options B and C are incorrect. Option D is the correct answer here, as it catches the central theme of the passage.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 58,
    "passage": "  What’s your favourite Woody Allen movie’? Dylan Farrow asked the readers of The New York Times, before giving her account of Allen molesting her when she was seven years old. She challenged the continued acclaim for Allen’s movies: ‘Imagine your seven-year-old daughter being led into an attic by Woody Allen … Are you imagining that? Now, what’s your favourite Woody Allen movie’? Farrow’s essay, published in 2014, presaged the #MeToo era when sexual offences committed by film and entertainment stars such as Bill Cosby, Harvey Weinstein, Louis CK, and others burst into larger public awareness. The grossness of their crimes, combined with the celebratedness of their art, prompted vociferous debate. In the words of the television critic Emily Nussbaum: ‘What should we do with the art of terrible men’? What’s your favourite Ronald Fisher paper? Before you answer, you should know: Fisher, a British statistician, and geneticist, served on the Committee for Legalising Eugenic Sterilisation, and advocated for the involuntary sterilisation of the ‘feeble-minded’. In 1948, he wrote a letter of support for a German colleague, Otmar von Verschuer, a Nazi scientist who received human body parts from twins murdered by Josef Mengele at Auschwitz. It’s clear from the letter that the atrocities of the Nazi regime hadn’t dampened Fisher’s enthusiasm for eugenics. Now, what’s your favourite Ronald Fisher paper? Mine is ‘The Correlation Between Relatives on the Supposition of Mendelian Inheritance’ (1918). In it, Fisher proposed that human characteristics are influenced by many different genetic factors, each of which has a small effect. He was right about that, even as he was so terribly wrong about the evils of Nazism. The grossness of Fisher’s eugenic beliefs, combined with the brilliance of his  scientific observations, raises the question: what do we do with the science of terrible men? This question is personal. My research is in the area of social science genetics, which aims to use information about people’s DNA in order to understand why their lives turn out differently. Every day, every paper, every calculation of my professional life (and, indeed, of any working scientist who uses basic statistical concepts such as variance) has been spent using scientific tools created by the same people who worked to bring violence and suffering to vulnerable people’s lives. For decades, the primary tool of social science genetics was the twin study, which compares identical twins to fraternal twins in order to make inferences about how much of the variation between people is due to the genetic differences between them. Twin studies, however, make some simplifying assumptions, such as the assumption that identical twins are not treated more similarly than fraternal twins just because their parents know they are identical. Despite being debated ad nauseam for decades, these assumptions are still controversial. More recently, then, researchers have begun to rely more on a method called the genome-wide association study (GWAS), which directly measures part of a person’s DNA sequence. A GWAS aims to identify specific bits of DNA that are associated with being higher or lower on some characteristic you can measure about a person (such as their height). For the most part, GWASs have been largely limited to people whose recent genetic ancestors all lived on the European continent and who therefore are very likely to identify as white according to the social rules by which racial identity is assigned. Some researchers use the tools of twin studies and GWAS to study how genetic differences are related to physical health outcomes, such as cataracts or cancer. Others study mental health disorders, such as Reading Comprehension – Basic Levelschizophrenia or anorexia nervosa. In contrast, my lab—like other groups doing work in social science genetics—uses these methods to study inequalities between people in outcomes that are socially valued and often moralised.",
    "ImageID": "",
    "question": "The author’s attitude toward Woody Allen and Ronald Fisher can be best de scribed as:",
    "options": {
      "a": "Apprehensive and disapproving",
      "b": "Concerned and understanding",
      "c": "Unsympathetic and annoyed",
      "d": "Enthusiastic but apprehensive"
    },
    "answer": "d",
    "explanation": "He has taken the two, Woody Allen and Ronald Fisher, as examples of his discussion. He considers both of them to be great in their respective f ields, yet he seems more interested in their downsides. That is how such brilliant people can be inclined towards violence. So, option D describes his views the best.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 59,
    "passage": "  What’s your favourite Woody Allen movie’? Dylan Farrow asked the readers of The New York Times, before giving her account of Allen molesting her when she was seven years old. She challenged the continued acclaim for Allen’s movies: ‘Imagine your seven-year-old daughter being led into an attic by Woody Allen … Are you imagining that? Now, what’s your favourite Woody Allen movie’? Farrow’s essay, published in 2014, presaged the #MeToo era when sexual offences committed by film and entertainment stars such as Bill Cosby, Harvey Weinstein, Louis CK, and others burst into larger public awareness. The grossness of their crimes, combined with the celebratedness of their art, prompted vociferous debate. In the words of the television critic Emily Nussbaum: ‘What should we do with the art of terrible men’? What’s your favourite Ronald Fisher paper? Before you answer, you should know: Fisher, a British statistician, and geneticist, served on the Committee for Legalising Eugenic Sterilisation, and advocated for the involuntary sterilisation of the ‘feeble-minded’. In 1948, he wrote a letter of support for a German colleague, Otmar von Verschuer, a Nazi scientist who received human body parts from twins murdered by Josef Mengele at Auschwitz. It’s clear from the letter that the atrocities of the Nazi regime hadn’t dampened Fisher’s enthusiasm for eugenics. Now, what’s your favourite Ronald Fisher paper? Mine is ‘The Correlation Between Relatives on the Supposition of Mendelian Inheritance’ (1918). In it, Fisher proposed that human characteristics are influenced by many different genetic factors, each of which has a small effect. He was right about that, even as he was so terribly wrong about the evils of Nazism. The grossness of Fisher’s eugenic beliefs, combined with the brilliance of his  scientific observations, raises the question: what do we do with the science of terrible men? This question is personal. My research is in the area of social science genetics, which aims to use information about people’s DNA in order to understand why their lives turn out differently. Every day, every paper, every calculation of my professional life (and, indeed, of any working scientist who uses basic statistical concepts such as variance) has been spent using scientific tools created by the same people who worked to bring violence and suffering to vulnerable people’s lives. For decades, the primary tool of social science genetics was the twin study, which compares identical twins to fraternal twins in order to make inferences about how much of the variation between people is due to the genetic differences between them. Twin studies, however, make some simplifying assumptions, such as the assumption that identical twins are not treated more similarly than fraternal twins just because their parents know they are identical. Despite being debated ad nauseam for decades, these assumptions are still controversial. More recently, then, researchers have begun to rely more on a method called the genome-wide association study (GWAS), which directly measures part of a person’s DNA sequence. A GWAS aims to identify specific bits of DNA that are associated with being higher or lower on some characteristic you can measure about a person (such as their height). For the most part, GWASs have been largely limited to people whose recent genetic ancestors all lived on the European continent and who therefore are very likely to identify as white according to the social rules by which racial identity is assigned. Some researchers use the tools of twin studies and GWAS to study how genetic differences are related to physical health outcomes, such as cataracts or cancer. Others study mental health disorders, such as Reading Comprehension – Basic Levelschizophrenia or anorexia nervosa. In contrast, my lab—like other groups doing work in social science genetics—uses these methods to study inequalities between people in outcomes that are socially valued and often moralised.",
    "ImageID": "",
    "question": "Which of the following is true according to the passage?",
    "options": {
      "a": "The author is likely to use the twin study method in his own research.",
      "b": "The author is likely to use the ge nome-wide association study meth od in his research.",
      "c": "The author is likely to use none in his research",
      "d": "The author is likely to use both in his research."
    },
    "answer": "d",
    "explanation": "By reading the last paragraph of the pas sage, it is clear that the author would use both methods. Hence, option D is correct.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 60,
    "passage": "  What’s your favourite Woody Allen movie’? Dylan Farrow asked the readers of The New York Times, before giving her account of Allen molesting her when she was seven years old. She challenged the continued acclaim for Allen’s movies: ‘Imagine your seven-year-old daughter being led into an attic by Woody Allen … Are you imagining that? Now, what’s your favourite Woody Allen movie’? Farrow’s essay, published in 2014, presaged the #MeToo era when sexual offences committed by film and entertainment stars such as Bill Cosby, Harvey Weinstein, Louis CK, and others burst into larger public awareness. The grossness of their crimes, combined with the celebratedness of their art, prompted vociferous debate. In the words of the television critic Emily Nussbaum: ‘What should we do with the art of terrible men’? What’s your favourite Ronald Fisher paper? Before you answer, you should know: Fisher, a British statistician, and geneticist, served on the Committee for Legalising Eugenic Sterilisation, and advocated for the involuntary sterilisation of the ‘feeble-minded’. In 1948, he wrote a letter of support for a German colleague, Otmar von Verschuer, a Nazi scientist who received human body parts from twins murdered by Josef Mengele at Auschwitz. It’s clear from the letter that the atrocities of the Nazi regime hadn’t dampened Fisher’s enthusiasm for eugenics. Now, what’s your favourite Ronald Fisher paper? Mine is ‘The Correlation Between Relatives on the Supposition of Mendelian Inheritance’ (1918). In it, Fisher proposed that human characteristics are influenced by many different genetic factors, each of which has a small effect. He was right about that, even as he was so terribly wrong about the evils of Nazism. The grossness of Fisher’s eugenic beliefs, combined with the brilliance of his  scientific observations, raises the question: what do we do with the science of terrible men? This question is personal. My research is in the area of social science genetics, which aims to use information about people’s DNA in order to understand why their lives turn out differently. Every day, every paper, every calculation of my professional life (and, indeed, of any working scientist who uses basic statistical concepts such as variance) has been spent using scientific tools created by the same people who worked to bring violence and suffering to vulnerable people’s lives. For decades, the primary tool of social science genetics was the twin study, which compares identical twins to fraternal twins in order to make inferences about how much of the variation between people is due to the genetic differences between them. Twin studies, however, make some simplifying assumptions, such as the assumption that identical twins are not treated more similarly than fraternal twins just because their parents know they are identical. Despite being debated ad nauseam for decades, these assumptions are still controversial. More recently, then, researchers have begun to rely more on a method called the genome-wide association study (GWAS), which directly measures part of a person’s DNA sequence. A GWAS aims to identify specific bits of DNA that are associated with being higher or lower on some characteristic you can measure about a person (such as their height). For the most part, GWASs have been largely limited to people whose recent genetic ancestors all lived on the European continent and who therefore are very likely to identify as white according to the social rules by which racial identity is assigned. Some researchers use the tools of twin studies and GWAS to study how genetic differences are related to physical health outcomes, such as cataracts or cancer. Others study mental health disorders, such as Reading Comprehension – Basic Levelschizophrenia or anorexia nervosa. In contrast, my lab—like other groups doing work in social science genetics—uses these methods to study inequalities between people in outcomes that are socially valued and often moralised.",
    "ImageID": "",
    "question": "Which of the following is true according to the author?",
    "options": {
      "a": "Teenagers who score higher on intel ligence tests tend to have sex earlier.",
      "b": "Teenagers who delay having sex tend to be more likely to commit crimes.",
      "c": "Teenagers with certain DNA patterns are more likely to get assigned to certain mathematics classes.",
      "d": "Teenagers who do not get a girlfriend/ boyfriend are less likely to succeed in life."
    },
    "answer": "c",
    "explanation": "The question demands a careful reading of the last paragraph. Statements written in options A and B are the opposite of what is written in the passage. Option D is irrelevant and not covered in the passage. Hence, option C is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 61,
    "passage": "  A mathematician, a philosopher, and a gambler walk into a bar. As the barman pulls each of them a beer, he decides to stir up a bit of trouble. He pulls a die from his pocket and rolls it ostentatiously on the bar counter: it comes up with a 1. The mathematician says: ‘The probability that 1 would come up is 1/6, and at the next throw it will be the same. If we roll the die infinitely many times, the relative frequency of the number 1 will converge to 1/6, that is, to one occurrence every six throws’. The philosopher strokes her chin and remarks: ‘Well, this doesn’t mean we won’t get the number at the next throw. Actually, it’s physically possible to have the same number on the next 1,000 throws, although that’s highly improbable’. The gambler says: ‘I know you’re both right, but I wouldn’t bet on that number for the next throw’. ‘Why not’? asks the mathematician. ‘Because I trust mathematics, and so I expect that number to come up about once every six throws’, the gambler answers. ‘Having the same number twice in a row is a rare event. Why would that happen right now’? The gambler’s ‘argument’ is a mix of conceptual inadequacy, misinterpretation, irrelevant application of mathematics, and misleading use of language. She thinks that she has some new information that will increase her chances of winning—that there are now five numbers to choose from instead of six, and as such the randomness of the game is ‘losing its strength’. This sort of belief reinforces a gambler’s impulse to bet—it won’t make her quit the game, but rather continue gambling. Some people believe that confronting problem gamblers with the ‘reality’ of mathematics—a kind of mathematical counselling, often called ‘facing the odds’—can help them overcome it. After all, since our earliest school days, many of us have learned to trust mathematics as the provider of necessary and logical truths. But we also trust our senses, as well as the patterns we discern from our experiences and the words we use to communicate with one another. Mathematics has its own language, and the extent to which we should trust mathematics depends on how we interpret these words, especially when applied to physical reality. In fact, understanding gamblers’ relationship to maths reveals something deeper about the nature of mathematics itself. All games of chance—whether casino games such as roulette, craps, blackjack, and slots, or lottery and bingo, or card games such as poker or bridge—rely on certain basic statistical and probabilistic models. Uncertainty is built into them, which is what makes games ‘fun’ to play and also explains their continued existence. Casino games would never run if ‘the house’ wasn’t confident that they’d always win in the end. The mathematics of the games, including their rules and payout schedules, assures the house will profit in aggregate, regardless of individual behaviour. In mathematical terms, this guarantee is expressed through the fact that the house edge (HE) of a game is positive. The expected value of a bet (EV) is defined as follows: (Probability of winning) × (payoff if you win) + (probability of losing) × (loss if you lose) The HE of a game is defined as the opposite of the expected value calculated for all possible bets (HE = −EV). For example, in European Roulette, a wheel spins and you have to decide where you think a small ball will land. There are 37 numbers (0 to 36). If you bet $1 on one number (called a straightup bet), the payoff is 35 times what you bet, and the probability of winning is 1/37. So the EV of that bet is: (1/37) × $35 + (36/37) × (−$1) That is about −$0.027 or, as a percentage,",
    "ImageID": "",
    "question": "7 percent of the initial bet. EV can be read as an average; in our example, you might ex pect to lose on average $2.70 at every 100 plays with that bet over the long run. This means that European Roulette has a house edge of 2.7 percent. This is the house’s share of all the income produced by that game in the form of bets over the long run. From a player’s point of view, a positive house edge should mean that she can’t make a living off that game: over the long run, the house will have an advantage. That’s why a pragmatic principle of safe gambling behaviour is: ‘When you make a satisfactory win, take the money and get out of there’.",
    "options": {},
    "answer": "b",
    "explanation": "It is evident from the gambler’s conver sation with the mathematician and the philosopher that she would bet on any other number except for the number that came up in the first round. So, option B is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 62,
    "passage": "  A mathematician, a philosopher, and a gambler walk into a bar. As the barman pulls each of them a beer, he decides to stir up a bit of trouble. He pulls a die from his pocket and rolls it ostentatiously on the bar counter: it comes up with a 1. The mathematician says: ‘The probability that 1 would come up is 1/6, and at the next throw it will be the same. If we roll the die infinitely many times, the relative frequency of the number 1 will converge to 1/6, that is, to one occurrence every six throws’. The philosopher strokes her chin and remarks: ‘Well, this doesn’t mean we won’t get the number at the next throw. Actually, it’s physically possible to have the same number on the next 1,000 throws, although that’s highly improbable’. The gambler says: ‘I know you’re both right, but I wouldn’t bet on that number for the next throw’. ‘Why not’? asks the mathematician. ‘Because I trust mathematics, and so I expect that number to come up about once every six throws’, the gambler answers. ‘Having the same number twice in a row is a rare event. Why would that happen right now’? The gambler’s ‘argument’ is a mix of conceptual inadequacy, misinterpretation, irrelevant application of mathematics, and misleading use of language. She thinks that she has some new information that will increase her chances of winning—that there are now five numbers to choose from instead of six, and as such the randomness of the game is ‘losing its strength’. This sort of belief reinforces a gambler’s impulse to bet—it won’t make her quit the game, but rather continue gambling. Some people believe that confronting problem gamblers with the ‘reality’ of mathematics—a kind of mathematical counselling, often called ‘facing the odds’—can help them overcome it. After all, since our earliest school days, many of us have learned to trust mathematics as the provider of necessary and logical truths. But we also trust our senses, as well as the patterns we discern from our experiences and the words we use to communicate with one another. Mathematics has its own language, and the extent to which we should trust mathematics depends on how we interpret these words, especially when applied to physical reality. In fact, understanding gamblers’ relationship to maths reveals something deeper about the nature of mathematics itself. All games of chance—whether casino games such as roulette, craps, blackjack, and slots, or lottery and bingo, or card games such as poker or bridge—rely on certain basic statistical and probabilistic models. Uncertainty is built into them, which is what makes games ‘fun’ to play and also explains their continued existence. Casino games would never run if ‘the house’ wasn’t confident that they’d always win in the end. The mathematics of the games, including their rules and payout schedules, assures the house will profit in aggregate, regardless of individual behaviour. In mathematical terms, this guarantee is expressed through the fact that the house edge (HE) of a game is positive. The expected value of a bet (EV) is defined as follows: (Probability of winning) × (payoff if you win) + (probability of losing) × (loss if you lose) The HE of a game is defined as the opposite of the expected value calculated for all possible bets (HE = −EV). For example, in European Roulette, a wheel spins and you have to decide where you think a small ball will land. There are 37 numbers (0 to 36). If you bet $1 on one number (called a straightup bet), the payoff is 35 times what you bet, and the probability of winning is 1/37. So the EV of that bet is: (1/37) × $35 + (36/37) × (−$1) That is about −$0.027 or, as a percentage,",
    "ImageID": "",
    "question": "From the arguments made by the au thor in the passage, it can be inferred that if a gambler, a mathematician, and a philosopher make a straight bet in the game of Roulette, the chance of winning is maximum for:",
    "options": {
      "a": "The mathematician",
      "b": "The philosopher",
      "c": "The gambler",
      "d": "None of these"
    },
    "answer": "d",
    "explanation": "First of all, the mathematics of chance always favours the house; plus, the probability of winning is the same for all three. So, the chance of winning is the same for all of them, and maximum for none of them. Hence option D is the right answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 63,
    "passage": "  A mathematician, a philosopher, and a gambler walk into a bar. As the barman pulls each of them a beer, he decides to stir up a bit of trouble. He pulls a die from his pocket and rolls it ostentatiously on the bar counter: it comes up with a 1. The mathematician says: ‘The probability that 1 would come up is 1/6, and at the next throw it will be the same. If we roll the die infinitely many times, the relative frequency of the number 1 will converge to 1/6, that is, to one occurrence every six throws’. The philosopher strokes her chin and remarks: ‘Well, this doesn’t mean we won’t get the number at the next throw. Actually, it’s physically possible to have the same number on the next 1,000 throws, although that’s highly improbable’. The gambler says: ‘I know you’re both right, but I wouldn’t bet on that number for the next throw’. ‘Why not’? asks the mathematician. ‘Because I trust mathematics, and so I expect that number to come up about once every six throws’, the gambler answers. ‘Having the same number twice in a row is a rare event. Why would that happen right now’? The gambler’s ‘argument’ is a mix of conceptual inadequacy, misinterpretation, irrelevant application of mathematics, and misleading use of language. She thinks that she has some new information that will increase her chances of winning—that there are now five numbers to choose from instead of six, and as such the randomness of the game is ‘losing its strength’. This sort of belief reinforces a gambler’s impulse to bet—it won’t make her quit the game, but rather continue gambling. Some people believe that confronting problem gamblers with the ‘reality’ of mathematics—a kind of mathematical counselling, often called ‘facing the odds’—can help them overcome it. After all, since our earliest school days, many of us have learned to trust mathematics as the provider of necessary and logical truths. But we also trust our senses, as well as the patterns we discern from our experiences and the words we use to communicate with one another. Mathematics has its own language, and the extent to which we should trust mathematics depends on how we interpret these words, especially when applied to physical reality. In fact, understanding gamblers’ relationship to maths reveals something deeper about the nature of mathematics itself. All games of chance—whether casino games such as roulette, craps, blackjack, and slots, or lottery and bingo, or card games such as poker or bridge—rely on certain basic statistical and probabilistic models. Uncertainty is built into them, which is what makes games ‘fun’ to play and also explains their continued existence. Casino games would never run if ‘the house’ wasn’t confident that they’d always win in the end. The mathematics of the games, including their rules and payout schedules, assures the house will profit in aggregate, regardless of individual behaviour. In mathematical terms, this guarantee is expressed through the fact that the house edge (HE) of a game is positive. The expected value of a bet (EV) is defined as follows: (Probability of winning) × (payoff if you win) + (probability of losing) × (loss if you lose) The HE of a game is defined as the opposite of the expected value calculated for all possible bets (HE = −EV). For example, in European Roulette, a wheel spins and you have to decide where you think a small ball will land. There are 37 numbers (0 to 36). If you bet $1 on one number (called a straightup bet), the payoff is 35 times what you bet, and the probability of winning is 1/37. So the EV of that bet is: (1/37) × $35 + (36/37) × (−$1) That is about −$0.027 or, as a percentage,",
    "ImageID": "",
    "question": "If a die is rolled and it comes up with a 2, there is a great possibility",
    "options": {
      "a": "That a gambler would make a bet on 2 for the very next throw.",
      "b": "That a gambler would make a bet on any other number except 2 for the next throw.",
      "c": "That a gambler would never make a bet on 2 for the next five throws.",
      "d": "That a gambler would make a bet on 3 for the next throw."
    },
    "answer": "b",
    "explanation": "It is evident from the gambler’s conver sation with the mathematician and the philosopher that she would bet on any other number except for the number that came up in the first round. So, option B is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 64,
    "passage": "  A mathematician, a philosopher, and a gambler walk into a bar. As the barman pulls each of them a beer, he decides to stir up a bit of trouble. He pulls a die from his pocket and rolls it ostentatiously on the bar counter: it comes up with a 1. The mathematician says: ‘The probability that 1 would come up is 1/6, and at the next throw it will be the same. If we roll the die infinitely many times, the relative frequency of the number 1 will converge to 1/6, that is, to one occurrence every six throws’. The philosopher strokes her chin and remarks: ‘Well, this doesn’t mean we won’t get the number at the next throw. Actually, it’s physically possible to have the same number on the next 1,000 throws, although that’s highly improbable’. The gambler says: ‘I know you’re both right, but I wouldn’t bet on that number for the next throw’. ‘Why not’? asks the mathematician. ‘Because I trust mathematics, and so I expect that number to come up about once every six throws’, the gambler answers. ‘Having the same number twice in a row is a rare event. Why would that happen right now’? The gambler’s ‘argument’ is a mix of conceptual inadequacy, misinterpretation, irrelevant application of mathematics, and misleading use of language. She thinks that she has some new information that will increase her chances of winning—that there are now five numbers to choose from instead of six, and as such the randomness of the game is ‘losing its strength’. This sort of belief reinforces a gambler’s impulse to bet—it won’t make her quit the game, but rather continue gambling. Some people believe that confronting problem gamblers with the ‘reality’ of mathematics—a kind of mathematical counselling, often called ‘facing the odds’—can help them overcome it. After all, since our earliest school days, many of us have learned to trust mathematics as the provider of necessary and logical truths. But we also trust our senses, as well as the patterns we discern from our experiences and the words we use to communicate with one another. Mathematics has its own language, and the extent to which we should trust mathematics depends on how we interpret these words, especially when applied to physical reality. In fact, understanding gamblers’ relationship to maths reveals something deeper about the nature of mathematics itself. All games of chance—whether casino games such as roulette, craps, blackjack, and slots, or lottery and bingo, or card games such as poker or bridge—rely on certain basic statistical and probabilistic models. Uncertainty is built into them, which is what makes games ‘fun’ to play and also explains their continued existence. Casino games would never run if ‘the house’ wasn’t confident that they’d always win in the end. The mathematics of the games, including their rules and payout schedules, assures the house will profit in aggregate, regardless of individual behaviour. In mathematical terms, this guarantee is expressed through the fact that the house edge (HE) of a game is positive. The expected value of a bet (EV) is defined as follows: (Probability of winning) × (payoff if you win) + (probability of losing) × (loss if you lose) The HE of a game is defined as the opposite of the expected value calculated for all possible bets (HE = −EV). For example, in European Roulette, a wheel spins and you have to decide where you think a small ball will land. There are 37 numbers (0 to 36). If you bet $1 on one number (called a straightup bet), the payoff is 35 times what you bet, and the probability of winning is 1/37. So the EV of that bet is: (1/37) × $35 + (36/37) × (−$1) That is about −$0.027 or, as a percentage,",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "Driven by their conceptual inadequa cy, misinterpretation,and irrelevant application of mathematics, gam blers tend to continue betting de spite prolonged losses.",
      "b": "A greater expected value of a bet im plies a greater house edge for that game.",
      "c": "Mathematics has its own language, and good gamblers are fluent in it.",
      "d": "A sound understanding of mathe matics and its principles may help problem gamblers curb their habit."
    },
    "answer": "c",
    "explanation": "Option A can be inferred from the fifth paragraph. Option B can be inferred from the defini tions of expected value and house edge. Option D can also be inferred, as con fronting problem gamblers with the real ity of mathematics is called mathemati cal counselling. Option C cannot be inferred from the passage. Rather it is the opposite of what has been claimed in the passage. Hence, option C is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 65,
    "passage": "  A mathematician, a philosopher, and a gambler walk into a bar. As the barman pulls each of them a beer, he decides to stir up a bit of trouble. He pulls a die from his pocket and rolls it ostentatiously on the bar counter: it comes up with a 1. The mathematician says: ‘The probability that 1 would come up is 1/6, and at the next throw it will be the same. If we roll the die infinitely many times, the relative frequency of the number 1 will converge to 1/6, that is, to one occurrence every six throws’. The philosopher strokes her chin and remarks: ‘Well, this doesn’t mean we won’t get the number at the next throw. Actually, it’s physically possible to have the same number on the next 1,000 throws, although that’s highly improbable’. The gambler says: ‘I know you’re both right, but I wouldn’t bet on that number for the next throw’. ‘Why not’? asks the mathematician. ‘Because I trust mathematics, and so I expect that number to come up about once every six throws’, the gambler answers. ‘Having the same number twice in a row is a rare event. Why would that happen right now’? The gambler’s ‘argument’ is a mix of conceptual inadequacy, misinterpretation, irrelevant application of mathematics, and misleading use of language. She thinks that she has some new information that will increase her chances of winning—that there are now five numbers to choose from instead of six, and as such the randomness of the game is ‘losing its strength’. This sort of belief reinforces a gambler’s impulse to bet—it won’t make her quit the game, but rather continue gambling. Some people believe that confronting problem gamblers with the ‘reality’ of mathematics—a kind of mathematical counselling, often called ‘facing the odds’—can help them overcome it. After all, since our earliest school days, many of us have learned to trust mathematics as the provider of necessary and logical truths. But we also trust our senses, as well as the patterns we discern from our experiences and the words we use to communicate with one another. Mathematics has its own language, and the extent to which we should trust mathematics depends on how we interpret these words, especially when applied to physical reality. In fact, understanding gamblers’ relationship to maths reveals something deeper about the nature of mathematics itself. All games of chance—whether casino games such as roulette, craps, blackjack, and slots, or lottery and bingo, or card games such as poker or bridge—rely on certain basic statistical and probabilistic models. Uncertainty is built into them, which is what makes games ‘fun’ to play and also explains their continued existence. Casino games would never run if ‘the house’ wasn’t confident that they’d always win in the end. The mathematics of the games, including their rules and payout schedules, assures the house will profit in aggregate, regardless of individual behaviour. In mathematical terms, this guarantee is expressed through the fact that the house edge (HE) of a game is positive. The expected value of a bet (EV) is defined as follows: (Probability of winning) × (payoff if you win) + (probability of losing) × (loss if you lose) The HE of a game is defined as the opposite of the expected value calculated for all possible bets (HE = −EV). For example, in European Roulette, a wheel spins and you have to decide where you think a small ball will land. There are 37 numbers (0 to 36). If you bet $1 on one number (called a straightup bet), the payoff is 35 times what you bet, and the probability of winning is 1/37. So the EV of that bet is: (1/37) × $35 + (36/37) × (−$1) That is about −$0.027 or, as a percentage,",
    "ImageID": "",
    "question": "In the last paragraph of the passage, the statement—‘A positive house edge should mean that she can’t make a living off that game’—implies that:",
    "options": {
      "a": "A gambler can never win a game with a positive house edge.",
      "b": "Gambling should not be adopted to make a living.",
      "c": "After a satisfactory win, a gambler should walk out with that money.",
      "d": "Many gamblers gamble to make a liv ing out of it."
    },
    "answer": "b",
    "explanation": "Option A is incorrect as the mathematics of gambling doesn’t predict the outcome of a particular game. It only predicts the outcome in the long run- which is always in favour of the house. Option C is incorrect as it has got noth ing to do with the given statement. It has been stated by the author as a safety measure for gamblers. Option D is incorrect as it would be an assumption. Option B is the correct answer in the context of the given statement as the au thor continues and says that the houses will always have an advantage in the long run. So, gambling can’t be taken as a way of making a living in the long run.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 66,
    "passage": "  A mathematician, a philosopher, and a gambler walk into a bar. As the barman pulls each of them a beer, he decides to stir up a bit of trouble. He pulls a die from his pocket and rolls it ostentatiously on the bar counter: it comes up with a 1. The mathematician says: ‘The probability that 1 would come up is 1/6, and at the next throw it will be the same. If we roll the die infinitely many times, the relative frequency of the number 1 will converge to 1/6, that is, to one occurrence every six throws’. The philosopher strokes her chin and remarks: ‘Well, this doesn’t mean we won’t get the number at the next throw. Actually, it’s physically possible to have the same number on the next 1,000 throws, although that’s highly improbable’. The gambler says: ‘I know you’re both right, but I wouldn’t bet on that number for the next throw’. ‘Why not’? asks the mathematician. ‘Because I trust mathematics, and so I expect that number to come up about once every six throws’, the gambler answers. ‘Having the same number twice in a row is a rare event. Why would that happen right now’? The gambler’s ‘argument’ is a mix of conceptual inadequacy, misinterpretation, irrelevant application of mathematics, and misleading use of language. She thinks that she has some new information that will increase her chances of winning—that there are now five numbers to choose from instead of six, and as such the randomness of the game is ‘losing its strength’. This sort of belief reinforces a gambler’s impulse to bet—it won’t make her quit the game, but rather continue gambling. Some people believe that confronting problem gamblers with the ‘reality’ of mathematics—a kind of mathematical counselling, often called ‘facing the odds’—can help them overcome it. After all, since our earliest school days, many of us have learned to trust mathematics as the provider of necessary and logical truths. But we also trust our senses, as well as the patterns we discern from our experiences and the words we use to communicate with one another. Mathematics has its own language, and the extent to which we should trust mathematics depends on how we interpret these words, especially when applied to physical reality. In fact, understanding gamblers’ relationship to maths reveals something deeper about the nature of mathematics itself. All games of chance—whether casino games such as roulette, craps, blackjack, and slots, or lottery and bingo, or card games such as poker or bridge—rely on certain basic statistical and probabilistic models. Uncertainty is built into them, which is what makes games ‘fun’ to play and also explains their continued existence. Casino games would never run if ‘the house’ wasn’t confident that they’d always win in the end. The mathematics of the games, including their rules and payout schedules, assures the house will profit in aggregate, regardless of individual behaviour. In mathematical terms, this guarantee is expressed through the fact that the house edge (HE) of a game is positive. The expected value of a bet (EV) is defined as follows: (Probability of winning) × (payoff if you win) + (probability of losing) × (loss if you lose) The HE of a game is defined as the opposite of the expected value calculated for all possible bets (HE = −EV). For example, in European Roulette, a wheel spins and you have to decide where you think a small ball will land. There are 37 numbers (0 to 36). If you bet $1 on one number (called a straightup bet), the payoff is 35 times what you bet, and the probability of winning is 1/37. So the EV of that bet is: (1/37) × $35 + (36/37) × (−$1) That is about −$0.027 or, as a percentage,",
    "ImageID": "",
    "question": "What could be a suitable title for the passage?",
    "options": {
      "a": "Mathematics of gambling",
      "b": "Philosophy of gambling",
      "c": "Mathematics and Gambling",
      "d": "Mathematics of chance"
    },
    "answer": "a",
    "explanation": "Option B is certainly out of the question, as philosophy has not been emphasised here. Option C can be ruled out, as mathemat ics and gambling have not been discussed separately here, but in the same context. Now, option A and option D are close contenders, but one should go with op tion A as the words ‘mathematics’ and ‘gambling’ are the highlights here. Hence, option A ‘mathematics of gam bling’ is the right choice here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 67,
    "passage": "  Scenario 1: Suppose you’ve been gazing intensely at Rembrandt’s Self-Portrait (1659), which hangs in the National Gallery of Art in Washington, D.C., and later you’re told that this was actually a painting made by a deep-learning machine that had internalised Rembrandt’s style through exposure to his paintings. You immediately feel that something’s lost. The museum would certainly take the work off its walls. What’s the thing that’s lost? Scenario 2: Recently, thousands of paintings covering almost eight miles were found on remote cliffs in the Amazonian rainforest; estimated age: 12,500 years. The Amazonian cliff art depicts humans dancing and holding hands, and now extinct mastodons, Ice Age horses with wild faces (some so detailed that the horse’s hair was shown), and giant sloths—like the weird creatures in a Hieronymus Bosch painting. This made headlines. Standing face-to-face with these actual images on the rocks would be exciting. If the paintings turned out to be a hoax, we’d no longer feel the thrill of imagining the prehistoric humans perhaps so like us painting these images. For me, as a psychologist with a special interest and expertise in the arts, our fascination with art raises two long-standing and fundamental questions, ones that have engaged philosophers, psychologists, and art lovers. First, why are we so drawn to works of art? For their beauty, of course, but that can’t be all, as the thought experiments above show us. Second, what kinds of demonstrable beneficial effects, if any, can engagement in the arts have on us? As for the first question—why do we care so much?—I argue that we’re drawn to works of art because they connect us quite directly to the imagined mind of the artist. We believe  that artists mean something by what they produce, even if it’s sometimes difficult to discern just what meanings were intended. And thus, whenever we take something to be art, rather than an accident or functional artefact, we automatically read into its intentionality and meaning. When we look at a Rembrandt, we feel like we’re reading a message sent to us today by this long-ago genius. The brushstrokes are clues to how his arm was moving as he painted, and how his arm moved can be read as an expression of his state of mind as he created this image. His self-portraits suggest a certain kind of self-scrutiny. We feel that we can see Rembrandt’s awareness of how he’s coming across, and understand his penetrative self-analysis in the series of self-portraits made over time as he aged. We have analogous reactions when we look at the Amazonian rock paintings. We try to imagine what these prehistoric artists with minds like ours were thinking, feeling, and intending by their actions in painting these images. It’s well-established that people dislike forgeries. Two recent documentaries, Driven to Abstraction (2019) and Made You Look: A True Story About Fake Art (2020), explore the biggest and most successful forgery-art scandal in memory. For more than 10 years beginning in 1994, a woman who said she represented a rich collector who wished to remain anonymous brought at least 40 paintings to the prestigious Knoedler Gallery in New York. The paintings were by the most famous 20th-century artists—Mark Rothko, Jackson Pollock, Robert Motherwell, Franz Kline, Clyfford Still, among others. The gallery owner reported that she’d been overwhelmed by the beauty of these works. She bought them all for very low prices, having been told that the anonymous collector who was selling them didn’t care about money, and then Knoedler turned them around at auction for many millions. The gallery had either overlooked or covered up the fact that these paintings didn’t come with any evidence of how they came to be owned by the anonymous collector. Though some art experts said the works looked authentic, others disagreed. Nonetheless, the paintings were sold at auction for a total of about $70 million. Much of the high-end art world had been duped. Little by little, the truth came out, ending with the confession in court of the woman who’d brought the paintings to the gallery. She admitted that the paintings were fakes made by Pei-Shen Qian, a painter from China who was living in Queens, New York. In China, making fakes is traditionally not frowned upon—it is a speciality of some artists—and one of the documentaries takes us to one of the studios in China where fakes are churned out. The collectors who’d been fooled were outraged. But if they’d found the paintings so thrillingly beautiful in the first place, why should they care? One reason is obviously the paintings’ loss of value: what would have been worth millions as an original is worth next to nothing when outed as a forgery. There’s also the possibility that a beautiful painting ceases to look so beautiful when we look at it knowing it’s a forgery—as if the negative tinge of fraudulence and immorality spills over into the painting’s aesthetic appeal. Then there’s the question of snobbery, as Arthur Koestler argued in 1964, noting how, when a friend of his learned that she had a genuine drawing rather than a mass-produced print, she hung it conspicuously on her wall, even though it hadn’t changed physically. But we don’t only dislike forgeries that we’ve bought—we also dislike discovering them on the walls of a museum, and certainly, snobbery can’t be involved when there’s no ownership.",
    "ImageID": "",
    "question": "The author has cited two different sce narios to illustrate:",
    "options": {
      "a": "Why are people so drawn to works of art?",
      "b": "That people hate forgery and hoaxes.",
      "c": "That an elegant and original piece of art captures our attention.",
      "d": "That the aesthetic beauty of a piece of art is not the only element that intrigues us."
    },
    "answer": "d",
    "explanation": "Scenarios I and II do not answer the question pertaining to option A. They only raise this question but leave it un answered. So, option A is incorrect. Options B and C, though correct, do not explain the reason behind the author’s citing the two scenarios. Hence, options B and C are the incorrect explanations for citing those scenarios. Option D is the correct answer here, as it explains the reason behind citing those two scenarios.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 68,
    "passage": "  Scenario 1: Suppose you’ve been gazing intensely at Rembrandt’s Self-Portrait (1659), which hangs in the National Gallery of Art in Washington, D.C., and later you’re told that this was actually a painting made by a deep-learning machine that had internalised Rembrandt’s style through exposure to his paintings. You immediately feel that something’s lost. The museum would certainly take the work off its walls. What’s the thing that’s lost? Scenario 2: Recently, thousands of paintings covering almost eight miles were found on remote cliffs in the Amazonian rainforest; estimated age: 12,500 years. The Amazonian cliff art depicts humans dancing and holding hands, and now extinct mastodons, Ice Age horses with wild faces (some so detailed that the horse’s hair was shown), and giant sloths—like the weird creatures in a Hieronymus Bosch painting. This made headlines. Standing face-to-face with these actual images on the rocks would be exciting. If the paintings turned out to be a hoax, we’d no longer feel the thrill of imagining the prehistoric humans perhaps so like us painting these images. For me, as a psychologist with a special interest and expertise in the arts, our fascination with art raises two long-standing and fundamental questions, ones that have engaged philosophers, psychologists, and art lovers. First, why are we so drawn to works of art? For their beauty, of course, but that can’t be all, as the thought experiments above show us. Second, what kinds of demonstrable beneficial effects, if any, can engagement in the arts have on us? As for the first question—why do we care so much?—I argue that we’re drawn to works of art because they connect us quite directly to the imagined mind of the artist. We believe  that artists mean something by what they produce, even if it’s sometimes difficult to discern just what meanings were intended. And thus, whenever we take something to be art, rather than an accident or functional artefact, we automatically read into its intentionality and meaning. When we look at a Rembrandt, we feel like we’re reading a message sent to us today by this long-ago genius. The brushstrokes are clues to how his arm was moving as he painted, and how his arm moved can be read as an expression of his state of mind as he created this image. His self-portraits suggest a certain kind of self-scrutiny. We feel that we can see Rembrandt’s awareness of how he’s coming across, and understand his penetrative self-analysis in the series of self-portraits made over time as he aged. We have analogous reactions when we look at the Amazonian rock paintings. We try to imagine what these prehistoric artists with minds like ours were thinking, feeling, and intending by their actions in painting these images. It’s well-established that people dislike forgeries. Two recent documentaries, Driven to Abstraction (2019) and Made You Look: A True Story About Fake Art (2020), explore the biggest and most successful forgery-art scandal in memory. For more than 10 years beginning in 1994, a woman who said she represented a rich collector who wished to remain anonymous brought at least 40 paintings to the prestigious Knoedler Gallery in New York. The paintings were by the most famous 20th-century artists—Mark Rothko, Jackson Pollock, Robert Motherwell, Franz Kline, Clyfford Still, among others. The gallery owner reported that she’d been overwhelmed by the beauty of these works. She bought them all for very low prices, having been told that the anonymous collector who was selling them didn’t care about money, and then Knoedler turned them around at auction for many millions. The gallery had either overlooked or covered up the fact that these paintings didn’t come with any evidence of how they came to be owned by the anonymous collector. Though some art experts said the works looked authentic, others disagreed. Nonetheless, the paintings were sold at auction for a total of about $70 million. Much of the high-end art world had been duped. Little by little, the truth came out, ending with the confession in court of the woman who’d brought the paintings to the gallery. She admitted that the paintings were fakes made by Pei-Shen Qian, a painter from China who was living in Queens, New York. In China, making fakes is traditionally not frowned upon—it is a speciality of some artists—and one of the documentaries takes us to one of the studios in China where fakes are churned out. The collectors who’d been fooled were outraged. But if they’d found the paintings so thrillingly beautiful in the first place, why should they care? One reason is obviously the paintings’ loss of value: what would have been worth millions as an original is worth next to nothing when outed as a forgery. There’s also the possibility that a beautiful painting ceases to look so beautiful when we look at it knowing it’s a forgery—as if the negative tinge of fraudulence and immorality spills over into the painting’s aesthetic appeal. Then there’s the question of snobbery, as Arthur Koestler argued in 1964, noting how, when a friend of his learned that she had a genuine drawing rather than a mass-produced print, she hung it conspicuously on her wall, even though it hadn’t changed physically. But we don’t only dislike forgeries that we’ve bought—we also dislike discovering them on the walls of a museum, and certainly, snobbery can’t be involved when there’s no ownership.",
    "ImageID": "",
    "question": "We are drawn to works of art: I. For their aesthetic beauty. II. Because they connect us directly to the mind of the artist. III. Because we try to decipher the hid den meanings in those pieces of art. IV Because of snobbery.",
    "options": {
      "a": "Only I",
      "b": "Only I, II, and III",
      "c": "Both II and III",
      "d": "All of the above"
    },
    "answer": "b",
    "explanation": "Statement I is written directly in the fourth paragraph, and statement II can be inferred from the fourth paragraph. We cannot negate statement A, as it is written in the third paragraph. Statement D is negative and is beyond the scope of arguments made in the passage. Hence option B is correct here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 69,
    "passage": "  Scenario 1: Suppose you’ve been gazing intensely at Rembrandt’s Self-Portrait (1659), which hangs in the National Gallery of Art in Washington, D.C., and later you’re told that this was actually a painting made by a deep-learning machine that had internalised Rembrandt’s style through exposure to his paintings. You immediately feel that something’s lost. The museum would certainly take the work off its walls. What’s the thing that’s lost? Scenario 2: Recently, thousands of paintings covering almost eight miles were found on remote cliffs in the Amazonian rainforest; estimated age: 12,500 years. The Amazonian cliff art depicts humans dancing and holding hands, and now extinct mastodons, Ice Age horses with wild faces (some so detailed that the horse’s hair was shown), and giant sloths—like the weird creatures in a Hieronymus Bosch painting. This made headlines. Standing face-to-face with these actual images on the rocks would be exciting. If the paintings turned out to be a hoax, we’d no longer feel the thrill of imagining the prehistoric humans perhaps so like us painting these images. For me, as a psychologist with a special interest and expertise in the arts, our fascination with art raises two long-standing and fundamental questions, ones that have engaged philosophers, psychologists, and art lovers. First, why are we so drawn to works of art? For their beauty, of course, but that can’t be all, as the thought experiments above show us. Second, what kinds of demonstrable beneficial effects, if any, can engagement in the arts have on us? As for the first question—why do we care so much?—I argue that we’re drawn to works of art because they connect us quite directly to the imagined mind of the artist. We believe  that artists mean something by what they produce, even if it’s sometimes difficult to discern just what meanings were intended. And thus, whenever we take something to be art, rather than an accident or functional artefact, we automatically read into its intentionality and meaning. When we look at a Rembrandt, we feel like we’re reading a message sent to us today by this long-ago genius. The brushstrokes are clues to how his arm was moving as he painted, and how his arm moved can be read as an expression of his state of mind as he created this image. His self-portraits suggest a certain kind of self-scrutiny. We feel that we can see Rembrandt’s awareness of how he’s coming across, and understand his penetrative self-analysis in the series of self-portraits made over time as he aged. We have analogous reactions when we look at the Amazonian rock paintings. We try to imagine what these prehistoric artists with minds like ours were thinking, feeling, and intending by their actions in painting these images. It’s well-established that people dislike forgeries. Two recent documentaries, Driven to Abstraction (2019) and Made You Look: A True Story About Fake Art (2020), explore the biggest and most successful forgery-art scandal in memory. For more than 10 years beginning in 1994, a woman who said she represented a rich collector who wished to remain anonymous brought at least 40 paintings to the prestigious Knoedler Gallery in New York. The paintings were by the most famous 20th-century artists—Mark Rothko, Jackson Pollock, Robert Motherwell, Franz Kline, Clyfford Still, among others. The gallery owner reported that she’d been overwhelmed by the beauty of these works. She bought them all for very low prices, having been told that the anonymous collector who was selling them didn’t care about money, and then Knoedler turned them around at auction for many millions. The gallery had either overlooked or covered up the fact that these paintings didn’t come with any evidence of how they came to be owned by the anonymous collector. Though some art experts said the works looked authentic, others disagreed. Nonetheless, the paintings were sold at auction for a total of about $70 million. Much of the high-end art world had been duped. Little by little, the truth came out, ending with the confession in court of the woman who’d brought the paintings to the gallery. She admitted that the paintings were fakes made by Pei-Shen Qian, a painter from China who was living in Queens, New York. In China, making fakes is traditionally not frowned upon—it is a speciality of some artists—and one of the documentaries takes us to one of the studios in China where fakes are churned out. The collectors who’d been fooled were outraged. But if they’d found the paintings so thrillingly beautiful in the first place, why should they care? One reason is obviously the paintings’ loss of value: what would have been worth millions as an original is worth next to nothing when outed as a forgery. There’s also the possibility that a beautiful painting ceases to look so beautiful when we look at it knowing it’s a forgery—as if the negative tinge of fraudulence and immorality spills over into the painting’s aesthetic appeal. Then there’s the question of snobbery, as Arthur Koestler argued in 1964, noting how, when a friend of his learned that she had a genuine drawing rather than a mass-produced print, she hung it conspicuously on her wall, even though it hadn’t changed physically. But we don’t only dislike forgeries that we’ve bought—we also dislike discovering them on the walls of a museum, and certainly, snobbery can’t be involved when there’s no ownership.",
    "ImageID": "",
    "question": "Which of the following can be inferred from the passage?",
    "options": {
      "a": "A piece of art wouldn’t lose its charm even if it is discovered that it is a rep lica of the original work if the replica is made by a Chinese artist.",
      "b": "Even a forged piece of art can be sold at a very high price.",
      "c": "Knoedler gallery deliberately con cealed the reality of those paintings so that they could make huge profits.",
      "d": "Chinese artists are experts in making fakes, but even in China, it is consid ered malpractice."
    },
    "answer": "b",
    "explanation": "Option A is incorrect as no such claim has been made in the passage. Rather a forged piece of art loses its magic charm once the reality surfaces. Option C is incorrect as the passage doesn’t make it clear whether they did it deliberately or they simply overlooked it. Option D is incorrect, as it is stated in the passage that in China, traditionally, making fakes is not frowned upon. Which means people don’t mind it. Option B is the correct answer, as prov en by the example given in the passage. That if its reality is concealed, even a fake piece of art can be sold for millions.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 70,
    "passage": "  Scenario 1: Suppose you’ve been gazing intensely at Rembrandt’s Self-Portrait (1659), which hangs in the National Gallery of Art in Washington, D.C., and later you’re told that this was actually a painting made by a deep-learning machine that had internalised Rembrandt’s style through exposure to his paintings. You immediately feel that something’s lost. The museum would certainly take the work off its walls. What’s the thing that’s lost? Scenario 2: Recently, thousands of paintings covering almost eight miles were found on remote cliffs in the Amazonian rainforest; estimated age: 12,500 years. The Amazonian cliff art depicts humans dancing and holding hands, and now extinct mastodons, Ice Age horses with wild faces (some so detailed that the horse’s hair was shown), and giant sloths—like the weird creatures in a Hieronymus Bosch painting. This made headlines. Standing face-to-face with these actual images on the rocks would be exciting. If the paintings turned out to be a hoax, we’d no longer feel the thrill of imagining the prehistoric humans perhaps so like us painting these images. For me, as a psychologist with a special interest and expertise in the arts, our fascination with art raises two long-standing and fundamental questions, ones that have engaged philosophers, psychologists, and art lovers. First, why are we so drawn to works of art? For their beauty, of course, but that can’t be all, as the thought experiments above show us. Second, what kinds of demonstrable beneficial effects, if any, can engagement in the arts have on us? As for the first question—why do we care so much?—I argue that we’re drawn to works of art because they connect us quite directly to the imagined mind of the artist. We believe  that artists mean something by what they produce, even if it’s sometimes difficult to discern just what meanings were intended. And thus, whenever we take something to be art, rather than an accident or functional artefact, we automatically read into its intentionality and meaning. When we look at a Rembrandt, we feel like we’re reading a message sent to us today by this long-ago genius. The brushstrokes are clues to how his arm was moving as he painted, and how his arm moved can be read as an expression of his state of mind as he created this image. His self-portraits suggest a certain kind of self-scrutiny. We feel that we can see Rembrandt’s awareness of how he’s coming across, and understand his penetrative self-analysis in the series of self-portraits made over time as he aged. We have analogous reactions when we look at the Amazonian rock paintings. We try to imagine what these prehistoric artists with minds like ours were thinking, feeling, and intending by their actions in painting these images. It’s well-established that people dislike forgeries. Two recent documentaries, Driven to Abstraction (2019) and Made You Look: A True Story About Fake Art (2020), explore the biggest and most successful forgery-art scandal in memory. For more than 10 years beginning in 1994, a woman who said she represented a rich collector who wished to remain anonymous brought at least 40 paintings to the prestigious Knoedler Gallery in New York. The paintings were by the most famous 20th-century artists—Mark Rothko, Jackson Pollock, Robert Motherwell, Franz Kline, Clyfford Still, among others. The gallery owner reported that she’d been overwhelmed by the beauty of these works. She bought them all for very low prices, having been told that the anonymous collector who was selling them didn’t care about money, and then Knoedler turned them around at auction for many millions. The gallery had either overlooked or covered up the fact that these paintings didn’t come with any evidence of how they came to be owned by the anonymous collector. Though some art experts said the works looked authentic, others disagreed. Nonetheless, the paintings were sold at auction for a total of about $70 million. Much of the high-end art world had been duped. Little by little, the truth came out, ending with the confession in court of the woman who’d brought the paintings to the gallery. She admitted that the paintings were fakes made by Pei-Shen Qian, a painter from China who was living in Queens, New York. In China, making fakes is traditionally not frowned upon—it is a speciality of some artists—and one of the documentaries takes us to one of the studios in China where fakes are churned out. The collectors who’d been fooled were outraged. But if they’d found the paintings so thrillingly beautiful in the first place, why should they care? One reason is obviously the paintings’ loss of value: what would have been worth millions as an original is worth next to nothing when outed as a forgery. There’s also the possibility that a beautiful painting ceases to look so beautiful when we look at it knowing it’s a forgery—as if the negative tinge of fraudulence and immorality spills over into the painting’s aesthetic appeal. Then there’s the question of snobbery, as Arthur Koestler argued in 1964, noting how, when a friend of his learned that she had a genuine drawing rather than a mass-produced print, she hung it conspicuously on her wall, even though it hadn’t changed physically. But we don’t only dislike forgeries that we’ve bought—we also dislike discovering them on the walls of a museum, and certainly, snobbery can’t be involved when there’s no ownership.",
    "ImageID": "",
    "question": "Which of the following would be the best analogy for the argument made in scenarios 1 and 2 of the passage?",
    "options": {
      "a": "Students lose their interest in a par ticular question because they are told that the question is not from the actual exam; rather the teacher made it up.",
      "b": "Medicine is not working on patients because they are told that it did not work on other patients earlier.",
      "c": "Customers are not buying a product from a mall because they learned that they could get it cheaper in the nearby market. ",
      "d": "In a shop of antiquities, a customer prefers product A to product B be cause he learned that product A’s authenticity is guaranteed while the authenticity of product B is dubious."
    },
    "answer": "a",
    "explanation": "Scenarios I and II are about losing curi osity about something once you find out that it is not what it is claimed to be. Option A pertains to this same situation. Hence, it is the correct answer. Option D is about preference, while the situation in the passage is about losing interest. Options B and C also do not relate to the situation.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 71,
    "passage": "  Scenario 1: Suppose you’ve been gazing intensely at Rembrandt’s Self-Portrait (1659), which hangs in the National Gallery of Art in Washington, D.C., and later you’re told that this was actually a painting made by a deep-learning machine that had internalised Rembrandt’s style through exposure to his paintings. You immediately feel that something’s lost. The museum would certainly take the work off its walls. What’s the thing that’s lost? Scenario 2: Recently, thousands of paintings covering almost eight miles were found on remote cliffs in the Amazonian rainforest; estimated age: 12,500 years. The Amazonian cliff art depicts humans dancing and holding hands, and now extinct mastodons, Ice Age horses with wild faces (some so detailed that the horse’s hair was shown), and giant sloths—like the weird creatures in a Hieronymus Bosch painting. This made headlines. Standing face-to-face with these actual images on the rocks would be exciting. If the paintings turned out to be a hoax, we’d no longer feel the thrill of imagining the prehistoric humans perhaps so like us painting these images. For me, as a psychologist with a special interest and expertise in the arts, our fascination with art raises two long-standing and fundamental questions, ones that have engaged philosophers, psychologists, and art lovers. First, why are we so drawn to works of art? For their beauty, of course, but that can’t be all, as the thought experiments above show us. Second, what kinds of demonstrable beneficial effects, if any, can engagement in the arts have on us? As for the first question—why do we care so much?—I argue that we’re drawn to works of art because they connect us quite directly to the imagined mind of the artist. We believe  that artists mean something by what they produce, even if it’s sometimes difficult to discern just what meanings were intended. And thus, whenever we take something to be art, rather than an accident or functional artefact, we automatically read into its intentionality and meaning. When we look at a Rembrandt, we feel like we’re reading a message sent to us today by this long-ago genius. The brushstrokes are clues to how his arm was moving as he painted, and how his arm moved can be read as an expression of his state of mind as he created this image. His self-portraits suggest a certain kind of self-scrutiny. We feel that we can see Rembrandt’s awareness of how he’s coming across, and understand his penetrative self-analysis in the series of self-portraits made over time as he aged. We have analogous reactions when we look at the Amazonian rock paintings. We try to imagine what these prehistoric artists with minds like ours were thinking, feeling, and intending by their actions in painting these images. It’s well-established that people dislike forgeries. Two recent documentaries, Driven to Abstraction (2019) and Made You Look: A True Story About Fake Art (2020), explore the biggest and most successful forgery-art scandal in memory. For more than 10 years beginning in 1994, a woman who said she represented a rich collector who wished to remain anonymous brought at least 40 paintings to the prestigious Knoedler Gallery in New York. The paintings were by the most famous 20th-century artists—Mark Rothko, Jackson Pollock, Robert Motherwell, Franz Kline, Clyfford Still, among others. The gallery owner reported that she’d been overwhelmed by the beauty of these works. She bought them all for very low prices, having been told that the anonymous collector who was selling them didn’t care about money, and then Knoedler turned them around at auction for many millions. The gallery had either overlooked or covered up the fact that these paintings didn’t come with any evidence of how they came to be owned by the anonymous collector. Though some art experts said the works looked authentic, others disagreed. Nonetheless, the paintings were sold at auction for a total of about $70 million. Much of the high-end art world had been duped. Little by little, the truth came out, ending with the confession in court of the woman who’d brought the paintings to the gallery. She admitted that the paintings were fakes made by Pei-Shen Qian, a painter from China who was living in Queens, New York. In China, making fakes is traditionally not frowned upon—it is a speciality of some artists—and one of the documentaries takes us to one of the studios in China where fakes are churned out. The collectors who’d been fooled were outraged. But if they’d found the paintings so thrillingly beautiful in the first place, why should they care? One reason is obviously the paintings’ loss of value: what would have been worth millions as an original is worth next to nothing when outed as a forgery. There’s also the possibility that a beautiful painting ceases to look so beautiful when we look at it knowing it’s a forgery—as if the negative tinge of fraudulence and immorality spills over into the painting’s aesthetic appeal. Then there’s the question of snobbery, as Arthur Koestler argued in 1964, noting how, when a friend of his learned that she had a genuine drawing rather than a mass-produced print, she hung it conspicuously on her wall, even though it hadn’t changed physically. But we don’t only dislike forgeries that we’ve bought—we also dislike discovering them on the walls of a museum, and certainly, snobbery can’t be involved when there’s no ownership.",
    "ImageID": "",
    "question": "Based on the assumptions made after reading the passage, on a Sunday morn ing, the author is most likely to visit:",
    "options": {
      "a": "National Gallery of ancient arts",
      "b": "National Gallery of modern arts",
      "c": "A modern art exhibition",
      "d": "National Museum of contemporary arts"
    },
    "answer": "a",
    "explanation": "As the author has made references to two old artefacts in the passage, it is possible that he is interested only in old art piec es. So, it would be safer to assume that he would visit a gallery of ancient arts.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 72,
    "passage": "  Samuel Taylor Coleridge (1772–1834) stands tall in the cultural pantheon for his poetry. It’s less well known that in his own lifetime, and in the decades following his death, this canonical poet had an equal reputation as a philosopher. His published works containing much of his philosophical prose span from The Statesman’s Manual (1816), which set out his theory of imagination and symbolism; Biographia Literaria (1817), one of the great and founding works of literary criticism; The Friend (1818), which includes his philosophical ‘Essays on the Principles of Method’; Aids to Reflection (1825), where he expounds his religious philosophy of transcendence; and On the Constitution of the Church and the State (1829), which presents his political philosophy. The effect of those last two books was so impressive that John Stuart Mill named Coleridge as one of the two great British philosophers of the age—the other being Jeremy Bentham, Coleridge’s polar opposite. His thinking was also at the root of the Broad Church Anglican movement, a major influence on F D Maurice’s Christian socialism, and the main source of American Transcendentalism. Ralph Waldo Emerson visited Coleridge in 1832, and John Dewey, the leading pragmatist philosopher, called Coleridge’s Aids to Reflection ‘my first Bible’. Yet philosophical fortunes change. The almost-total eclipse of British idealism by the rise of analytic philosophy saw a general decline in Coleridge’s philosophical stock. His philosophy languished while his verse rose. Coleridge’s poetry resonated with the psychedelia of the 1960s and a general cultural shift that emphasised the value of the imagination and a more holistic view of the human place within nature. Today, Coleridge is far more often remembered as a poet than a philosopher. But his philosophy was spectacular in its originality and syntheses. Although Coleridge wrote poetry throughout his life, his energies increasingly channelled towards philosophy. Drawing from neo-Platonism, the ingenious but difficult transcendental idealism of Immanuel Kant, and the even obscurer intricacies of post-Kantians such as J G Fichte and F W J Schelling, his philosophy was undoubtedly of the difficult metaphysical kind, very much at odds with practically minded British empiricism. Lord Byron spoke for many when he described Coleridge: Explaining Metaphysics to the nation I wish he would explain his Explanation. Yet the British empiricism of John Locke, David Hume, and David Hartley was itself at odds, Coleridge pointed out, with a deeper heritage of British thought. ‘Let England be’, he pronounced, ‘Sidney, Shakespeare, Spenser, Milton, Bacon, Harrington, Swift, Wordsworth’, who represent the idealising and proto-romantic tradition that he identified as ‘the spiritual platonic old England’. Coleridge rallied that ‘spiritual platonic’ tradition to oppose the philosophies of empiricists and hard-headed expounders of ‘common-sense’ such as Samuel Johnson, Erasmus Darwin, Hume, Joseph Priestley, William Paley, and William Pitt, ‘with Locke at the head of the Philosophers and [Alexander] Pope of the Poets’.",
    "ImageID": "",
    "question": "Choose the correct statement.",
    "options": {
      "a": "The Statesman’s Manual set out Coleridge’s theory of imagination and symbolism; Biographia Literaria is a work of literary criticism; in Aids to Reflection, he expounds his religious philosophy of transcendence; and On the Constitution of the Church and the State presents his political philosophy.",
      "b": "The Statesman’s Manual is a work of literary criticism; Biographia Literaria set out Coleridge’s theory of im agination and symbolism; in Aids to Reflection, he expounds on his  religious philosophy of transcend ence, and On the Constitution of the Church and the State presents his political philosophy.",
      "c": "The Statesman’s Manual set out Coleridge’s theory of imagination and symbolism; in Biographia Literaria, he expounds his religious philosophy of transcendence; Aids to Reflection is a work of literary criticism, and On the Constitution of the Church and the State presents his political philosophy.",
      "d": "The Statesman’s Manual set out Coleridge’s theory of imagination and symbolism; Biographia Literaria is a work of literary criticism; Aids to Reflection presents his political philosophy, and On the Constitution of the Church and the State he ex pounds his religious philosophy of transcendence."
    },
    "answer": "a",
    "explanation": "After a careful reading of the first par agraph, it can be confirmed that option A is the correct statement here. Such questions are sometimes there only to test one’s mind-eye coordination. A fo cused approach is required to tackle these types of questions.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 73,
    "passage": "  Samuel Taylor Coleridge (1772–1834) stands tall in the cultural pantheon for his poetry. It’s less well known that in his own lifetime, and in the decades following his death, this canonical poet had an equal reputation as a philosopher. His published works containing much of his philosophical prose span from The Statesman’s Manual (1816), which set out his theory of imagination and symbolism; Biographia Literaria (1817), one of the great and founding works of literary criticism; The Friend (1818), which includes his philosophical ‘Essays on the Principles of Method’; Aids to Reflection (1825), where he expounds his religious philosophy of transcendence; and On the Constitution of the Church and the State (1829), which presents his political philosophy. The effect of those last two books was so impressive that John Stuart Mill named Coleridge as one of the two great British philosophers of the age—the other being Jeremy Bentham, Coleridge’s polar opposite. His thinking was also at the root of the Broad Church Anglican movement, a major influence on F D Maurice’s Christian socialism, and the main source of American Transcendentalism. Ralph Waldo Emerson visited Coleridge in 1832, and John Dewey, the leading pragmatist philosopher, called Coleridge’s Aids to Reflection ‘my first Bible’. Yet philosophical fortunes change. The almost-total eclipse of British idealism by the rise of analytic philosophy saw a general decline in Coleridge’s philosophical stock. His philosophy languished while his verse rose. Coleridge’s poetry resonated with the psychedelia of the 1960s and a general cultural shift that emphasised the value of the imagination and a more holistic view of the human place within nature. Today, Coleridge is far more often remembered as a poet than a philosopher. But his philosophy was spectacular in its originality and syntheses. Although Coleridge wrote poetry throughout his life, his energies increasingly channelled towards philosophy. Drawing from neo-Platonism, the ingenious but difficult transcendental idealism of Immanuel Kant, and the even obscurer intricacies of post-Kantians such as J G Fichte and F W J Schelling, his philosophy was undoubtedly of the difficult metaphysical kind, very much at odds with practically minded British empiricism. Lord Byron spoke for many when he described Coleridge: Explaining Metaphysics to the nation I wish he would explain his Explanation. Yet the British empiricism of John Locke, David Hume, and David Hartley was itself at odds, Coleridge pointed out, with a deeper heritage of British thought. ‘Let England be’, he pronounced, ‘Sidney, Shakespeare, Spenser, Milton, Bacon, Harrington, Swift, Wordsworth’, who represent the idealising and proto-romantic tradition that he identified as ‘the spiritual platonic old England’. Coleridge rallied that ‘spiritual platonic’ tradition to oppose the philosophies of empiricists and hard-headed expounders of ‘common-sense’ such as Samuel Johnson, Erasmus Darwin, Hume, Joseph Priestley, William Paley, and William Pitt, ‘with Locke at the head of the Philosophers and [Alexander] Pope of the Poets’.",
    "ImageID": "",
    "question": "‘Ralph Waldo Emerson visited Coleridge in 1832’.—All of the following can be in ferred from this, except:",
    "options": {
      "a": "Ralph Waldo himself must have been a renowned philosopher of his time.",
      "b": "Ralph Waldo appreciated Coleridge as a philosopher.",
      "c": "The author has shared this informa tion to reinforce Coleridge’s image as a philosopher.",
      "d": "Ralph Waldo was fond of Coleridge’s poetry."
    },
    "answer": "d",
    "explanation": "The purpose of the passage is to depict Coleridge as a philosopher. Option C is the reason why the author has shared this information. Clearly, the author wants to say that Waldo visited Coleridge because he was impressed with Coleridge’s phi losophy. So, option B can also be inferred. Now, if option C is correct, option A can also be inferred. Option D is irrelevant in the given context since Coleridge’s philosophy has been emphasised here and not his poetry. Hence, option D is the correct answer here. It cannot be inferred.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 74,
    "passage": "  Samuel Taylor Coleridge (1772–1834) stands tall in the cultural pantheon for his poetry. It’s less well known that in his own lifetime, and in the decades following his death, this canonical poet had an equal reputation as a philosopher. His published works containing much of his philosophical prose span from The Statesman’s Manual (1816), which set out his theory of imagination and symbolism; Biographia Literaria (1817), one of the great and founding works of literary criticism; The Friend (1818), which includes his philosophical ‘Essays on the Principles of Method’; Aids to Reflection (1825), where he expounds his religious philosophy of transcendence; and On the Constitution of the Church and the State (1829), which presents his political philosophy. The effect of those last two books was so impressive that John Stuart Mill named Coleridge as one of the two great British philosophers of the age—the other being Jeremy Bentham, Coleridge’s polar opposite. His thinking was also at the root of the Broad Church Anglican movement, a major influence on F D Maurice’s Christian socialism, and the main source of American Transcendentalism. Ralph Waldo Emerson visited Coleridge in 1832, and John Dewey, the leading pragmatist philosopher, called Coleridge’s Aids to Reflection ‘my first Bible’. Yet philosophical fortunes change. The almost-total eclipse of British idealism by the rise of analytic philosophy saw a general decline in Coleridge’s philosophical stock. His philosophy languished while his verse rose. Coleridge’s poetry resonated with the psychedelia of the 1960s and a general cultural shift that emphasised the value of the imagination and a more holistic view of the human place within nature. Today, Coleridge is far more often remembered as a poet than a philosopher. But his philosophy was spectacular in its originality and syntheses. Although Coleridge wrote poetry throughout his life, his energies increasingly channelled towards philosophy. Drawing from neo-Platonism, the ingenious but difficult transcendental idealism of Immanuel Kant, and the even obscurer intricacies of post-Kantians such as J G Fichte and F W J Schelling, his philosophy was undoubtedly of the difficult metaphysical kind, very much at odds with practically minded British empiricism. Lord Byron spoke for many when he described Coleridge: Explaining Metaphysics to the nation I wish he would explain his Explanation. Yet the British empiricism of John Locke, David Hume, and David Hartley was itself at odds, Coleridge pointed out, with a deeper heritage of British thought. ‘Let England be’, he pronounced, ‘Sidney, Shakespeare, Spenser, Milton, Bacon, Harrington, Swift, Wordsworth’, who represent the idealising and proto-romantic tradition that he identified as ‘the spiritual platonic old England’. Coleridge rallied that ‘spiritual platonic’ tradition to oppose the philosophies of empiricists and hard-headed expounders of ‘common-sense’ such as Samuel Johnson, Erasmus Darwin, Hume, Joseph Priestley, William Paley, and William Pitt, ‘with Locke at the head of the Philosophers and [Alexander] Pope of the Poets’.",
    "ImageID": "",
    "question": "Which of the following is not true of Coleridge’s philosophy?",
    "options": {
      "a": "His philosophy was the main source of American Transcendentalism.",
      "b": "His philosophical views were very difficult to comprehend.",
      "c": "His philosophy confirmed British idealism.",
      "d": "In his lifetime and the decades af ter his death, Coleridge was lesser known for his philosophy than for his poetry."
    },
    "answer": "d",
    "explanation": "Option D is not true here, as it can be confirmed from the first paragraph that in his lifetime and the decades after his death, Coleridge had an equal reputation as a philosopher and poet. Option C can be inferred from the sec ond sentence of the third paragraph. Option B can be confirmed from Lord Byron’s comment. Option A is clearly written in the second paragraph.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 75,
    "passage": "  Samuel Taylor Coleridge (1772–1834) stands tall in the cultural pantheon for his poetry. It’s less well known that in his own lifetime, and in the decades following his death, this canonical poet had an equal reputation as a philosopher. His published works containing much of his philosophical prose span from The Statesman’s Manual (1816), which set out his theory of imagination and symbolism; Biographia Literaria (1817), one of the great and founding works of literary criticism; The Friend (1818), which includes his philosophical ‘Essays on the Principles of Method’; Aids to Reflection (1825), where he expounds his religious philosophy of transcendence; and On the Constitution of the Church and the State (1829), which presents his political philosophy. The effect of those last two books was so impressive that John Stuart Mill named Coleridge as one of the two great British philosophers of the age—the other being Jeremy Bentham, Coleridge’s polar opposite. His thinking was also at the root of the Broad Church Anglican movement, a major influence on F D Maurice’s Christian socialism, and the main source of American Transcendentalism. Ralph Waldo Emerson visited Coleridge in 1832, and John Dewey, the leading pragmatist philosopher, called Coleridge’s Aids to Reflection ‘my first Bible’. Yet philosophical fortunes change. The almost-total eclipse of British idealism by the rise of analytic philosophy saw a general decline in Coleridge’s philosophical stock. His philosophy languished while his verse rose. Coleridge’s poetry resonated with the psychedelia of the 1960s and a general cultural shift that emphasised the value of the imagination and a more holistic view of the human place within nature. Today, Coleridge is far more often remembered as a poet than a philosopher. But his philosophy was spectacular in its originality and syntheses. Although Coleridge wrote poetry throughout his life, his energies increasingly channelled towards philosophy. Drawing from neo-Platonism, the ingenious but difficult transcendental idealism of Immanuel Kant, and the even obscurer intricacies of post-Kantians such as J G Fichte and F W J Schelling, his philosophy was undoubtedly of the difficult metaphysical kind, very much at odds with practically minded British empiricism. Lord Byron spoke for many when he described Coleridge: Explaining Metaphysics to the nation I wish he would explain his Explanation. Yet the British empiricism of John Locke, David Hume, and David Hartley was itself at odds, Coleridge pointed out, with a deeper heritage of British thought. ‘Let England be’, he pronounced, ‘Sidney, Shakespeare, Spenser, Milton, Bacon, Harrington, Swift, Wordsworth’, who represent the idealising and proto-romantic tradition that he identified as ‘the spiritual platonic old England’. Coleridge rallied that ‘spiritual platonic’ tradition to oppose the philosophies of empiricists and hard-headed expounders of ‘common-sense’ such as Samuel Johnson, Erasmus Darwin, Hume, Joseph Priestley, William Paley, and William Pitt, ‘with Locke at the head of the Philosophers and [Alexander] Pope of the Poets’.",
    "ImageID": "",
    "question": "All of the following establish Coleridge’s reputation as a philosopher, except:",
    "options": {
      "a": "Some of his literary works.",
      "b": "American Transcendentalism being influenced by his philosophy.",
      "c": "Ralph Waldo visiting him in 1832.",
      "d": "His philosophy being confirmed by the British idealists."
    },
    "answer": "d",
    "explanation": "Options A, B, and C can be confirmed from the second paragraph. The author has mentioned all these facts to rein force Coleridge’s image as a philosopher. Option D has not been mentioned in the passage, nor can it be inferred. Hence, option D is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 76,
    "passage": "  Samuel Taylor Coleridge (1772–1834) stands tall in the cultural pantheon for his poetry. It’s less well known that in his own lifetime, and in the decades following his death, this canonical poet had an equal reputation as a philosopher. His published works containing much of his philosophical prose span from The Statesman’s Manual (1816), which set out his theory of imagination and symbolism; Biographia Literaria (1817), one of the great and founding works of literary criticism; The Friend (1818), which includes his philosophical ‘Essays on the Principles of Method’; Aids to Reflection (1825), where he expounds his religious philosophy of transcendence; and On the Constitution of the Church and the State (1829), which presents his political philosophy. The effect of those last two books was so impressive that John Stuart Mill named Coleridge as one of the two great British philosophers of the age—the other being Jeremy Bentham, Coleridge’s polar opposite. His thinking was also at the root of the Broad Church Anglican movement, a major influence on F D Maurice’s Christian socialism, and the main source of American Transcendentalism. Ralph Waldo Emerson visited Coleridge in 1832, and John Dewey, the leading pragmatist philosopher, called Coleridge’s Aids to Reflection ‘my first Bible’. Yet philosophical fortunes change. The almost-total eclipse of British idealism by the rise of analytic philosophy saw a general decline in Coleridge’s philosophical stock. His philosophy languished while his verse rose. Coleridge’s poetry resonated with the psychedelia of the 1960s and a general cultural shift that emphasised the value of the imagination and a more holistic view of the human place within nature. Today, Coleridge is far more often remembered as a poet than a philosopher. But his philosophy was spectacular in its originality and syntheses. Although Coleridge wrote poetry throughout his life, his energies increasingly channelled towards philosophy. Drawing from neo-Platonism, the ingenious but difficult transcendental idealism of Immanuel Kant, and the even obscurer intricacies of post-Kantians such as J G Fichte and F W J Schelling, his philosophy was undoubtedly of the difficult metaphysical kind, very much at odds with practically minded British empiricism. Lord Byron spoke for many when he described Coleridge: Explaining Metaphysics to the nation I wish he would explain his Explanation. Yet the British empiricism of John Locke, David Hume, and David Hartley was itself at odds, Coleridge pointed out, with a deeper heritage of British thought. ‘Let England be’, he pronounced, ‘Sidney, Shakespeare, Spenser, Milton, Bacon, Harrington, Swift, Wordsworth’, who represent the idealising and proto-romantic tradition that he identified as ‘the spiritual platonic old England’. Coleridge rallied that ‘spiritual platonic’ tradition to oppose the philosophies of empiricists and hard-headed expounders of ‘common-sense’ such as Samuel Johnson, Erasmus Darwin, Hume, Joseph Priestley, William Paley, and William Pitt, ‘with Locke at the head of the Philosophers and [Alexander] Pope of the Poets’.",
    "ImageID": "",
    "question": "Coleridge’s own philosophy was influ enced by:",
    "options": {
      "a": "British idealism",
      "b": "British empiricism",
      "c": "Transcendental idealism of Immanuel Kant",
      "d": "Proto-romantic tradition"
    },
    "answer": "c",
    "explanation": "Option C contains one of the sources Coleridge drew his philosophical inspira tion from. Hence, option C is the correct answer here, as can be confirmed from the fourth paragraph. Options A and D are distractions. Option B is clearly incorrect as he was at odds with British empiricism.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 77,
    "passage": "  The Arab East was among the last regions in the world to be colonised by Western powers. It was also the first to be colonised in the name of self-determination. An iconic photograph from September 1920 of the French colonial general Henri Gouraud dressed in a splendid white uniform and flanked by two ‘native’ religious figures captures this moment. Seated to one side is the Patriarch of the Maronite Church, an Eastern Christian Catholic sect. On the other side is the Sunni Muslim Mufti of Beirut. Gouraud’s proclamation of the state of Greater Lebanon, or Grand Liban, which was carved out of the lands of the defeated Ottoman Empire, served as the occasion. With Britain’s blessing, France had occupied Syria two months earlier and overthrown the short-lived, constitutional Arab Kingdom of Syria. The pretext offered for this late colonialism was one that continues to be used today. The alleged object of France in the Orient was not to aggrandise itself but to lead its inhabitants, particularly its diverse and significant minority populations of Lebanon, towards freedom and independence. France separated the Christian-dominated state of Lebanon from the rest of geographic Syria, which itself was parcelled out along sectarian Alawi, Druze, and Sunni polities under overarching French dominion. This late colonialism was allegedly meant to liberate the peoples of the Arab world from the tyranny of the Ottoman Muslim ‘Turk’ and from the depredations of notionally age-old sectarian hatreds. Thus General Gouraud appeared in the photograph not as a vanquisher of supposedly barbarous native tribes; he was neither a modern Hernán Cortés toppling the Aztec Montezuma nor a French reincarnation of Andrew Jackson destroying the Seminoles of Florida. The French colonial general who had served in Niger, Chad, and Morocco was portrayed as an indispensable peacemaker and benevolent arbiter between what the Europeans claimed to be the antagonistic communities of the Orient. The colonisation of the Arab East had come after that of the Americas, South and Southeastern Asia, and Africa. This last great spurt of colonial conquest ostensibly repudiated the brutal and rapacious rule of the kind that King Leopold of Belgium had visited upon the Congo in the late-19th century. Instead, after the First World War, Europeans ruled through euphemism: a so-called ‘mandate’ system dominated by ‘advanced’ powers was established by the new Britishand-French-dominated League of Nations to aid less-able nations. The new Lebanese and Syrian states blessed by the League were ‘provisionally’ independent, yet subject to mandatory European tutelage. Drawing on the British experience of ‘indirect’ rule in Africa, the victorious powers cultivated a native facade to obscure the coloniser’s hand. Perhaps most importantly, this late colonialism claimed to respect the new ideals of the US president Woodrow Wilson, the presumptive father of so-called ‘self-determination’ of peoples around the world. Throughout modern history, the weight of Western colonialism in the name of freedom and religious liberty has distorted the nature of the Middle East. It has transformed the political geography of the region by creating a series of small and dependent Middle Eastern states and emirates where once stood a large interconnected Ottoman sultanate. It introduced a new—and still unresolved—conflict between ‘Arab’ and ‘Jew’ in Palestine just when a new Arab identity that included Muslim, Christian, and Jewish Arabs appeared most promising. This late— last—Western colonialism has obscured the fact that the shift from Ottoman imperial rule to post-Ottoman Arab national rule was neither natural nor inevitable. European colonialism abruptly interrupted and reshaped a vital anti-sectarian Arab cultural Reading Comprehension – Basic Leveland political path that had begun to take shape during the last century of Ottoman rule. Despite European colonialism, the ecumenical ideal, and the dream of creating sovereign societies greater than the sum of their communal or sectarian parts, survived well into the 20th-century Arab world.",
    "ImageID": "",
    "question": "All of the following can be inferred from the passage, except:",
    "options": {
      "a": "The Arab East was more united and powerful under the rule of the Ottomans.",
      "b": "The so-called ‘self-determination’ was just a pretext for colonising the Arab Eastern countries.",
      "c": "The current plight of the Middle East can be attributed to the colonisation policies of the European powers.",
      "d": "Colonisation of the Arab East by European powers brought unity and peace to the region."
    },
    "answer": "d",
    "explanation": "Out of options A and D, only one can be correct as they state opposite facts. Option A can certainly be inferred from the passage, as the author has claimed that the colonisation of the region result ed in a diverse society (last paragraph). Option B can also be inferred from a careful reading of the third paragraph. And the last paragraph suggests that op tion C can also be inferred. Hence, option D is the correct answer here as it represents an idea that is op posite to the claims made in the passage.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 78,
    "passage": "  The Arab East was among the last regions in the world to be colonised by Western powers. It was also the first to be colonised in the name of self-determination. An iconic photograph from September 1920 of the French colonial general Henri Gouraud dressed in a splendid white uniform and flanked by two ‘native’ religious figures captures this moment. Seated to one side is the Patriarch of the Maronite Church, an Eastern Christian Catholic sect. On the other side is the Sunni Muslim Mufti of Beirut. Gouraud’s proclamation of the state of Greater Lebanon, or Grand Liban, which was carved out of the lands of the defeated Ottoman Empire, served as the occasion. With Britain’s blessing, France had occupied Syria two months earlier and overthrown the short-lived, constitutional Arab Kingdom of Syria. The pretext offered for this late colonialism was one that continues to be used today. The alleged object of France in the Orient was not to aggrandise itself but to lead its inhabitants, particularly its diverse and significant minority populations of Lebanon, towards freedom and independence. France separated the Christian-dominated state of Lebanon from the rest of geographic Syria, which itself was parcelled out along sectarian Alawi, Druze, and Sunni polities under overarching French dominion. This late colonialism was allegedly meant to liberate the peoples of the Arab world from the tyranny of the Ottoman Muslim ‘Turk’ and from the depredations of notionally age-old sectarian hatreds. Thus General Gouraud appeared in the photograph not as a vanquisher of supposedly barbarous native tribes; he was neither a modern Hernán Cortés toppling the Aztec Montezuma nor a French reincarnation of Andrew Jackson destroying the Seminoles of Florida. The French colonial general who had served in Niger, Chad, and Morocco was portrayed as an indispensable peacemaker and benevolent arbiter between what the Europeans claimed to be the antagonistic communities of the Orient. The colonisation of the Arab East had come after that of the Americas, South and Southeastern Asia, and Africa. This last great spurt of colonial conquest ostensibly repudiated the brutal and rapacious rule of the kind that King Leopold of Belgium had visited upon the Congo in the late-19th century. Instead, after the First World War, Europeans ruled through euphemism: a so-called ‘mandate’ system dominated by ‘advanced’ powers was established by the new Britishand-French-dominated League of Nations to aid less-able nations. The new Lebanese and Syrian states blessed by the League were ‘provisionally’ independent, yet subject to mandatory European tutelage. Drawing on the British experience of ‘indirect’ rule in Africa, the victorious powers cultivated a native facade to obscure the coloniser’s hand. Perhaps most importantly, this late colonialism claimed to respect the new ideals of the US president Woodrow Wilson, the presumptive father of so-called ‘self-determination’ of peoples around the world. Throughout modern history, the weight of Western colonialism in the name of freedom and religious liberty has distorted the nature of the Middle East. It has transformed the political geography of the region by creating a series of small and dependent Middle Eastern states and emirates where once stood a large interconnected Ottoman sultanate. It introduced a new—and still unresolved—conflict between ‘Arab’ and ‘Jew’ in Palestine just when a new Arab identity that included Muslim, Christian, and Jewish Arabs appeared most promising. This late— last—Western colonialism has obscured the fact that the shift from Ottoman imperial rule to post-Ottoman Arab national rule was neither natural nor inevitable. European colonialism abruptly interrupted and reshaped a vital anti-sectarian Arab cultural Reading Comprehension – Basic Leveland political path that had begun to take shape during the last century of Ottoman rule. Despite European colonialism, the ecumenical ideal, and the dream of creating sovereign societies greater than the sum of their communal or sectarian parts, survived well into the 20th-century Arab world.",
    "ImageID": "",
    "question": "Arab East’s colonisation by the European powers was possible due to: I. Collaborative efforts of European powers to dominate the region. II. Fall of the Ottoman Empire. III. Weak and divided natives of the region.",
    "options": {
      "a": "Only I and III",
      "b": "Only II and III",
      "c": "Only I and II",
      "d": "All of the above"
    },
    "answer": "d",
    "explanation": "With Britain’s blessing, France had occu pied Syria—this statement suggests that statement A is correct. Where once stood a large interconnected Ottoman sultanate—from this statement in the last paragraph, statement II can be inferred. From the first and second paragraphs, statement III can be inferred. Hence, the correct answer is option D.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 79,
    "passage": "  The Arab East was among the last regions in the world to be colonised by Western powers. It was also the first to be colonised in the name of self-determination. An iconic photograph from September 1920 of the French colonial general Henri Gouraud dressed in a splendid white uniform and flanked by two ‘native’ religious figures captures this moment. Seated to one side is the Patriarch of the Maronite Church, an Eastern Christian Catholic sect. On the other side is the Sunni Muslim Mufti of Beirut. Gouraud’s proclamation of the state of Greater Lebanon, or Grand Liban, which was carved out of the lands of the defeated Ottoman Empire, served as the occasion. With Britain’s blessing, France had occupied Syria two months earlier and overthrown the short-lived, constitutional Arab Kingdom of Syria. The pretext offered for this late colonialism was one that continues to be used today. The alleged object of France in the Orient was not to aggrandise itself but to lead its inhabitants, particularly its diverse and significant minority populations of Lebanon, towards freedom and independence. France separated the Christian-dominated state of Lebanon from the rest of geographic Syria, which itself was parcelled out along sectarian Alawi, Druze, and Sunni polities under overarching French dominion. This late colonialism was allegedly meant to liberate the peoples of the Arab world from the tyranny of the Ottoman Muslim ‘Turk’ and from the depredations of notionally age-old sectarian hatreds. Thus General Gouraud appeared in the photograph not as a vanquisher of supposedly barbarous native tribes; he was neither a modern Hernán Cortés toppling the Aztec Montezuma nor a French reincarnation of Andrew Jackson destroying the Seminoles of Florida. The French colonial general who had served in Niger, Chad, and Morocco was portrayed as an indispensable peacemaker and benevolent arbiter between what the Europeans claimed to be the antagonistic communities of the Orient. The colonisation of the Arab East had come after that of the Americas, South and Southeastern Asia, and Africa. This last great spurt of colonial conquest ostensibly repudiated the brutal and rapacious rule of the kind that King Leopold of Belgium had visited upon the Congo in the late-19th century. Instead, after the First World War, Europeans ruled through euphemism: a so-called ‘mandate’ system dominated by ‘advanced’ powers was established by the new Britishand-French-dominated League of Nations to aid less-able nations. The new Lebanese and Syrian states blessed by the League were ‘provisionally’ independent, yet subject to mandatory European tutelage. Drawing on the British experience of ‘indirect’ rule in Africa, the victorious powers cultivated a native facade to obscure the coloniser’s hand. Perhaps most importantly, this late colonialism claimed to respect the new ideals of the US president Woodrow Wilson, the presumptive father of so-called ‘self-determination’ of peoples around the world. Throughout modern history, the weight of Western colonialism in the name of freedom and religious liberty has distorted the nature of the Middle East. It has transformed the political geography of the region by creating a series of small and dependent Middle Eastern states and emirates where once stood a large interconnected Ottoman sultanate. It introduced a new—and still unresolved—conflict between ‘Arab’ and ‘Jew’ in Palestine just when a new Arab identity that included Muslim, Christian, and Jewish Arabs appeared most promising. This late— last—Western colonialism has obscured the fact that the shift from Ottoman imperial rule to post-Ottoman Arab national rule was neither natural nor inevitable. European colonialism abruptly interrupted and reshaped a vital anti-sectarian Arab cultural Reading Comprehension – Basic Leveland political path that had begun to take shape during the last century of Ottoman rule. Despite European colonialism, the ecumenical ideal, and the dream of creating sovereign societies greater than the sum of their communal or sectarian parts, survived well into the 20th-century Arab world.",
    "ImageID": "",
    "question": "The real purpose of France behind colo nising Lebanon was to:",
    "options": {
      "a": "Separate the Christian-dominated state of Lebanon from the rest of ge ographic Syria.",
      "b": "Maintain its supremacy in the Arab world.",
      "c": "Liberate the peoples of the Arab world from the tyranny of the Ottoman Muslim ‘Turk’.",
      "d": "Vanquish the supposedly barbarous native tribes."
    },
    "answer": "b",
    "explanation": "Option A states what France did; it doesn’t explain the purpose. Option C defines the pretext under which France colonised the region. It also doesn’t define the real purpose. Option D is what France did not want to show, but what somehow it did. But again, it doesn’t define the purpose. From the tone of the passage, it can be inferred that the reason given in option B was the real purpose of France.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 80,
    "passage": "  The Arab East was among the last regions in the world to be colonised by Western powers. It was also the first to be colonised in the name of self-determination. An iconic photograph from September 1920 of the French colonial general Henri Gouraud dressed in a splendid white uniform and flanked by two ‘native’ religious figures captures this moment. Seated to one side is the Patriarch of the Maronite Church, an Eastern Christian Catholic sect. On the other side is the Sunni Muslim Mufti of Beirut. Gouraud’s proclamation of the state of Greater Lebanon, or Grand Liban, which was carved out of the lands of the defeated Ottoman Empire, served as the occasion. With Britain’s blessing, France had occupied Syria two months earlier and overthrown the short-lived, constitutional Arab Kingdom of Syria. The pretext offered for this late colonialism was one that continues to be used today. The alleged object of France in the Orient was not to aggrandise itself but to lead its inhabitants, particularly its diverse and significant minority populations of Lebanon, towards freedom and independence. France separated the Christian-dominated state of Lebanon from the rest of geographic Syria, which itself was parcelled out along sectarian Alawi, Druze, and Sunni polities under overarching French dominion. This late colonialism was allegedly meant to liberate the peoples of the Arab world from the tyranny of the Ottoman Muslim ‘Turk’ and from the depredations of notionally age-old sectarian hatreds. Thus General Gouraud appeared in the photograph not as a vanquisher of supposedly barbarous native tribes; he was neither a modern Hernán Cortés toppling the Aztec Montezuma nor a French reincarnation of Andrew Jackson destroying the Seminoles of Florida. The French colonial general who had served in Niger, Chad, and Morocco was portrayed as an indispensable peacemaker and benevolent arbiter between what the Europeans claimed to be the antagonistic communities of the Orient. The colonisation of the Arab East had come after that of the Americas, South and Southeastern Asia, and Africa. This last great spurt of colonial conquest ostensibly repudiated the brutal and rapacious rule of the kind that King Leopold of Belgium had visited upon the Congo in the late-19th century. Instead, after the First World War, Europeans ruled through euphemism: a so-called ‘mandate’ system dominated by ‘advanced’ powers was established by the new Britishand-French-dominated League of Nations to aid less-able nations. The new Lebanese and Syrian states blessed by the League were ‘provisionally’ independent, yet subject to mandatory European tutelage. Drawing on the British experience of ‘indirect’ rule in Africa, the victorious powers cultivated a native facade to obscure the coloniser’s hand. Perhaps most importantly, this late colonialism claimed to respect the new ideals of the US president Woodrow Wilson, the presumptive father of so-called ‘self-determination’ of peoples around the world. Throughout modern history, the weight of Western colonialism in the name of freedom and religious liberty has distorted the nature of the Middle East. It has transformed the political geography of the region by creating a series of small and dependent Middle Eastern states and emirates where once stood a large interconnected Ottoman sultanate. It introduced a new—and still unresolved—conflict between ‘Arab’ and ‘Jew’ in Palestine just when a new Arab identity that included Muslim, Christian, and Jewish Arabs appeared most promising. This late— last—Western colonialism has obscured the fact that the shift from Ottoman imperial rule to post-Ottoman Arab national rule was neither natural nor inevitable. European colonialism abruptly interrupted and reshaped a vital anti-sectarian Arab cultural Reading Comprehension – Basic Leveland political path that had begun to take shape during the last century of Ottoman rule. Despite European colonialism, the ecumenical ideal, and the dream of creating sovereign societies greater than the sum of their communal or sectarian parts, survived well into the 20th-century Arab world.",
    "ImageID": "",
    "question": "The author has mentioned all of the fol lowing as the outcome of the European Colonialism, except:",
    "options": {
      "a": "Fall of the Ottoman sultanate.",
      "b": "Creation of many small and inde pendent regions in the area.",
      "c": "The conflict between Arabs and Jews in Palestine.",
      "d": "Transformation of the political geog raphy of the region."
    },
    "answer": "a",
    "explanation": "Options B, C, and D are mentioned in the last paragraph. The fall of the Ottoman Empire was not the outcome of European colonisation, but European colonisation was the out come of the fall of the Ottoman Empire. Hence, option A is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 81,
    "passage": "  The Arab East was among the last regions in the world to be colonised by Western powers. It was also the first to be colonised in the name of self-determination. An iconic photograph from September 1920 of the French colonial general Henri Gouraud dressed in a splendid white uniform and flanked by two ‘native’ religious figures captures this moment. Seated to one side is the Patriarch of the Maronite Church, an Eastern Christian Catholic sect. On the other side is the Sunni Muslim Mufti of Beirut. Gouraud’s proclamation of the state of Greater Lebanon, or Grand Liban, which was carved out of the lands of the defeated Ottoman Empire, served as the occasion. With Britain’s blessing, France had occupied Syria two months earlier and overthrown the short-lived, constitutional Arab Kingdom of Syria. The pretext offered for this late colonialism was one that continues to be used today. The alleged object of France in the Orient was not to aggrandise itself but to lead its inhabitants, particularly its diverse and significant minority populations of Lebanon, towards freedom and independence. France separated the Christian-dominated state of Lebanon from the rest of geographic Syria, which itself was parcelled out along sectarian Alawi, Druze, and Sunni polities under overarching French dominion. This late colonialism was allegedly meant to liberate the peoples of the Arab world from the tyranny of the Ottoman Muslim ‘Turk’ and from the depredations of notionally age-old sectarian hatreds. Thus General Gouraud appeared in the photograph not as a vanquisher of supposedly barbarous native tribes; he was neither a modern Hernán Cortés toppling the Aztec Montezuma nor a French reincarnation of Andrew Jackson destroying the Seminoles of Florida. The French colonial general who had served in Niger, Chad, and Morocco was portrayed as an indispensable peacemaker and benevolent arbiter between what the Europeans claimed to be the antagonistic communities of the Orient. The colonisation of the Arab East had come after that of the Americas, South and Southeastern Asia, and Africa. This last great spurt of colonial conquest ostensibly repudiated the brutal and rapacious rule of the kind that King Leopold of Belgium had visited upon the Congo in the late-19th century. Instead, after the First World War, Europeans ruled through euphemism: a so-called ‘mandate’ system dominated by ‘advanced’ powers was established by the new Britishand-French-dominated League of Nations to aid less-able nations. The new Lebanese and Syrian states blessed by the League were ‘provisionally’ independent, yet subject to mandatory European tutelage. Drawing on the British experience of ‘indirect’ rule in Africa, the victorious powers cultivated a native facade to obscure the coloniser’s hand. Perhaps most importantly, this late colonialism claimed to respect the new ideals of the US president Woodrow Wilson, the presumptive father of so-called ‘self-determination’ of peoples around the world. Throughout modern history, the weight of Western colonialism in the name of freedom and religious liberty has distorted the nature of the Middle East. It has transformed the political geography of the region by creating a series of small and dependent Middle Eastern states and emirates where once stood a large interconnected Ottoman sultanate. It introduced a new—and still unresolved—conflict between ‘Arab’ and ‘Jew’ in Palestine just when a new Arab identity that included Muslim, Christian, and Jewish Arabs appeared most promising. This late— last—Western colonialism has obscured the fact that the shift from Ottoman imperial rule to post-Ottoman Arab national rule was neither natural nor inevitable. European colonialism abruptly interrupted and reshaped a vital anti-sectarian Arab cultural Reading Comprehension – Basic Leveland political path that had begun to take shape during the last century of Ottoman rule. Despite European colonialism, the ecumenical ideal, and the dream of creating sovereign societies greater than the sum of their communal or sectarian parts, survived well into the 20th-century Arab world.",
    "ImageID": "",
    "question": "According to the passage, all of the fol lowing are true, except:",
    "options": {
      "a": "America, Africa, and Asia were colo nised before the Middle East.",
      "b": "After World War I, European powers kept the Arab East colonised, but in an indirect way.",
      "c": "Before their colonisation, Lebanon was Sunni-dominated, while Syria was a Christian-dominated region.",
      "d": "There was a constitutional kingdom in Syria before its colonisation by France."
    },
    "answer": "c",
    "explanation": "Option A can be confirmed from the third paragraph. Option B can also be inferred from the third paragraph. Option D can be inferred from the First paragraph. Option C is the correct answer here, as it is the opposite of what has been stated in the passage.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 82,
    "passage": "  When you think of ‘smart people’, you likely have an intuitive sense of the qualities that make them intelligent. Maybe you think they have a good memory, or that they can think quickly, or that they simply know a whole lot of information. Indeed, people who exhibit such qualities appear very intelligent. That said, it seems that intelligence must be more than simply knowing facts and being able to remember them. One point in favour of this argument is the idea of animal intelligence. It will come as no surprise to you that a dog, which can learn commands and tricks seems smarter than a snake that cannot. In fact, researchers and laypeople generally agree with one another that primates— monkeys and apes (including humans)—are among the most intelligent animals. Apes such as chimpanzees are capable of complex problem solving and sophisticated communication. Scientists point to the social nature of primates as one evolutionary source of their intelligence. Primates live together in troops or family groups and are, therefore, highly social creatures. As such, primates tend to have brains that are better developed for communication and long-term thinking than most other animals. For instance, the complex social environment has led primates to develop deception, altruism, numerical concepts, and ‘theory of mind’ (a sense of the self as a unique individual separate from others in the group. The question of what constitutes human intelligence is one of the oldest inquiries in psychology. When we talk about intelligence we typically mean intellectual ability. This broadly encompasses the ability to learn, remember and use new information, solve problems and adapt to novel situations. An early scholar of intelligence, Charles Spearman, proposed the idea that intelligence was one thing, a ‘general factor’  sometimes known as simply ‘g.’ He based this conclusion on the observation that people who perform well in one intellectual area such as verbal ability also tend to perform well in other areas such as logic and reasoning A contemporary of Spearman’s named Francis Galton—himself a cousin of Charles Darwin—was among those who pioneered psychological measurement. For three pence Galton would measure various physical characteristics such as grip strength but also some psychological attributes such as the ability to judge distance or discriminate between colours. This is an example of one of the earliest systematic measures of individual ability. Galton was particularly interested in intelligence, which he thought was heritable in much the same way that height and eye colour are. He conceived of several rudimentary methods for assessing whether his hypothesis was true. For example, he carefully tracked the family tree of the top-scoring Cambridge students over the previous 40 years. Although he found specific families disproportionately produced top scholars, intellectual achievement could still be the product of economic status, family culture, or other non-genetic factors. Galton was also, possibly, the first to popularise the idea that the heritability of psychological traits could be studied by looking at identical and fraternal twins. Although his methods were crude by modern standards, Galton established intelligence as a variable that could be measured. The person best known for formally pioneering the measurement of intellectual ability is Alfred Binet. Like Galton, Binet was fascinated by individual differences in intelligence. For instance, he blindfolded chess players and saw that some of them had the ability to continue playing using only their memory to keep the many positions of the pieces in mind. Binet was particularly interested in the development of intelligence, a fascination that led him to observe children carefully in the classroom setting. Along with his colleague Theodore Simon, Binet created a test of children’s intellectual capacity. They created individual test items that should be answerable by children of given ages. For instance, a child who is three should be able to point to her mouth and eyes, a child who is nine should be able to name the months of the year in order, and a twelve-year-old ought to be able to name sixty words in three minutes. Their assessment became the first ‘IQ test’.",
    "ImageID": "",
    "question": "The passage is about:",
    "options": {
      "a": "Different scientists and their experi ments for measuring intelligence.",
      "b": "The history of the evolution of intel ligence in human beings.",
      "c": "How scientists reached their first au thentic IQ test.",
      "d": "Defining and measuring intelligence."
    },
    "answer": "d",
    "explanation": "The question is basically asking the theme of the passage. Option A covers only examples cited in the passage, but it is not why the pas sage has been written. Option B covers only one aspect of the passage; it doesn’t cover the measure ment part of the passage. Option C is the same as option B. Option D is the answer here, as it covers the entire passage. In the first three par agraphs, the author has defined intelli gence, and then in the later paragraphs, he discusses different attempts made by scientists for measuring intelligence. Hence, option D is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 83,
    "passage": "  When you think of ‘smart people’, you likely have an intuitive sense of the qualities that make them intelligent. Maybe you think they have a good memory, or that they can think quickly, or that they simply know a whole lot of information. Indeed, people who exhibit such qualities appear very intelligent. That said, it seems that intelligence must be more than simply knowing facts and being able to remember them. One point in favour of this argument is the idea of animal intelligence. It will come as no surprise to you that a dog, which can learn commands and tricks seems smarter than a snake that cannot. In fact, researchers and laypeople generally agree with one another that primates— monkeys and apes (including humans)—are among the most intelligent animals. Apes such as chimpanzees are capable of complex problem solving and sophisticated communication. Scientists point to the social nature of primates as one evolutionary source of their intelligence. Primates live together in troops or family groups and are, therefore, highly social creatures. As such, primates tend to have brains that are better developed for communication and long-term thinking than most other animals. For instance, the complex social environment has led primates to develop deception, altruism, numerical concepts, and ‘theory of mind’ (a sense of the self as a unique individual separate from others in the group. The question of what constitutes human intelligence is one of the oldest inquiries in psychology. When we talk about intelligence we typically mean intellectual ability. This broadly encompasses the ability to learn, remember and use new information, solve problems and adapt to novel situations. An early scholar of intelligence, Charles Spearman, proposed the idea that intelligence was one thing, a ‘general factor’  sometimes known as simply ‘g.’ He based this conclusion on the observation that people who perform well in one intellectual area such as verbal ability also tend to perform well in other areas such as logic and reasoning A contemporary of Spearman’s named Francis Galton—himself a cousin of Charles Darwin—was among those who pioneered psychological measurement. For three pence Galton would measure various physical characteristics such as grip strength but also some psychological attributes such as the ability to judge distance or discriminate between colours. This is an example of one of the earliest systematic measures of individual ability. Galton was particularly interested in intelligence, which he thought was heritable in much the same way that height and eye colour are. He conceived of several rudimentary methods for assessing whether his hypothesis was true. For example, he carefully tracked the family tree of the top-scoring Cambridge students over the previous 40 years. Although he found specific families disproportionately produced top scholars, intellectual achievement could still be the product of economic status, family culture, or other non-genetic factors. Galton was also, possibly, the first to popularise the idea that the heritability of psychological traits could be studied by looking at identical and fraternal twins. Although his methods were crude by modern standards, Galton established intelligence as a variable that could be measured. The person best known for formally pioneering the measurement of intellectual ability is Alfred Binet. Like Galton, Binet was fascinated by individual differences in intelligence. For instance, he blindfolded chess players and saw that some of them had the ability to continue playing using only their memory to keep the many positions of the pieces in mind. Binet was particularly interested in the development of intelligence, a fascination that led him to observe children carefully in the classroom setting. Along with his colleague Theodore Simon, Binet created a test of children’s intellectual capacity. They created individual test items that should be answerable by children of given ages. For instance, a child who is three should be able to point to her mouth and eyes, a child who is nine should be able to name the months of the year in order, and a twelve-year-old ought to be able to name sixty words in three minutes. Their assessment became the first ‘IQ test’.",
    "ImageID": "",
    "question": "Which of the following is not true about intelligence?",
    "options": {
      "a": "The social nature of a species can be an indicator of its intelligence.",
      "b": "Deception and altruism can be a sign of intelligence.",
      "c": "Intelligence is simply knowing facts and being able to remember them.",
      "d": "The ability to solve complex prob lems is an indicator of intelligence."
    },
    "answer": "c",
    "explanation": "Options A and B can be inferred from the second paragraph. Option D can be inferred from the third paragraph. The passage says (first para) that in telligence is more than simply knowing facts and being able to remember them. Hence option C cannot be inferred and is the correct answer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 84,
    "passage": "  When you think of ‘smart people’, you likely have an intuitive sense of the qualities that make them intelligent. Maybe you think they have a good memory, or that they can think quickly, or that they simply know a whole lot of information. Indeed, people who exhibit such qualities appear very intelligent. That said, it seems that intelligence must be more than simply knowing facts and being able to remember them. One point in favour of this argument is the idea of animal intelligence. It will come as no surprise to you that a dog, which can learn commands and tricks seems smarter than a snake that cannot. In fact, researchers and laypeople generally agree with one another that primates— monkeys and apes (including humans)—are among the most intelligent animals. Apes such as chimpanzees are capable of complex problem solving and sophisticated communication. Scientists point to the social nature of primates as one evolutionary source of their intelligence. Primates live together in troops or family groups and are, therefore, highly social creatures. As such, primates tend to have brains that are better developed for communication and long-term thinking than most other animals. For instance, the complex social environment has led primates to develop deception, altruism, numerical concepts, and ‘theory of mind’ (a sense of the self as a unique individual separate from others in the group. The question of what constitutes human intelligence is one of the oldest inquiries in psychology. When we talk about intelligence we typically mean intellectual ability. This broadly encompasses the ability to learn, remember and use new information, solve problems and adapt to novel situations. An early scholar of intelligence, Charles Spearman, proposed the idea that intelligence was one thing, a ‘general factor’  sometimes known as simply ‘g.’ He based this conclusion on the observation that people who perform well in one intellectual area such as verbal ability also tend to perform well in other areas such as logic and reasoning A contemporary of Spearman’s named Francis Galton—himself a cousin of Charles Darwin—was among those who pioneered psychological measurement. For three pence Galton would measure various physical characteristics such as grip strength but also some psychological attributes such as the ability to judge distance or discriminate between colours. This is an example of one of the earliest systematic measures of individual ability. Galton was particularly interested in intelligence, which he thought was heritable in much the same way that height and eye colour are. He conceived of several rudimentary methods for assessing whether his hypothesis was true. For example, he carefully tracked the family tree of the top-scoring Cambridge students over the previous 40 years. Although he found specific families disproportionately produced top scholars, intellectual achievement could still be the product of economic status, family culture, or other non-genetic factors. Galton was also, possibly, the first to popularise the idea that the heritability of psychological traits could be studied by looking at identical and fraternal twins. Although his methods were crude by modern standards, Galton established intelligence as a variable that could be measured. The person best known for formally pioneering the measurement of intellectual ability is Alfred Binet. Like Galton, Binet was fascinated by individual differences in intelligence. For instance, he blindfolded chess players and saw that some of them had the ability to continue playing using only their memory to keep the many positions of the pieces in mind. Binet was particularly interested in the development of intelligence, a fascination that led him to observe children carefully in the classroom setting. Along with his colleague Theodore Simon, Binet created a test of children’s intellectual capacity. They created individual test items that should be answerable by children of given ages. For instance, a child who is three should be able to point to her mouth and eyes, a child who is nine should be able to name the months of the year in order, and a twelve-year-old ought to be able to name sixty words in three minutes. Their assessment became the first ‘IQ test’.",
    "ImageID": "",
    "question": "Which of the following has not been claimed in the passage?",
    "options": {
      "a": "Spearman defined intelligence as a gen eral factor, and he believed that a per son performing well in one area is likely to perform well in other areas as well.",
      "b": "Galton thought that intelligence is her itable, and he looked at intelligence as a variable that can be measured.",
      "c": "Binet was interested in the devel opment of intelligence in individuals and he was the first to measure in telligence in humans.",
      "d": "A child who is three should be able to point to her mouth and eyes. A child who is nine should be able to name the months of the year in order."
    },
    "answer": "c",
    "explanation": "A simple reading of the passage should suffice to answer this question. Option A can be confirmed from the third para. Option B can be confirmed from the fifth para. Option D can be confirmed from the last para. Option C is not true; hence it is the an swer here.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 85,
    "passage": "  When you think of ‘smart people’, you likely have an intuitive sense of the qualities that make them intelligent. Maybe you think they have a good memory, or that they can think quickly, or that they simply know a whole lot of information. Indeed, people who exhibit such qualities appear very intelligent. That said, it seems that intelligence must be more than simply knowing facts and being able to remember them. One point in favour of this argument is the idea of animal intelligence. It will come as no surprise to you that a dog, which can learn commands and tricks seems smarter than a snake that cannot. In fact, researchers and laypeople generally agree with one another that primates— monkeys and apes (including humans)—are among the most intelligent animals. Apes such as chimpanzees are capable of complex problem solving and sophisticated communication. Scientists point to the social nature of primates as one evolutionary source of their intelligence. Primates live together in troops or family groups and are, therefore, highly social creatures. As such, primates tend to have brains that are better developed for communication and long-term thinking than most other animals. For instance, the complex social environment has led primates to develop deception, altruism, numerical concepts, and ‘theory of mind’ (a sense of the self as a unique individual separate from others in the group. The question of what constitutes human intelligence is one of the oldest inquiries in psychology. When we talk about intelligence we typically mean intellectual ability. This broadly encompasses the ability to learn, remember and use new information, solve problems and adapt to novel situations. An early scholar of intelligence, Charles Spearman, proposed the idea that intelligence was one thing, a ‘general factor’  sometimes known as simply ‘g.’ He based this conclusion on the observation that people who perform well in one intellectual area such as verbal ability also tend to perform well in other areas such as logic and reasoning A contemporary of Spearman’s named Francis Galton—himself a cousin of Charles Darwin—was among those who pioneered psychological measurement. For three pence Galton would measure various physical characteristics such as grip strength but also some psychological attributes such as the ability to judge distance or discriminate between colours. This is an example of one of the earliest systematic measures of individual ability. Galton was particularly interested in intelligence, which he thought was heritable in much the same way that height and eye colour are. He conceived of several rudimentary methods for assessing whether his hypothesis was true. For example, he carefully tracked the family tree of the top-scoring Cambridge students over the previous 40 years. Although he found specific families disproportionately produced top scholars, intellectual achievement could still be the product of economic status, family culture, or other non-genetic factors. Galton was also, possibly, the first to popularise the idea that the heritability of psychological traits could be studied by looking at identical and fraternal twins. Although his methods were crude by modern standards, Galton established intelligence as a variable that could be measured. The person best known for formally pioneering the measurement of intellectual ability is Alfred Binet. Like Galton, Binet was fascinated by individual differences in intelligence. For instance, he blindfolded chess players and saw that some of them had the ability to continue playing using only their memory to keep the many positions of the pieces in mind. Binet was particularly interested in the development of intelligence, a fascination that led him to observe children carefully in the classroom setting. Along with his colleague Theodore Simon, Binet created a test of children’s intellectual capacity. They created individual test items that should be answerable by children of given ages. For instance, a child who is three should be able to point to her mouth and eyes, a child who is nine should be able to name the months of the year in order, and a twelve-year-old ought to be able to name sixty words in three minutes. Their assessment became the first ‘IQ test’.",
    "ImageID": "",
    "question": "The author has cited examples of three dif ferent scientists and their experiments to:",
    "options": {
      "a": "Highlight their different perspectives of intelligence.",
      "b": "Outline the gradual develop ment of the process of intelligence measurement.",
      "c": "Show how intelligence could mean different things to different people.",
      "d": "Show that intelligence is heritable as well as depends on the interest of people."
    },
    "answer": "b",
    "explanation": "Option B captures the theme of the pas sage and justifies the flow of the pas sage. Hence, it is the correct answer. Other options have a mental aspect, and they do not justify the flow of the passage.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 86,
    "passage": " Cold War histories focusing on race, culture, gender, and geopolitics frequently acknowledge the importance of science as a tool of government policy, but the ideological underpinnings that define, legitimise, and perpetuate concepts of scientific freedom are seldom explored. Audra Wolfe innovatively addresses this gap in Freedom’s Laboratory by examining how the U.S. government targeted the Soviet Union from 1947 to 1989 using the concept of ‘scientific freedom’ as a form of ideological containment. Paradoxically, Wolfe argues that apolitical science and the free exchange of information were political constructions perpetuated by U.S. officials and academics seeking to win ‘global hearts and minds’ by contrasting Western scientific benevolence and objectivity against perceived statist biases tainting the Soviet scientific establishment. Although many American scientists relied on government contracts, she claims few saw any conflict of interest with their commitment to apolitical science. Wolfe convincingly demonstrates that concepts of scientific freedom constituted critical elements of Cold War cultural diplomacy conducted on disparate fronts by scientists, journalists, and government officials. Wolfe argues that these ideological divisions formed in response to Joseph Stalin’s persecution of geneticists in the 1930s and the notorious Soviet geneticist Trofim Lysenko’s subsequent rise to power in the Soviet scientific community. This controversy spawned ‘Lysenkoism’, a term Wolfe defines as the perception that Soviet science was corrupt and brutally politicised. Wolfe focuses much of her research on how the field of genetics influenced concepts of scientific freedom, and U.S. geneticists such as Hermann Joseph Muller and H. Bentley Glass assume various roles as social commentators, ideologues, and scientific advisers. Wolfe  concludes that Lysenkoism merged with a general critique of statist science inspired by Nazi Germany’s failed nuclear program and that together these sentiments justified convictions that scientific progress lay with the free and democratic exchange of knowledge. Scientific freedom easily translated into ‘scientific internationalism’, a nebulous term Wolfe uses to define the international exchange of scientific information and the cultivation of a transnational scientific community. She argues that this concept was overtly incorporated into U.S. foreign policy in the 1950s through the establishment of State Department science attachés. Ostensibly assigned to cultivate international scientific networks, the attachés were also instructed to investigate foreign scientific developments. Wolfe concludes that inherent contradictions within this dual overt and covert program ultimately led to its failure once attachés found themselves distrusted by foreign colleagues and U.S. anti-Communists alike. As a result, Wolfe writes that U.S. intelligence organisations reduced their reliance on science attachés even while increasingly incorporating the ideology of scientific freedom into covert programs. These connections are apparent in Wolfe’s analysis of the Congress for Cultural Freedom (CCF), an ostensibly private organisation covertly funded by the U.S. Central Intelligence Agency (CIA). Although many historians have examined the CCF, an organisation that sponsored private publications and conferences with the intention of influencing Europe’s intellectual environment, Wolfe argues that scientific freedom formed an important element of these broader propaganda campaigns. Coordination between the CIA and private individuals proved unwieldy however, exemplified by difficulties the CCF main office encountered when pushing affiliate Michael Polanyi and his family-run periodical Science and Freedom to publish harsher critiques of Communist countries. Reading Comprehension – Basic LevelFor Wolfe, Polanyi’s case is indicative of the awkward positions U.S. intelligence agencies were in when cooperating with private citizens and foreign nationals to mask governmental interference.",
    "ImageID": "",
    "question": "According to Wolfe, the idea of apolit ical science and the free exchange of information:",
    "options": {
      "a": "Was used as a tool by U.S. officials and academics to fool the world about their real intentions.",
      "b": "Was used as a tool by U.S. officials and academics to win the hearts and minds of the world.",
      "c": "Was used as a tool by U.S. officials and academics to malign the Soviet scientific establishments.",
      "d": "Was used as a tool by U.S. offi cials and academics to win over the hearts and minds of people across the world while cunningly maligning the Soviet scientific establishments."
    },
    "answer": "d",
    "explanation": "Option D gives a complete picture of the USA’s intention, as argued by Wolfe. So, D will be the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 87,
    "passage": " Cold War histories focusing on race, culture, gender, and geopolitics frequently acknowledge the importance of science as a tool of government policy, but the ideological underpinnings that define, legitimise, and perpetuate concepts of scientific freedom are seldom explored. Audra Wolfe innovatively addresses this gap in Freedom’s Laboratory by examining how the U.S. government targeted the Soviet Union from 1947 to 1989 using the concept of ‘scientific freedom’ as a form of ideological containment. Paradoxically, Wolfe argues that apolitical science and the free exchange of information were political constructions perpetuated by U.S. officials and academics seeking to win ‘global hearts and minds’ by contrasting Western scientific benevolence and objectivity against perceived statist biases tainting the Soviet scientific establishment. Although many American scientists relied on government contracts, she claims few saw any conflict of interest with their commitment to apolitical science. Wolfe convincingly demonstrates that concepts of scientific freedom constituted critical elements of Cold War cultural diplomacy conducted on disparate fronts by scientists, journalists, and government officials. Wolfe argues that these ideological divisions formed in response to Joseph Stalin’s persecution of geneticists in the 1930s and the notorious Soviet geneticist Trofim Lysenko’s subsequent rise to power in the Soviet scientific community. This controversy spawned ‘Lysenkoism’, a term Wolfe defines as the perception that Soviet science was corrupt and brutally politicised. Wolfe focuses much of her research on how the field of genetics influenced concepts of scientific freedom, and U.S. geneticists such as Hermann Joseph Muller and H. Bentley Glass assume various roles as social commentators, ideologues, and scientific advisers. Wolfe  concludes that Lysenkoism merged with a general critique of statist science inspired by Nazi Germany’s failed nuclear program and that together these sentiments justified convictions that scientific progress lay with the free and democratic exchange of knowledge. Scientific freedom easily translated into ‘scientific internationalism’, a nebulous term Wolfe uses to define the international exchange of scientific information and the cultivation of a transnational scientific community. She argues that this concept was overtly incorporated into U.S. foreign policy in the 1950s through the establishment of State Department science attachés. Ostensibly assigned to cultivate international scientific networks, the attachés were also instructed to investigate foreign scientific developments. Wolfe concludes that inherent contradictions within this dual overt and covert program ultimately led to its failure once attachés found themselves distrusted by foreign colleagues and U.S. anti-Communists alike. As a result, Wolfe writes that U.S. intelligence organisations reduced their reliance on science attachés even while increasingly incorporating the ideology of scientific freedom into covert programs. These connections are apparent in Wolfe’s analysis of the Congress for Cultural Freedom (CCF), an ostensibly private organisation covertly funded by the U.S. Central Intelligence Agency (CIA). Although many historians have examined the CCF, an organisation that sponsored private publications and conferences with the intention of influencing Europe’s intellectual environment, Wolfe argues that scientific freedom formed an important element of these broader propaganda campaigns. Coordination between the CIA and private individuals proved unwieldy however, exemplified by difficulties the CCF main office encountered when pushing affiliate Michael Polanyi and his family-run periodical Science and Freedom to publish harsher critiques of Communist countries. Reading Comprehension – Basic LevelFor Wolfe, Polanyi’s case is indicative of the awkward positions U.S. intelligence agencies were in when cooperating with private citizens and foreign nationals to mask governmental interference.",
    "ImageID": "",
    "question": "In the statement ‘Wolfe argues that these ideological divisions formed…’ (first sentence, second para), the phrase ‘these ideological divisions’ refers to:",
    "options": {
      "a": "Cold War histories acknowledging the importance of science as a tool of government policy but ignoring the ideological underpinnings that define, legitimise, and perpetuate concepts of scientific freedom.",
      "b": "The fundamental difference be tween apolitical science and political science.",
      "c": "The difference between the U.S.A’s approach towards science and Soviet’s approach towards science.",
      "d": "The difference between Soviet ge neticist Trofim Lysenko and U.S. ge neticists Hermann Joseph Muller and H. Bentley Glass."
    },
    "answer": "c",
    "explanation": "The pronoun ‘these’ simply indicates that something that has been mentioned ear lier is being discussed. So, by common sense option D cannot be the answer, as this fact has been discussed after that phrase. Option A is not talking about any division but the gap (discontinuity) between the two approaches. Option B is irrelevant. After reading the f irst paragraph, one can observe that the U.S.A’s handling of science and the Soviet’s handling of science are the sub jects of discussion. So, option C is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 88,
    "passage": " Cold War histories focusing on race, culture, gender, and geopolitics frequently acknowledge the importance of science as a tool of government policy, but the ideological underpinnings that define, legitimise, and perpetuate concepts of scientific freedom are seldom explored. Audra Wolfe innovatively addresses this gap in Freedom’s Laboratory by examining how the U.S. government targeted the Soviet Union from 1947 to 1989 using the concept of ‘scientific freedom’ as a form of ideological containment. Paradoxically, Wolfe argues that apolitical science and the free exchange of information were political constructions perpetuated by U.S. officials and academics seeking to win ‘global hearts and minds’ by contrasting Western scientific benevolence and objectivity against perceived statist biases tainting the Soviet scientific establishment. Although many American scientists relied on government contracts, she claims few saw any conflict of interest with their commitment to apolitical science. Wolfe convincingly demonstrates that concepts of scientific freedom constituted critical elements of Cold War cultural diplomacy conducted on disparate fronts by scientists, journalists, and government officials. Wolfe argues that these ideological divisions formed in response to Joseph Stalin’s persecution of geneticists in the 1930s and the notorious Soviet geneticist Trofim Lysenko’s subsequent rise to power in the Soviet scientific community. This controversy spawned ‘Lysenkoism’, a term Wolfe defines as the perception that Soviet science was corrupt and brutally politicised. Wolfe focuses much of her research on how the field of genetics influenced concepts of scientific freedom, and U.S. geneticists such as Hermann Joseph Muller and H. Bentley Glass assume various roles as social commentators, ideologues, and scientific advisers. Wolfe  concludes that Lysenkoism merged with a general critique of statist science inspired by Nazi Germany’s failed nuclear program and that together these sentiments justified convictions that scientific progress lay with the free and democratic exchange of knowledge. Scientific freedom easily translated into ‘scientific internationalism’, a nebulous term Wolfe uses to define the international exchange of scientific information and the cultivation of a transnational scientific community. She argues that this concept was overtly incorporated into U.S. foreign policy in the 1950s through the establishment of State Department science attachés. Ostensibly assigned to cultivate international scientific networks, the attachés were also instructed to investigate foreign scientific developments. Wolfe concludes that inherent contradictions within this dual overt and covert program ultimately led to its failure once attachés found themselves distrusted by foreign colleagues and U.S. anti-Communists alike. As a result, Wolfe writes that U.S. intelligence organisations reduced their reliance on science attachés even while increasingly incorporating the ideology of scientific freedom into covert programs. These connections are apparent in Wolfe’s analysis of the Congress for Cultural Freedom (CCF), an ostensibly private organisation covertly funded by the U.S. Central Intelligence Agency (CIA). Although many historians have examined the CCF, an organisation that sponsored private publications and conferences with the intention of influencing Europe’s intellectual environment, Wolfe argues that scientific freedom formed an important element of these broader propaganda campaigns. Coordination between the CIA and private individuals proved unwieldy however, exemplified by difficulties the CCF main office encountered when pushing affiliate Michael Polanyi and his family-run periodical Science and Freedom to publish harsher critiques of Communist countries. Reading Comprehension – Basic LevelFor Wolfe, Polanyi’s case is indicative of the awkward positions U.S. intelligence agencies were in when cooperating with private citizens and foreign nationals to mask governmental interference.",
    "ImageID": "",
    "question": "All of the following metaphors can be in ferred from the passage, except:",
    "options": {
      "a": "Scientific progress is a free and dem ocratic exchange of knowledge.",
      "b": "Scientific freedom is scientific internationalism.",
      "c": "Lysenkoism is fascism.",
      "d": "Apolitical science and the free ex change of information are political constructions."
    },
    "answer": "c",
    "explanation": "Option A can be inferred from the last sentence of the second para. Option B can be inferred from the first line of the third para. Option D can be inferred from the first passage. Option C cannot be inferred from the passage. Hence, it is the correct answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 89,
    "passage": " Cold War histories focusing on race, culture, gender, and geopolitics frequently acknowledge the importance of science as a tool of government policy, but the ideological underpinnings that define, legitimise, and perpetuate concepts of scientific freedom are seldom explored. Audra Wolfe innovatively addresses this gap in Freedom’s Laboratory by examining how the U.S. government targeted the Soviet Union from 1947 to 1989 using the concept of ‘scientific freedom’ as a form of ideological containment. Paradoxically, Wolfe argues that apolitical science and the free exchange of information were political constructions perpetuated by U.S. officials and academics seeking to win ‘global hearts and minds’ by contrasting Western scientific benevolence and objectivity against perceived statist biases tainting the Soviet scientific establishment. Although many American scientists relied on government contracts, she claims few saw any conflict of interest with their commitment to apolitical science. Wolfe convincingly demonstrates that concepts of scientific freedom constituted critical elements of Cold War cultural diplomacy conducted on disparate fronts by scientists, journalists, and government officials. Wolfe argues that these ideological divisions formed in response to Joseph Stalin’s persecution of geneticists in the 1930s and the notorious Soviet geneticist Trofim Lysenko’s subsequent rise to power in the Soviet scientific community. This controversy spawned ‘Lysenkoism’, a term Wolfe defines as the perception that Soviet science was corrupt and brutally politicised. Wolfe focuses much of her research on how the field of genetics influenced concepts of scientific freedom, and U.S. geneticists such as Hermann Joseph Muller and H. Bentley Glass assume various roles as social commentators, ideologues, and scientific advisers. Wolfe  concludes that Lysenkoism merged with a general critique of statist science inspired by Nazi Germany’s failed nuclear program and that together these sentiments justified convictions that scientific progress lay with the free and democratic exchange of knowledge. Scientific freedom easily translated into ‘scientific internationalism’, a nebulous term Wolfe uses to define the international exchange of scientific information and the cultivation of a transnational scientific community. She argues that this concept was overtly incorporated into U.S. foreign policy in the 1950s through the establishment of State Department science attachés. Ostensibly assigned to cultivate international scientific networks, the attachés were also instructed to investigate foreign scientific developments. Wolfe concludes that inherent contradictions within this dual overt and covert program ultimately led to its failure once attachés found themselves distrusted by foreign colleagues and U.S. anti-Communists alike. As a result, Wolfe writes that U.S. intelligence organisations reduced their reliance on science attachés even while increasingly incorporating the ideology of scientific freedom into covert programs. These connections are apparent in Wolfe’s analysis of the Congress for Cultural Freedom (CCF), an ostensibly private organisation covertly funded by the U.S. Central Intelligence Agency (CIA). Although many historians have examined the CCF, an organisation that sponsored private publications and conferences with the intention of influencing Europe’s intellectual environment, Wolfe argues that scientific freedom formed an important element of these broader propaganda campaigns. Coordination between the CIA and private individuals proved unwieldy however, exemplified by difficulties the CCF main office encountered when pushing affiliate Michael Polanyi and his family-run periodical Science and Freedom to publish harsher critiques of Communist countries. Reading Comprehension – Basic LevelFor Wolfe, Polanyi’s case is indicative of the awkward positions U.S. intelligence agencies were in when cooperating with private citizens and foreign nationals to mask governmental interference.",
    "ImageID": "",
    "question": "All of the following arguments have been made by Wolfe, except:",
    "options": {
      "a": "Scientific internationalism was overtly incorporated into U.S. foreign policy through the establishment of State Department science attachés.",
      "b": "State Department science attachés were ostensibly assigned to cultivate international scientific networks.",
      "c": "State Department science attachés were instructed to investigate for eign scientific developments.",
      "d": "Using science attachés in overt and covert programs simultaneously ul timately led to a failure, so U.S. in telligence organisations stopped in corporating the ideology of scientific freedom into covert programs."
    },
    "answer": "d",
    "explanation": "Reading the third paragraph carefully re veals that A, B, and C have been claimed by Wolfe, but option D is only partially correct. U.S intelligence organisations did not stop incorporating the ideology of scientific freedom into covert pro grams; they only reduced their reliance on science attachés.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 90,
    "passage": " Cold War histories focusing on race, culture, gender, and geopolitics frequently acknowledge the importance of science as a tool of government policy, but the ideological underpinnings that define, legitimise, and perpetuate concepts of scientific freedom are seldom explored. Audra Wolfe innovatively addresses this gap in Freedom’s Laboratory by examining how the U.S. government targeted the Soviet Union from 1947 to 1989 using the concept of ‘scientific freedom’ as a form of ideological containment. Paradoxically, Wolfe argues that apolitical science and the free exchange of information were political constructions perpetuated by U.S. officials and academics seeking to win ‘global hearts and minds’ by contrasting Western scientific benevolence and objectivity against perceived statist biases tainting the Soviet scientific establishment. Although many American scientists relied on government contracts, she claims few saw any conflict of interest with their commitment to apolitical science. Wolfe convincingly demonstrates that concepts of scientific freedom constituted critical elements of Cold War cultural diplomacy conducted on disparate fronts by scientists, journalists, and government officials. Wolfe argues that these ideological divisions formed in response to Joseph Stalin’s persecution of geneticists in the 1930s and the notorious Soviet geneticist Trofim Lysenko’s subsequent rise to power in the Soviet scientific community. This controversy spawned ‘Lysenkoism’, a term Wolfe defines as the perception that Soviet science was corrupt and brutally politicised. Wolfe focuses much of her research on how the field of genetics influenced concepts of scientific freedom, and U.S. geneticists such as Hermann Joseph Muller and H. Bentley Glass assume various roles as social commentators, ideologues, and scientific advisers. Wolfe  concludes that Lysenkoism merged with a general critique of statist science inspired by Nazi Germany’s failed nuclear program and that together these sentiments justified convictions that scientific progress lay with the free and democratic exchange of knowledge. Scientific freedom easily translated into ‘scientific internationalism’, a nebulous term Wolfe uses to define the international exchange of scientific information and the cultivation of a transnational scientific community. She argues that this concept was overtly incorporated into U.S. foreign policy in the 1950s through the establishment of State Department science attachés. Ostensibly assigned to cultivate international scientific networks, the attachés were also instructed to investigate foreign scientific developments. Wolfe concludes that inherent contradictions within this dual overt and covert program ultimately led to its failure once attachés found themselves distrusted by foreign colleagues and U.S. anti-Communists alike. As a result, Wolfe writes that U.S. intelligence organisations reduced their reliance on science attachés even while increasingly incorporating the ideology of scientific freedom into covert programs. These connections are apparent in Wolfe’s analysis of the Congress for Cultural Freedom (CCF), an ostensibly private organisation covertly funded by the U.S. Central Intelligence Agency (CIA). Although many historians have examined the CCF, an organisation that sponsored private publications and conferences with the intention of influencing Europe’s intellectual environment, Wolfe argues that scientific freedom formed an important element of these broader propaganda campaigns. Coordination between the CIA and private individuals proved unwieldy however, exemplified by difficulties the CCF main office encountered when pushing affiliate Michael Polanyi and his family-run periodical Science and Freedom to publish harsher critiques of Communist countries. Reading Comprehension – Basic LevelFor Wolfe, Polanyi’s case is indicative of the awkward positions U.S. intelligence agencies were in when cooperating with private citizens and foreign nationals to mask governmental interference.",
    "ImageID": "",
    "question": "What could be a suitable title for this passage?",
    "options": {
      "a": "Cold War Science",
      "b": "Cold War and Science",
      "c": "Scientific Freedom: benevolence or propaganda?",
      "d": "Communist Science vs Capitalist Science"
    },
    "answer": "c",
    "explanation": "Option C captures the essence of the passage, as it covers the theme that has been repeatedly highlighted throughout the passage. Option A is incorrect; the phrase Cold War Science sounds like the science of cold war, which is certainly not the theme of the passage. Option B is inaccurate, as science and the Cold War are not the subjects of discussion here. Hence, option C is the most accurate choice because the pas sage examines the astute way in which the U.S. intelligence agencies pushed the ideology of scientific freedom in a dual way.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 91,
    "passage": " Read the passage carefully and answer the questions that follow. The scope of philosophy is any critical appraisal of religion. It is an ancient discipline, being found in the earliest known manuscripts concerning philosophy, and relates to many other branches of philosophy and general thought, including Metaphysics, Epistemology, Logic, and History. Let us begin by admitting the fact that, historically, no organised religion can stand up to honest criticism and come’ out of it with an unblemished report card. None of the mainline religions has proved itself to have always been and everywhere a reliable friend of ‘people struggling for liberation and emancipation. Often religions have added to the oppression, discrimination, and blood-letting that have plagued the world since time began. The subjugation of women has often been given religious sanction. The most cruel and bloodthirsty wars have been inspired by religious differences, with each side proclaiming an exclusive ‘Gott mit uns’ (God with us), while hailing all opponents as hirelings of Satan incarnate. Religion has often opposed scientific research and sided with obscurantism and superstition against trends of enlightenment. And politicians, especially in Third World countries, have learned that religion is the easiest handle with which to manipulate impoverished and oppressed masses, stirring up all kinds of mob violence and building up their ‘vote banks’. Indeed, religious leadership seems to be the last bastion of male exclusivism, determined to hold out against ‘female: incursions’ by all manner of pseudo-theological, philosophical, and sociological arguments to preserve power in the hands of men only. The priestly Conquerors’ Club is a very powerful and jealously guarded coterie of old men who, with bulldog tenacity, clings with alarm to its ever-shrinking list of ‘privileges and prerogatives’. Above all, it stands ready to flash its magic wand of ‘God’s will’ and ‘the divinely established scheme of things’ to justify and protect the status quo (heavily loaded in its favour) and block any attempt at reform which just might among other things, help towards a more authentic encounter with God. On the other hand (there always is the other hand, isn’t it?), religions have also inspired many to selfless service to the downtrodden, have given humans a rich legacy of art and beauty as well as played a not insignificant role in opening our eyes to the essential dignity of the human person, irrespective of race, colour, or sex. Some religious personalities—Mother Teresa, Dorothy Day, Mahatma Gandhi, Oscar Romero, Desmond Tutu—have been true friends to liberation movements. Yet, when all is said and done, it would appear that some kind of institutionalisation or organisation of religion is inevitable—unless we are quite prepared to accept the consequences of reducing it to some sort of private, abstract, and ‘spiritual’ preoccupation. In fact, we can cite at least three major reasons why some kind of organisation in religion is not merely to be tolerated as unavoidable, but even accepted as inevitable. First, in as much as we are embodied beings, we cannot be satisfied with an intangible something, which remains at that level. Anything that we take seriously must be embodied in some way, through some manner of institutionalisation, just as our love for our country must be given tangible expression in flag-hoisting and march pasts and our love for our family and friends has to be rendered incarnate in birthday parties and family gatherings. Anything less would but touch us lightly and leave us with a profound sense of frustration. Second, if religion is to have some social significance, if it is to have some transformative, reformative impact upon society—inspiring people to work for justice and peace, or in support of the environment—it requires some kind of communitarian expression. Finally, if it is Reading Comprehension – Basic Levelnot to become a fleeting, fly-by-night sort of thing, here today, and gone tomorrow, coming to birth and dying with each individual’s alleged encounter with the powers that be, it must have some concrete form to ensure the sharing, preservation and development of its tradition. Actually, if we look a bit more closely at the objections against organised religion, it would probably become clear that these objections are not so much aimed at the very fact that religions are organised but at the rigid authoritarian way in which they have been organised. That is the real villain.",
    "ImageID": "",
    "question": "Why does the author claim that all reli gious wars have begun with ‘Gott mit uns’?",
    "options": {
      "a": "To highlight the arbitrary nature of the involvement of God in these wars.",
      "b": "That men hide behind the shield of God to exploit the credulity of the believers.",
      "c": "To highlight the bloody consequenc es of religious intolerance ever re corded in human history.",
      "d": "However, one may dress up the fun damentals, the divine scheme is a nefarious idea only to exploit women."
    },
    "answer": "b",
    "explanation": "The use of the phrase ‘Gott mitt uns’ can be observed at the ending of the first par agraph. The application of this phrase by each side highlights the consequences of religious intolerance worldwide and shows how men can easily manipulate the mass es to do their bidding, not of God itself. Point of reference: Final line, First paragraph. The most cruel and bloodthirsty wars have been inspired by religious differences, with each side proclaiming an exclusive ‘Gott mit uns’ (God with us) while hailing all op ponents as hirelings of Satan incarnate. Options A, C, and D are to be rejected as the answer. God’s arbitrary involvement in the religious crusades, the consequenc es of religious intolerance, and the prop er use of ideas such as direct or indirect divine intervention to exploit women are only touching on the secondary implica tions behind the religious wars. Option B is the right choice. Under the guise of hailing God, the men of power only exploit the believers’ credulity to satisfy their agendas.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 92,
    "passage": " Read the passage carefully and answer the questions that follow. The scope of philosophy is any critical appraisal of religion. It is an ancient discipline, being found in the earliest known manuscripts concerning philosophy, and relates to many other branches of philosophy and general thought, including Metaphysics, Epistemology, Logic, and History. Let us begin by admitting the fact that, historically, no organised religion can stand up to honest criticism and come’ out of it with an unblemished report card. None of the mainline religions has proved itself to have always been and everywhere a reliable friend of ‘people struggling for liberation and emancipation. Often religions have added to the oppression, discrimination, and blood-letting that have plagued the world since time began. The subjugation of women has often been given religious sanction. The most cruel and bloodthirsty wars have been inspired by religious differences, with each side proclaiming an exclusive ‘Gott mit uns’ (God with us), while hailing all opponents as hirelings of Satan incarnate. Religion has often opposed scientific research and sided with obscurantism and superstition against trends of enlightenment. And politicians, especially in Third World countries, have learned that religion is the easiest handle with which to manipulate impoverished and oppressed masses, stirring up all kinds of mob violence and building up their ‘vote banks’. Indeed, religious leadership seems to be the last bastion of male exclusivism, determined to hold out against ‘female: incursions’ by all manner of pseudo-theological, philosophical, and sociological arguments to preserve power in the hands of men only. The priestly Conquerors’ Club is a very powerful and jealously guarded coterie of old men who, with bulldog tenacity, clings with alarm to its ever-shrinking list of ‘privileges and prerogatives’. Above all, it stands ready to flash its magic wand of ‘God’s will’ and ‘the divinely established scheme of things’ to justify and protect the status quo (heavily loaded in its favour) and block any attempt at reform which just might among other things, help towards a more authentic encounter with God. On the other hand (there always is the other hand, isn’t it?), religions have also inspired many to selfless service to the downtrodden, have given humans a rich legacy of art and beauty as well as played a not insignificant role in opening our eyes to the essential dignity of the human person, irrespective of race, colour, or sex. Some religious personalities—Mother Teresa, Dorothy Day, Mahatma Gandhi, Oscar Romero, Desmond Tutu—have been true friends to liberation movements. Yet, when all is said and done, it would appear that some kind of institutionalisation or organisation of religion is inevitable—unless we are quite prepared to accept the consequences of reducing it to some sort of private, abstract, and ‘spiritual’ preoccupation. In fact, we can cite at least three major reasons why some kind of organisation in religion is not merely to be tolerated as unavoidable, but even accepted as inevitable. First, in as much as we are embodied beings, we cannot be satisfied with an intangible something, which remains at that level. Anything that we take seriously must be embodied in some way, through some manner of institutionalisation, just as our love for our country must be given tangible expression in flag-hoisting and march pasts and our love for our family and friends has to be rendered incarnate in birthday parties and family gatherings. Anything less would but touch us lightly and leave us with a profound sense of frustration. Second, if religion is to have some social significance, if it is to have some transformative, reformative impact upon society—inspiring people to work for justice and peace, or in support of the environment—it requires some kind of communitarian expression. Finally, if it is Reading Comprehension – Basic Levelnot to become a fleeting, fly-by-night sort of thing, here today, and gone tomorrow, coming to birth and dying with each individual’s alleged encounter with the powers that be, it must have some concrete form to ensure the sharing, preservation and development of its tradition. Actually, if we look a bit more closely at the objections against organised religion, it would probably become clear that these objections are not so much aimed at the very fact that religions are organised but at the rigid authoritarian way in which they have been organised. That is the real villain.",
    "ImageID": "",
    "question": "Why did the author share the examples of Father of the Nation and Saint Teresa of Calcutta?",
    "options": {
      "a": "To give instances that everything is gloomy with religious personalities.",
      "b": "To highlight that the religious per sonalities, by definition, are all authoritative.",
      "c": "To contradict an assertion previously made.",
      "d": "To protect the good name of Mother Teresa and the Catholic Church."
    },
    "answer": "c",
    "explanation": "Mahatma Gandhi and Mother Teresa’s ex amples are stated to show the religious personalities or influencers who were staunch believers in religious tolerance. Point of reference: Some religious per sonalities—Mother Teresa, Dorothy Day, Mahatma Gandhi, Oscar Romero, Desmond Tutu—have been true friends to liberation movements. Options A, B, and D are invalid arguments for the use of these influential people. The one-sided and strict views of religious personalities, the traditional assumptions presented by them, and the protection of the Catholic Church’s good name are in adequate responses for stating the exam ple of these names to the reader. Option C is the only valid reason. The author began this passage by highlighting the ad verse effects of religion by counting instanc es recorded in Human history and yet gave these examples to show that religious toler ance is possible even in organised religion.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 93,
    "passage": " Read the passage carefully and answer the questions that follow. The scope of philosophy is any critical appraisal of religion. It is an ancient discipline, being found in the earliest known manuscripts concerning philosophy, and relates to many other branches of philosophy and general thought, including Metaphysics, Epistemology, Logic, and History. Let us begin by admitting the fact that, historically, no organised religion can stand up to honest criticism and come’ out of it with an unblemished report card. None of the mainline religions has proved itself to have always been and everywhere a reliable friend of ‘people struggling for liberation and emancipation. Often religions have added to the oppression, discrimination, and blood-letting that have plagued the world since time began. The subjugation of women has often been given religious sanction. The most cruel and bloodthirsty wars have been inspired by religious differences, with each side proclaiming an exclusive ‘Gott mit uns’ (God with us), while hailing all opponents as hirelings of Satan incarnate. Religion has often opposed scientific research and sided with obscurantism and superstition against trends of enlightenment. And politicians, especially in Third World countries, have learned that religion is the easiest handle with which to manipulate impoverished and oppressed masses, stirring up all kinds of mob violence and building up their ‘vote banks’. Indeed, religious leadership seems to be the last bastion of male exclusivism, determined to hold out against ‘female: incursions’ by all manner of pseudo-theological, philosophical, and sociological arguments to preserve power in the hands of men only. The priestly Conquerors’ Club is a very powerful and jealously guarded coterie of old men who, with bulldog tenacity, clings with alarm to its ever-shrinking list of ‘privileges and prerogatives’. Above all, it stands ready to flash its magic wand of ‘God’s will’ and ‘the divinely established scheme of things’ to justify and protect the status quo (heavily loaded in its favour) and block any attempt at reform which just might among other things, help towards a more authentic encounter with God. On the other hand (there always is the other hand, isn’t it?), religions have also inspired many to selfless service to the downtrodden, have given humans a rich legacy of art and beauty as well as played a not insignificant role in opening our eyes to the essential dignity of the human person, irrespective of race, colour, or sex. Some religious personalities—Mother Teresa, Dorothy Day, Mahatma Gandhi, Oscar Romero, Desmond Tutu—have been true friends to liberation movements. Yet, when all is said and done, it would appear that some kind of institutionalisation or organisation of religion is inevitable—unless we are quite prepared to accept the consequences of reducing it to some sort of private, abstract, and ‘spiritual’ preoccupation. In fact, we can cite at least three major reasons why some kind of organisation in religion is not merely to be tolerated as unavoidable, but even accepted as inevitable. First, in as much as we are embodied beings, we cannot be satisfied with an intangible something, which remains at that level. Anything that we take seriously must be embodied in some way, through some manner of institutionalisation, just as our love for our country must be given tangible expression in flag-hoisting and march pasts and our love for our family and friends has to be rendered incarnate in birthday parties and family gatherings. Anything less would but touch us lightly and leave us with a profound sense of frustration. Second, if religion is to have some social significance, if it is to have some transformative, reformative impact upon society—inspiring people to work for justice and peace, or in support of the environment—it requires some kind of communitarian expression. Finally, if it is Reading Comprehension – Basic Levelnot to become a fleeting, fly-by-night sort of thing, here today, and gone tomorrow, coming to birth and dying with each individual’s alleged encounter with the powers that be, it must have some concrete form to ensure the sharing, preservation and development of its tradition. Actually, if we look a bit more closely at the objections against organised religion, it would probably become clear that these objections are not so much aimed at the very fact that religions are organised but at the rigid authoritarian way in which they have been organised. That is the real villain.",
    "ImageID": "",
    "question": "Which out of the following is best suited to be the heading of the passage?",
    "options": {
      "a": "Organised religion: A bane to society.",
      "b": "Religious Intolerance: The obstruc tion to utopia.",
      "c": "A brief history of idolatry, fanaticism, and superstition.",
      "d": "The pros and cons of organised religion."
    },
    "answer": "d",
    "explanation": "The heading of the passage must be an option that summarises the entire pas sage and highlights the key points. Point of reference: First paragraph, the f irst line of every other paragraph, and the last four lines of the passage. Options A, B, and C are incorrect assump tions for the heading of the passage. The adverse implications of Organised Religion on society, the hurdles for a Utopian society in the form of religious intolerance, and idolatry’s history are only touching one side of the discussion, which was discussed in the passage. It does not highlight the sigh of relief that the writer observed with organised reli gion’s inevitable nature. Option D is the accurate heading.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 94,
    "passage": " Read the passage carefully and answer the questions that follow. The scope of philosophy is any critical appraisal of religion. It is an ancient discipline, being found in the earliest known manuscripts concerning philosophy, and relates to many other branches of philosophy and general thought, including Metaphysics, Epistemology, Logic, and History. Let us begin by admitting the fact that, historically, no organised religion can stand up to honest criticism and come’ out of it with an unblemished report card. None of the mainline religions has proved itself to have always been and everywhere a reliable friend of ‘people struggling for liberation and emancipation. Often religions have added to the oppression, discrimination, and blood-letting that have plagued the world since time began. The subjugation of women has often been given religious sanction. The most cruel and bloodthirsty wars have been inspired by religious differences, with each side proclaiming an exclusive ‘Gott mit uns’ (God with us), while hailing all opponents as hirelings of Satan incarnate. Religion has often opposed scientific research and sided with obscurantism and superstition against trends of enlightenment. And politicians, especially in Third World countries, have learned that religion is the easiest handle with which to manipulate impoverished and oppressed masses, stirring up all kinds of mob violence and building up their ‘vote banks’. Indeed, religious leadership seems to be the last bastion of male exclusivism, determined to hold out against ‘female: incursions’ by all manner of pseudo-theological, philosophical, and sociological arguments to preserve power in the hands of men only. The priestly Conquerors’ Club is a very powerful and jealously guarded coterie of old men who, with bulldog tenacity, clings with alarm to its ever-shrinking list of ‘privileges and prerogatives’. Above all, it stands ready to flash its magic wand of ‘God’s will’ and ‘the divinely established scheme of things’ to justify and protect the status quo (heavily loaded in its favour) and block any attempt at reform which just might among other things, help towards a more authentic encounter with God. On the other hand (there always is the other hand, isn’t it?), religions have also inspired many to selfless service to the downtrodden, have given humans a rich legacy of art and beauty as well as played a not insignificant role in opening our eyes to the essential dignity of the human person, irrespective of race, colour, or sex. Some religious personalities—Mother Teresa, Dorothy Day, Mahatma Gandhi, Oscar Romero, Desmond Tutu—have been true friends to liberation movements. Yet, when all is said and done, it would appear that some kind of institutionalisation or organisation of religion is inevitable—unless we are quite prepared to accept the consequences of reducing it to some sort of private, abstract, and ‘spiritual’ preoccupation. In fact, we can cite at least three major reasons why some kind of organisation in religion is not merely to be tolerated as unavoidable, but even accepted as inevitable. First, in as much as we are embodied beings, we cannot be satisfied with an intangible something, which remains at that level. Anything that we take seriously must be embodied in some way, through some manner of institutionalisation, just as our love for our country must be given tangible expression in flag-hoisting and march pasts and our love for our family and friends has to be rendered incarnate in birthday parties and family gatherings. Anything less would but touch us lightly and leave us with a profound sense of frustration. Second, if religion is to have some social significance, if it is to have some transformative, reformative impact upon society—inspiring people to work for justice and peace, or in support of the environment—it requires some kind of communitarian expression. Finally, if it is Reading Comprehension – Basic Levelnot to become a fleeting, fly-by-night sort of thing, here today, and gone tomorrow, coming to birth and dying with each individual’s alleged encounter with the powers that be, it must have some concrete form to ensure the sharing, preservation and development of its tradition. Actually, if we look a bit more closely at the objections against organised religion, it would probably become clear that these objections are not so much aimed at the very fact that religions are organised but at the rigid authoritarian way in which they have been organised. That is the real villain.",
    "ImageID": "",
    "question": "The scientific revolution started by Copernicus and Galileo in support of the heliocentric theory was heavily criticised by the Catholic Church. Which paragraph discusses this level of blasphemy being against a progressive society?",
    "options": {
      "a": "Paragraph 1",
      "b": "Paragraph 2",
      "c": "Paragraph 3",
      "d": "Paragraph 4"
    },
    "answer": "b",
    "explanation": "Point of reference: Second paragraph, f irst line. Religion has often opposed scientific re search and sided with obscurantism and su perstition against trends of enlightenment. Options A, C, and D should be discarded. The introduction to organised religion in the opening of the passage, the inevitable nature of organised religion, and the en tire story’s true villain are the highlights of the first, third, and fourth paragraphs.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 95,
    "passage": " Read the passage carefully and answer the questions that follow. The scope of philosophy is any critical appraisal of religion. It is an ancient discipline, being found in the earliest known manuscripts concerning philosophy, and relates to many other branches of philosophy and general thought, including Metaphysics, Epistemology, Logic, and History. Let us begin by admitting the fact that, historically, no organised religion can stand up to honest criticism and come’ out of it with an unblemished report card. None of the mainline religions has proved itself to have always been and everywhere a reliable friend of ‘people struggling for liberation and emancipation. Often religions have added to the oppression, discrimination, and blood-letting that have plagued the world since time began. The subjugation of women has often been given religious sanction. The most cruel and bloodthirsty wars have been inspired by religious differences, with each side proclaiming an exclusive ‘Gott mit uns’ (God with us), while hailing all opponents as hirelings of Satan incarnate. Religion has often opposed scientific research and sided with obscurantism and superstition against trends of enlightenment. And politicians, especially in Third World countries, have learned that religion is the easiest handle with which to manipulate impoverished and oppressed masses, stirring up all kinds of mob violence and building up their ‘vote banks’. Indeed, religious leadership seems to be the last bastion of male exclusivism, determined to hold out against ‘female: incursions’ by all manner of pseudo-theological, philosophical, and sociological arguments to preserve power in the hands of men only. The priestly Conquerors’ Club is a very powerful and jealously guarded coterie of old men who, with bulldog tenacity, clings with alarm to its ever-shrinking list of ‘privileges and prerogatives’. Above all, it stands ready to flash its magic wand of ‘God’s will’ and ‘the divinely established scheme of things’ to justify and protect the status quo (heavily loaded in its favour) and block any attempt at reform which just might among other things, help towards a more authentic encounter with God. On the other hand (there always is the other hand, isn’t it?), religions have also inspired many to selfless service to the downtrodden, have given humans a rich legacy of art and beauty as well as played a not insignificant role in opening our eyes to the essential dignity of the human person, irrespective of race, colour, or sex. Some religious personalities—Mother Teresa, Dorothy Day, Mahatma Gandhi, Oscar Romero, Desmond Tutu—have been true friends to liberation movements. Yet, when all is said and done, it would appear that some kind of institutionalisation or organisation of religion is inevitable—unless we are quite prepared to accept the consequences of reducing it to some sort of private, abstract, and ‘spiritual’ preoccupation. In fact, we can cite at least three major reasons why some kind of organisation in religion is not merely to be tolerated as unavoidable, but even accepted as inevitable. First, in as much as we are embodied beings, we cannot be satisfied with an intangible something, which remains at that level. Anything that we take seriously must be embodied in some way, through some manner of institutionalisation, just as our love for our country must be given tangible expression in flag-hoisting and march pasts and our love for our family and friends has to be rendered incarnate in birthday parties and family gatherings. Anything less would but touch us lightly and leave us with a profound sense of frustration. Second, if religion is to have some social significance, if it is to have some transformative, reformative impact upon society—inspiring people to work for justice and peace, or in support of the environment—it requires some kind of communitarian expression. Finally, if it is Reading Comprehension – Basic Levelnot to become a fleeting, fly-by-night sort of thing, here today, and gone tomorrow, coming to birth and dying with each individual’s alleged encounter with the powers that be, it must have some concrete form to ensure the sharing, preservation and development of its tradition. Actually, if we look a bit more closely at the objections against organised religion, it would probably become clear that these objections are not so much aimed at the very fact that religions are organised but at the rigid authoritarian way in which they have been organised. That is the real villain.",
    "ImageID": "",
    "question": "What does the author conclude about organised religion?",
    "options": {
      "a": "There is nothing wrong with organ ised religion. It is the penetration of extremism that has made organised religion harmful.",
      "b": "The organisation of world religions is not only possible; it is inevitable.",
      "c": "Organised religion is supported by pillars such as holidays, communal feasts, and the harmonious singing in choirs, which philosophy lacks.",
      "d": "Art and culture will outlive and re place scripture."
    },
    "answer": "a",
    "explanation": "The author concluded that it is not the or ganisation of religions that is the main cul prit; rather, it is religious bigotry that can be blamed. Point of reference: Final line, fourth paragraph.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 96,
    "passage": "  Karl Marx (1818–1883) was a revolutionary thinker who influenced the struggles of the oppressed of the world. His philosophy coherently formulates modern materialism. The Contributions to Critique of Hegel’s Philosophy of Right (1844) Economic and Philosophic Manuscripts (1844) German Ideology, Communist Manifesto (1848), and Capital (1867) are some of the important writings of Marx. Marx claims his philosophy is scientific, naturalistic, realistic, and opposed to all utopian ideals. He is equally critical of religious philosophies, anarchism, idealism, and positivism. The influence of the enlightenment is evident in Marx’s view of religion. As an atheist, he opposed the arguments that are in support of the existence of God. According to Marx, the world is not governed by the divine spirit and was not created out of anything. The only reality is matter and motion; therefore, there is no beyond, and heaven and hell are merely products of human imagination. In the realm of philosophy, Marx is critical of all forms of idealism. In Marx’s view, the idealists who regard nature as a symbol of the divine and speak about teleology are prescientific and merely guided by superstition. Idealism becomes the opiate of the educated, for it substitutes a subjective notion for objective truth. He has also kept his distance from positivism, although he appreciated its scientific foundation. He attacked positivism on the ground that it ends in scientific scepticism, underestimates the influence of society, and reduces knowledge to a mere convenient set of descriptions. While positivism is interested in describing the laws of nature, he said dialectical materialism is concerned with changing and reinterpreting the process of nature. Marx developed his philosophy on Dialectical Materialism. Dialectic is a theory of all reality, and it depends on contradictions being everywhere. For Marx, dialectic is a key to understanding human history. Marx pointed out that man makes religion; religion does not make a man. Consequently, religion is a social product and cannot be treated as an individual phenomenon. Marx believed that the function of philosophy is to criticise society. He considers that social institutions be studied instead of the ideals of supernaturalism and let politics replace theology. Marx viewed philosophy as the persuasion of change. As he says, ‘Philosophers until now, have only interpreted the world, in various ways. The point, however, is to change it’. Marx is critical of doing philosophy in an idealistic and religious way. According to Marx, ‘consciousness doesn’t determine life, but life determines consciousness’.  Dialectical materialism emphasises the importance of change and accuses idealism of a static view of life. It considers substance as material and in a constant state of change. Marx’s basic thought in his philosophy of history is that in every epoch, the prevailing system of production is fundamental. For Marx, the mode of production of material life conditions the social, political, and intellectual life process in general. Marx explained everything from a view of economic determinism. The economic structure is a base, and the politics, culture, law, religion, and ideology are viewed as superstructure. Marx believed that at a certain stage of their development, the material forces of society came into conflict with the existing relations of production. Then begins a social revolution. Marx considers men are makers of history. According to him, the history of all hitherto existing societies is the history of class struggles. His philosophy aims at bringing a classless society through revolution.",
    "ImageID": "",
    "question": "What is the ultimate purpose of Marx’s Dialectical Materialism?",
    "options": {
      "a": "To form a society where everyone gives as per their ability and takes as per their need. ",
      "b": "To drive home the point that religion doesn’t make man; rather, it is man who makes religion.",
      "c": "To remove the dire effects of positiv ism including the checks placed on knowledge.",
      "d": "To overthrow the oppression of the ruling class and usher in a new soci ety through revolution."
    },
    "answer": "d",
    "explanation": "Marx’s dialectical materialism was to op pose the previous views of idealism and ideas derived from supernatural origins. The ultimate purpose of bringing reform in the working conditions and Capitalism, in general, was to make way for a new society. Point of reference: Final line, sixth paragraph. ‘His philosophy aims at bringing class less society through revolution’. Options A, B, and C are invalid purpos es of Dialectical Materialism. They are the secondary highlights of the passage. They do not address the true purpose of Marx’s philosophy. Option D is the ultimate purpose. The ushering in of a new society, where there is no oppression and exploitation of the working class by the ruling class, is the true intent and purpose of Marx’s philos ophy or dialectical materialism.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 97,
    "passage": "  Karl Marx (1818–1883) was a revolutionary thinker who influenced the struggles of the oppressed of the world. His philosophy coherently formulates modern materialism. The Contributions to Critique of Hegel’s Philosophy of Right (1844) Economic and Philosophic Manuscripts (1844) German Ideology, Communist Manifesto (1848), and Capital (1867) are some of the important writings of Marx. Marx claims his philosophy is scientific, naturalistic, realistic, and opposed to all utopian ideals. He is equally critical of religious philosophies, anarchism, idealism, and positivism. The influence of the enlightenment is evident in Marx’s view of religion. As an atheist, he opposed the arguments that are in support of the existence of God. According to Marx, the world is not governed by the divine spirit and was not created out of anything. The only reality is matter and motion; therefore, there is no beyond, and heaven and hell are merely products of human imagination. In the realm of philosophy, Marx is critical of all forms of idealism. In Marx’s view, the idealists who regard nature as a symbol of the divine and speak about teleology are prescientific and merely guided by superstition. Idealism becomes the opiate of the educated, for it substitutes a subjective notion for objective truth. He has also kept his distance from positivism, although he appreciated its scientific foundation. He attacked positivism on the ground that it ends in scientific scepticism, underestimates the influence of society, and reduces knowledge to a mere convenient set of descriptions. While positivism is interested in describing the laws of nature, he said dialectical materialism is concerned with changing and reinterpreting the process of nature. Marx developed his philosophy on Dialectical Materialism. Dialectic is a theory of all reality, and it depends on contradictions being everywhere. For Marx, dialectic is a key to understanding human history. Marx pointed out that man makes religion; religion does not make a man. Consequently, religion is a social product and cannot be treated as an individual phenomenon. Marx believed that the function of philosophy is to criticise society. He considers that social institutions be studied instead of the ideals of supernaturalism and let politics replace theology. Marx viewed philosophy as the persuasion of change. As he says, ‘Philosophers until now, have only interpreted the world, in various ways. The point, however, is to change it’. Marx is critical of doing philosophy in an idealistic and religious way. According to Marx, ‘consciousness doesn’t determine life, but life determines consciousness’.  Dialectical materialism emphasises the importance of change and accuses idealism of a static view of life. It considers substance as material and in a constant state of change. Marx’s basic thought in his philosophy of history is that in every epoch, the prevailing system of production is fundamental. For Marx, the mode of production of material life conditions the social, political, and intellectual life process in general. Marx explained everything from a view of economic determinism. The economic structure is a base, and the politics, culture, law, religion, and ideology are viewed as superstructure. Marx believed that at a certain stage of their development, the material forces of society came into conflict with the existing relations of production. Then begins a social revolution. Marx considers men are makers of history. According to him, the history of all hitherto existing societies is the history of class struggles. His philosophy aims at bringing a classless society through revolution.",
    "ImageID": "",
    "question": "Why is the influence of enlightenment evident in Marx’s views of religion?",
    "options": {
      "a": "His philosophy was scientific, natu ralistic, and realistic.",
      "b": "Reality, as per Marx, consists of mat ter and motion. These two only gov ern the world.",
      "c": "He was an atheist who had decided to reject the idea of Heaven and Hell. Such a move towards atheism was popular at that time.",
      "d": "His rejection of ideas such as world spirit or divine spirit, which Hegel had conceptualised, was obvious."
    },
    "answer": "c",
    "explanation": "Marx did not believe in the existence of a God, nor in the ideas of direct or indi rect divine intervention. In other words, he was an atheist. This radical and ro bust thinking presented by him makes evident the effect of enlightenment on Marx’s view of religion. Point of reference: Third line, second paragraph. ‘The influence of the enlightenment is evident in Marx’s view of religion. As an atheist, he opposed the arguments that are in support of the existence of God.’ Options A, B, and D are incorrect reasons to state the influence of the enlighten ment on Marx’s religious views. His phi losophy being realistic, the governance of the world through matter and its mo tion, and the rejection of ideas such as ‘world spirit’ do not make the influence of enlightenment evident on Marx’s view of religion.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 98,
    "passage": "  Karl Marx (1818–1883) was a revolutionary thinker who influenced the struggles of the oppressed of the world. His philosophy coherently formulates modern materialism. The Contributions to Critique of Hegel’s Philosophy of Right (1844) Economic and Philosophic Manuscripts (1844) German Ideology, Communist Manifesto (1848), and Capital (1867) are some of the important writings of Marx. Marx claims his philosophy is scientific, naturalistic, realistic, and opposed to all utopian ideals. He is equally critical of religious philosophies, anarchism, idealism, and positivism. The influence of the enlightenment is evident in Marx’s view of religion. As an atheist, he opposed the arguments that are in support of the existence of God. According to Marx, the world is not governed by the divine spirit and was not created out of anything. The only reality is matter and motion; therefore, there is no beyond, and heaven and hell are merely products of human imagination. In the realm of philosophy, Marx is critical of all forms of idealism. In Marx’s view, the idealists who regard nature as a symbol of the divine and speak about teleology are prescientific and merely guided by superstition. Idealism becomes the opiate of the educated, for it substitutes a subjective notion for objective truth. He has also kept his distance from positivism, although he appreciated its scientific foundation. He attacked positivism on the ground that it ends in scientific scepticism, underestimates the influence of society, and reduces knowledge to a mere convenient set of descriptions. While positivism is interested in describing the laws of nature, he said dialectical materialism is concerned with changing and reinterpreting the process of nature. Marx developed his philosophy on Dialectical Materialism. Dialectic is a theory of all reality, and it depends on contradictions being everywhere. For Marx, dialectic is a key to understanding human history. Marx pointed out that man makes religion; religion does not make a man. Consequently, religion is a social product and cannot be treated as an individual phenomenon. Marx believed that the function of philosophy is to criticise society. He considers that social institutions be studied instead of the ideals of supernaturalism and let politics replace theology. Marx viewed philosophy as the persuasion of change. As he says, ‘Philosophers until now, have only interpreted the world, in various ways. The point, however, is to change it’. Marx is critical of doing philosophy in an idealistic and religious way. According to Marx, ‘consciousness doesn’t determine life, but life determines consciousness’.  Dialectical materialism emphasises the importance of change and accuses idealism of a static view of life. It considers substance as material and in a constant state of change. Marx’s basic thought in his philosophy of history is that in every epoch, the prevailing system of production is fundamental. For Marx, the mode of production of material life conditions the social, political, and intellectual life process in general. Marx explained everything from a view of economic determinism. The economic structure is a base, and the politics, culture, law, religion, and ideology are viewed as superstructure. Marx believed that at a certain stage of their development, the material forces of society came into conflict with the existing relations of production. Then begins a social revolution. Marx considers men are makers of history. According to him, the history of all hitherto existing societies is the history of class struggles. His philosophy aims at bringing a classless society through revolution.",
    "ImageID": "",
    "question": "What, according to Marx, could bring a change in the world and our relationship with material goods?",
    "options": {
      "a": "Dialectical materialism",
      "b": "Philosophy",
      "c": "Political theory",
      "d": "Literature and art"
    },
    "answer": "b",
    "explanation": "The process of bringing change in the world, as per Marx, is the task of philoso phy and philosophers alike. This is made even more evident by Marx’s quote in the f ifth paragraph. Point of reference: Second line, fifth paragraph. ‘Philosophers until now have only inter preted the world in various ways. The point, however, is to change it’. Options A, C, and D are invalid answers. Dialectical materialism, political theory, literature, and art are not directly re sponsible for bringing change in society and the world in general.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 99,
    "passage": "  Karl Marx (1818–1883) was a revolutionary thinker who influenced the struggles of the oppressed of the world. His philosophy coherently formulates modern materialism. The Contributions to Critique of Hegel’s Philosophy of Right (1844) Economic and Philosophic Manuscripts (1844) German Ideology, Communist Manifesto (1848), and Capital (1867) are some of the important writings of Marx. Marx claims his philosophy is scientific, naturalistic, realistic, and opposed to all utopian ideals. He is equally critical of religious philosophies, anarchism, idealism, and positivism. The influence of the enlightenment is evident in Marx’s view of religion. As an atheist, he opposed the arguments that are in support of the existence of God. According to Marx, the world is not governed by the divine spirit and was not created out of anything. The only reality is matter and motion; therefore, there is no beyond, and heaven and hell are merely products of human imagination. In the realm of philosophy, Marx is critical of all forms of idealism. In Marx’s view, the idealists who regard nature as a symbol of the divine and speak about teleology are prescientific and merely guided by superstition. Idealism becomes the opiate of the educated, for it substitutes a subjective notion for objective truth. He has also kept his distance from positivism, although he appreciated its scientific foundation. He attacked positivism on the ground that it ends in scientific scepticism, underestimates the influence of society, and reduces knowledge to a mere convenient set of descriptions. While positivism is interested in describing the laws of nature, he said dialectical materialism is concerned with changing and reinterpreting the process of nature. Marx developed his philosophy on Dialectical Materialism. Dialectic is a theory of all reality, and it depends on contradictions being everywhere. For Marx, dialectic is a key to understanding human history. Marx pointed out that man makes religion; religion does not make a man. Consequently, religion is a social product and cannot be treated as an individual phenomenon. Marx believed that the function of philosophy is to criticise society. He considers that social institutions be studied instead of the ideals of supernaturalism and let politics replace theology. Marx viewed philosophy as the persuasion of change. As he says, ‘Philosophers until now, have only interpreted the world, in various ways. The point, however, is to change it’. Marx is critical of doing philosophy in an idealistic and religious way. According to Marx, ‘consciousness doesn’t determine life, but life determines consciousness’.  Dialectical materialism emphasises the importance of change and accuses idealism of a static view of life. It considers substance as material and in a constant state of change. Marx’s basic thought in his philosophy of history is that in every epoch, the prevailing system of production is fundamental. For Marx, the mode of production of material life conditions the social, political, and intellectual life process in general. Marx explained everything from a view of economic determinism. The economic structure is a base, and the politics, culture, law, religion, and ideology are viewed as superstructure. Marx believed that at a certain stage of their development, the material forces of society came into conflict with the existing relations of production. Then begins a social revolution. Marx considers men are makers of history. According to him, the history of all hitherto existing societies is the history of class struggles. His philosophy aims at bringing a classless society through revolution.",
    "ImageID": "",
    "question": "Why did Marx’s works (Das Kapital and Communist Manifesto) emphasise a lot on the means of production and distri bution in our society?",
    "options": {
      "a": "The means of production are better off in the hands of the public in place of private ownership that only per petuates human agony.",
      "b": "Conflict arising from our relation to ma terial goods will bring history to an end.",
      "c": "The abolition of private property would usher in a new society where the art, philosophy, and culture of the society will no longer be in conflict.",
      "d": "In the beginning, mankind was only concerned with production; but due to economics, human beings got alienat ed from this very joy of production."
    },
    "answer": "b",
    "explanation": "Marx’s works placed importance on the means of production and distribution as they are vital in governing the life con ditions, the social environment, and po litical and overall intellectual processes of human beings in general. This relation with material goods is bound to come into conflict, which leads to social revo lution and the progress of ideas. Point of reference: Final paragraph, fifth line. ‘Marx believed that at a certain stage of their development, material forces of so ciety came into conflict with the existing relations of production. Then begins the social revolution. Marx considers men are makers of history. According to him, the history of all hitherto existing socie ties is the history of class struggles’.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 100,
    "passage": "  Karl Marx (1818–1883) was a revolutionary thinker who influenced the struggles of the oppressed of the world. His philosophy coherently formulates modern materialism. The Contributions to Critique of Hegel’s Philosophy of Right (1844) Economic and Philosophic Manuscripts (1844) German Ideology, Communist Manifesto (1848), and Capital (1867) are some of the important writings of Marx. Marx claims his philosophy is scientific, naturalistic, realistic, and opposed to all utopian ideals. He is equally critical of religious philosophies, anarchism, idealism, and positivism. The influence of the enlightenment is evident in Marx’s view of religion. As an atheist, he opposed the arguments that are in support of the existence of God. According to Marx, the world is not governed by the divine spirit and was not created out of anything. The only reality is matter and motion; therefore, there is no beyond, and heaven and hell are merely products of human imagination. In the realm of philosophy, Marx is critical of all forms of idealism. In Marx’s view, the idealists who regard nature as a symbol of the divine and speak about teleology are prescientific and merely guided by superstition. Idealism becomes the opiate of the educated, for it substitutes a subjective notion for objective truth. He has also kept his distance from positivism, although he appreciated its scientific foundation. He attacked positivism on the ground that it ends in scientific scepticism, underestimates the influence of society, and reduces knowledge to a mere convenient set of descriptions. While positivism is interested in describing the laws of nature, he said dialectical materialism is concerned with changing and reinterpreting the process of nature. Marx developed his philosophy on Dialectical Materialism. Dialectic is a theory of all reality, and it depends on contradictions being everywhere. For Marx, dialectic is a key to understanding human history. Marx pointed out that man makes religion; religion does not make a man. Consequently, religion is a social product and cannot be treated as an individual phenomenon. Marx believed that the function of philosophy is to criticise society. He considers that social institutions be studied instead of the ideals of supernaturalism and let politics replace theology. Marx viewed philosophy as the persuasion of change. As he says, ‘Philosophers until now, have only interpreted the world, in various ways. The point, however, is to change it’. Marx is critical of doing philosophy in an idealistic and religious way. According to Marx, ‘consciousness doesn’t determine life, but life determines consciousness’.  Dialectical materialism emphasises the importance of change and accuses idealism of a static view of life. It considers substance as material and in a constant state of change. Marx’s basic thought in his philosophy of history is that in every epoch, the prevailing system of production is fundamental. For Marx, the mode of production of material life conditions the social, political, and intellectual life process in general. Marx explained everything from a view of economic determinism. The economic structure is a base, and the politics, culture, law, religion, and ideology are viewed as superstructure. Marx believed that at a certain stage of their development, the material forces of society came into conflict with the existing relations of production. Then begins a social revolution. Marx considers men are makers of history. According to him, the history of all hitherto existing societies is the history of class struggles. His philosophy aims at bringing a classless society through revolution.",
    "ImageID": "",
    "question": "What is the main theme of the passagse?",
    "options": {
      "a": "Why Marxism is one of the most powerful ideologies in the world.",
      "b": "A brief overview of Capitalism’s most famous and ambitious critic.",
      "c": "Economic systems need to be re formed somehow, and Marx’s anal yses are going to be a part of that answer.",
      "d": "Marx’s diagnosis of Capitalism’s ills can navigate us towards a better and promising future."
    },
    "answer": "b",
    "explanation": "The main theme of the passage is the idea/theme which finds a mention and resonance with the entire passage. Point of reference: The entire passage We can get the main idea by reading the first paragraph. It talks about Marx’s critiques.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 101,
    "passage": " The western theories of evil are mainly explained by Christianity. Indian perspectives on the problem of evil are different from the west. The dominant conception of India is derived from Hinduism. The scholars try to explain it differently from the Semitic religious traditions. Does evil belong to the divine, or is it a purely human or psychological phenomenon? It is argued that evil is a major theological problem in the Semitic religious traditions as the existence of God and evil are not compatible and reconcilable. It is also argued that understanding the problem of evil depends upon one’s worldview. The theistic worldview of evil would be significantly different from that of that world view is non-theistic. As Ramamurty argues in his book Indian Philosophy of Religion: In Hinduism, the explanation of evil is more metaphysical than theological as there is no doctrine of creation in Hinduism. Since God is not the creator of the world, he is in no way connected with the explanation of evil. The problem of evil is delinked with the existence of God. Evil is viewed and explained basically in terms of man and his spiritual growth. It is more or less a value or a meaning that man attaches to certain things and experiences. The objective world or the world of facts is neither good nor bad. It acquires the value of good or bad from the point of view of the man who judges things in terms of their value and significance to himself. What is good or what is evil depends ultimately upon the culture and religion to which man belongs. Further, it is viewed that Indian philosophers of religion are pragmatic in their attitude and approach to religion and its problems. Their analysis and understanding of evil’s problem are also basically pragmatic as their object in understanding the problem of evil is to help man in overcoming it. A purely theoretical understanding of evil’s problem may not be possible as it is  not amenable to man’s rational understanding. At the same time, the problem is highly significant to man and his religious life of attaining perfection. A significant explanation of evil that characterises Indian understanding of evil and is common to several thinkers and schools of thought is that though man is the supreme or best form of manifestation of the divine, he is somehow unaware of his divine origin and nature. Instead, he thinks of himself as having an independent existence, and therefore lives for himself and conducts himself as if he is his own master and explanation. It is often claimed that the doctrine of Karma and rebirth provides Indian religion with a satisfying account of evil and suffering than do typical Western solutions to evil. In his work The Problem of Evil and Indian Thought, Arthur Herman similarly asserts the superiority of Karma to all Western theodicies: ‘Unlike the Western theories, the doctrine of rebirth is capable of meeting the major objections against which those Western attempts all failed’. The doctrine of Karma and rebirth represents perhaps the most striking difference between Western (Judeo-Christian) religious thought and the Indian religious traditions (mainly Hindu).",
    "ImageID": "",
    "question": "Why can it be inferred that the existence of God and evil are not reconcilable and compatible?",
    "options": {
      "a": "Since there is an absence of the doc trine of creation, the understanding of evil can be subjective.",
      "b": "The complication of evil depends on one’s view of the world.",
      "c": "Since God’s existence is debatable, so is the existence of evil at the same time.",
      "d": "The existence and explanation of evil are independent and thus can only be explained by evil or the evil act itself."
    },
    "answer": "a",
    "explanation": "The answer to this query finds its bear ings in paragraphs 1 and 2. Point of reference: Last line of paragraph 1 and last line of paragraph 2 Options B, C, and D are to be rejected as the answer. The subjective view of evil as per the lifeworld of an individual, as stated in option B, is only a part of why the rec onciliation of evil with God is not possible. The debate on God’s existence and the lack of connection to be made with con cerns to defining what is evil and what is not is an irrelevant assertion made in op tion C since this notion finds no mention in the entire passage. The independent ex istence and explanation of evil may appear as the plausible reason for its non-recon ciliation. However, this alone cannot justify the reason for this non-reconciliation.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 102,
    "passage": " The western theories of evil are mainly explained by Christianity. Indian perspectives on the problem of evil are different from the west. The dominant conception of India is derived from Hinduism. The scholars try to explain it differently from the Semitic religious traditions. Does evil belong to the divine, or is it a purely human or psychological phenomenon? It is argued that evil is a major theological problem in the Semitic religious traditions as the existence of God and evil are not compatible and reconcilable. It is also argued that understanding the problem of evil depends upon one’s worldview. The theistic worldview of evil would be significantly different from that of that world view is non-theistic. As Ramamurty argues in his book Indian Philosophy of Religion: In Hinduism, the explanation of evil is more metaphysical than theological as there is no doctrine of creation in Hinduism. Since God is not the creator of the world, he is in no way connected with the explanation of evil. The problem of evil is delinked with the existence of God. Evil is viewed and explained basically in terms of man and his spiritual growth. It is more or less a value or a meaning that man attaches to certain things and experiences. The objective world or the world of facts is neither good nor bad. It acquires the value of good or bad from the point of view of the man who judges things in terms of their value and significance to himself. What is good or what is evil depends ultimately upon the culture and religion to which man belongs. Further, it is viewed that Indian philosophers of religion are pragmatic in their attitude and approach to religion and its problems. Their analysis and understanding of evil’s problem are also basically pragmatic as their object in understanding the problem of evil is to help man in overcoming it. A purely theoretical understanding of evil’s problem may not be possible as it is  not amenable to man’s rational understanding. At the same time, the problem is highly significant to man and his religious life of attaining perfection. A significant explanation of evil that characterises Indian understanding of evil and is common to several thinkers and schools of thought is that though man is the supreme or best form of manifestation of the divine, he is somehow unaware of his divine origin and nature. Instead, he thinks of himself as having an independent existence, and therefore lives for himself and conducts himself as if he is his own master and explanation. It is often claimed that the doctrine of Karma and rebirth provides Indian religion with a satisfying account of evil and suffering than do typical Western solutions to evil. In his work The Problem of Evil and Indian Thought, Arthur Herman similarly asserts the superiority of Karma to all Western theodicies: ‘Unlike the Western theories, the doctrine of rebirth is capable of meeting the major objections against which those Western attempts all failed’. The doctrine of Karma and rebirth represents perhaps the most striking difference between Western (Judeo-Christian) religious thought and the Indian religious traditions (mainly Hindu).",
    "ImageID": "",
    "question": "What is the purpose of the passage?",
    "options": {
      "a": "To represent the reader with the Judeo-Christian perspective of evil. ",
      "b": "To present a view of evil that is not theological and at the same time in the metaphysical realms of Hindu philosophy.",
      "c": "The difficulties and views in under standing evil away from rationality and more into human beings’ divine origin.",
      "d": "The pragmatic attempt to make the reader understand evil’s very nature and overcome it simultaneously."
    },
    "answer": "b",
    "explanation": "To understand the passage’s purpose, the reader needs to form a basic outline for the passage’s theme. Point of reference: The entire passage Options A, C, and D are incorrect. The representation of the Judeo-Christian perspective of evil is not the only purpose of the passage. The understanding of the divine nature of human origin cannot be stated as the purpose as well. Hindu phi losophy’s attempt to make human beings understand evil’s nature to overcome it may appear as the correct answer at first glance. However, it is more in the line of being the purpose of the third paragraph. Option B is a good purpose. The views of evil apart from theology and into the metaphysi cal confines can help navigate human beings to an elevated perspective and comprehen sion of the divine order and evil in general.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 103,
    "passage": " The western theories of evil are mainly explained by Christianity. Indian perspectives on the problem of evil are different from the west. The dominant conception of India is derived from Hinduism. The scholars try to explain it differently from the Semitic religious traditions. Does evil belong to the divine, or is it a purely human or psychological phenomenon? It is argued that evil is a major theological problem in the Semitic religious traditions as the existence of God and evil are not compatible and reconcilable. It is also argued that understanding the problem of evil depends upon one’s worldview. The theistic worldview of evil would be significantly different from that of that world view is non-theistic. As Ramamurty argues in his book Indian Philosophy of Religion: In Hinduism, the explanation of evil is more metaphysical than theological as there is no doctrine of creation in Hinduism. Since God is not the creator of the world, he is in no way connected with the explanation of evil. The problem of evil is delinked with the existence of God. Evil is viewed and explained basically in terms of man and his spiritual growth. It is more or less a value or a meaning that man attaches to certain things and experiences. The objective world or the world of facts is neither good nor bad. It acquires the value of good or bad from the point of view of the man who judges things in terms of their value and significance to himself. What is good or what is evil depends ultimately upon the culture and religion to which man belongs. Further, it is viewed that Indian philosophers of religion are pragmatic in their attitude and approach to religion and its problems. Their analysis and understanding of evil’s problem are also basically pragmatic as their object in understanding the problem of evil is to help man in overcoming it. A purely theoretical understanding of evil’s problem may not be possible as it is  not amenable to man’s rational understanding. At the same time, the problem is highly significant to man and his religious life of attaining perfection. A significant explanation of evil that characterises Indian understanding of evil and is common to several thinkers and schools of thought is that though man is the supreme or best form of manifestation of the divine, he is somehow unaware of his divine origin and nature. Instead, he thinks of himself as having an independent existence, and therefore lives for himself and conducts himself as if he is his own master and explanation. It is often claimed that the doctrine of Karma and rebirth provides Indian religion with a satisfying account of evil and suffering than do typical Western solutions to evil. In his work The Problem of Evil and Indian Thought, Arthur Herman similarly asserts the superiority of Karma to all Western theodicies: ‘Unlike the Western theories, the doctrine of rebirth is capable of meeting the major objections against which those Western attempts all failed’. The doctrine of Karma and rebirth represents perhaps the most striking difference between Western (Judeo-Christian) religious thought and the Indian religious traditions (mainly Hindu).",
    "ImageID": "",
    "question": "Why do the Indian philosophers take a pragmatic view in discussing evil and considering religion and culture?",
    "options": {
      "a": "To overcome evil, which will be the gift from the philosophers of the Indian subcontinent to the entire world.",
      "b": "To help overcome the subjectivity of evil into a more objective think ing perspective backed by religious claims.",
      "c": "To attain a perfect utopian society where all human beings live happy and in peace.",
      "d": "The definition of evil and good var ies from religion to religion. Hence, the pragmatic approach to forming a universal definition applicable to all will help people in the long run."
    },
    "answer": "b",
    "explanation": "The Indian philosophers took the pragmat ic view, and their actions are discussed in the third paragraph, particularly in the second last line of the paragraph. Point of reference: ‘Their analysis and un derstanding of evil’s problem are also ba sically pragmatic as their object in under standing the problem of evil is to help man overcome it. A purely theoretical under standing of evil’s problem may not be pos sible as it is not amenable to man’s rational understanding. Moreover, at the same time, the problem is highly significant to man and his religious life of attaining perfection’.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 104,
    "passage": " The western theories of evil are mainly explained by Christianity. Indian perspectives on the problem of evil are different from the west. The dominant conception of India is derived from Hinduism. The scholars try to explain it differently from the Semitic religious traditions. Does evil belong to the divine, or is it a purely human or psychological phenomenon? It is argued that evil is a major theological problem in the Semitic religious traditions as the existence of God and evil are not compatible and reconcilable. It is also argued that understanding the problem of evil depends upon one’s worldview. The theistic worldview of evil would be significantly different from that of that world view is non-theistic. As Ramamurty argues in his book Indian Philosophy of Religion: In Hinduism, the explanation of evil is more metaphysical than theological as there is no doctrine of creation in Hinduism. Since God is not the creator of the world, he is in no way connected with the explanation of evil. The problem of evil is delinked with the existence of God. Evil is viewed and explained basically in terms of man and his spiritual growth. It is more or less a value or a meaning that man attaches to certain things and experiences. The objective world or the world of facts is neither good nor bad. It acquires the value of good or bad from the point of view of the man who judges things in terms of their value and significance to himself. What is good or what is evil depends ultimately upon the culture and religion to which man belongs. Further, it is viewed that Indian philosophers of religion are pragmatic in their attitude and approach to religion and its problems. Their analysis and understanding of evil’s problem are also basically pragmatic as their object in understanding the problem of evil is to help man in overcoming it. A purely theoretical understanding of evil’s problem may not be possible as it is  not amenable to man’s rational understanding. At the same time, the problem is highly significant to man and his religious life of attaining perfection. A significant explanation of evil that characterises Indian understanding of evil and is common to several thinkers and schools of thought is that though man is the supreme or best form of manifestation of the divine, he is somehow unaware of his divine origin and nature. Instead, he thinks of himself as having an independent existence, and therefore lives for himself and conducts himself as if he is his own master and explanation. It is often claimed that the doctrine of Karma and rebirth provides Indian religion with a satisfying account of evil and suffering than do typical Western solutions to evil. In his work The Problem of Evil and Indian Thought, Arthur Herman similarly asserts the superiority of Karma to all Western theodicies: ‘Unlike the Western theories, the doctrine of rebirth is capable of meeting the major objections against which those Western attempts all failed’. The doctrine of Karma and rebirth represents perhaps the most striking difference between Western (Judeo-Christian) religious thought and the Indian religious traditions (mainly Hindu).",
    "ImageID": "",
    "question": "The writer would agree with all the fol lowing points, except:",
    "options": {
      "a": "The human population, in general, is ignorant of their divine purpose and origination.",
      "b": "The association and connection be tween God and evil are non-inter dependent. Hence, forming an inter connection between the two is not feasible.",
      "c": "The philosophers of the Indian sub continent have taken a sensible and down-to-earth approach to resolving evil in society.",
      "d": "The confines of the world religions do not have a valid argument to de f ine the enormous scale of evil in the world. They cannot define human evil such as war or crime and moral evil such as earthquakes and floods."
    },
    "answer": "d",
    "explanation": "Option D is the correct answer. The reli gions of the world have proper arguments to define the enormities of evil in the world. The writer has taken a particular interest in the philosophers of the Hindu religion to support this notion. Hence, this is the notion that the writer will find disputable.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 105,
    "passage": " The western theories of evil are mainly explained by Christianity. Indian perspectives on the problem of evil are different from the west. The dominant conception of India is derived from Hinduism. The scholars try to explain it differently from the Semitic religious traditions. Does evil belong to the divine, or is it a purely human or psychological phenomenon? It is argued that evil is a major theological problem in the Semitic religious traditions as the existence of God and evil are not compatible and reconcilable. It is also argued that understanding the problem of evil depends upon one’s worldview. The theistic worldview of evil would be significantly different from that of that world view is non-theistic. As Ramamurty argues in his book Indian Philosophy of Religion: In Hinduism, the explanation of evil is more metaphysical than theological as there is no doctrine of creation in Hinduism. Since God is not the creator of the world, he is in no way connected with the explanation of evil. The problem of evil is delinked with the existence of God. Evil is viewed and explained basically in terms of man and his spiritual growth. It is more or less a value or a meaning that man attaches to certain things and experiences. The objective world or the world of facts is neither good nor bad. It acquires the value of good or bad from the point of view of the man who judges things in terms of their value and significance to himself. What is good or what is evil depends ultimately upon the culture and religion to which man belongs. Further, it is viewed that Indian philosophers of religion are pragmatic in their attitude and approach to religion and its problems. Their analysis and understanding of evil’s problem are also basically pragmatic as their object in understanding the problem of evil is to help man in overcoming it. A purely theoretical understanding of evil’s problem may not be possible as it is  not amenable to man’s rational understanding. At the same time, the problem is highly significant to man and his religious life of attaining perfection. A significant explanation of evil that characterises Indian understanding of evil and is common to several thinkers and schools of thought is that though man is the supreme or best form of manifestation of the divine, he is somehow unaware of his divine origin and nature. Instead, he thinks of himself as having an independent existence, and therefore lives for himself and conducts himself as if he is his own master and explanation. It is often claimed that the doctrine of Karma and rebirth provides Indian religion with a satisfying account of evil and suffering than do typical Western solutions to evil. In his work The Problem of Evil and Indian Thought, Arthur Herman similarly asserts the superiority of Karma to all Western theodicies: ‘Unlike the Western theories, the doctrine of rebirth is capable of meeting the major objections against which those Western attempts all failed’. The doctrine of Karma and rebirth represents perhaps the most striking difference between Western (Judeo-Christian) religious thought and the Indian religious traditions (mainly Hindu).",
    "ImageID": "",
    "question": "Why does the writer recommend the Indian religious view of life and re birth over the western Judeo-Christian perception?",
    "options": {
      "a": "Presence of notions like Karma and the subsequent rebirth based on how people choose to live rather than on wealth or prestige.",
      "b": "The Hindu religion’s determined pur suit to attain human life’s perfection and human society in general.",
      "c": "The solution behind the difficulty of understanding the divine nature and origin of human beings.",
      "d": "The resolution of assigning evil as being purely divine and not human or psychological."
    },
    "answer": "a",
    "explanation": "The answer to this query can be found in the target region of the final paragraph. Karma is one reason why the writer pre fers the Indian view of evil compared to the Judeo-Christian view. Point of reference: The last paragraph. Options B, C, and D are to be rejected as the answer. The hot pursuit of the Hindu religion, the solutions for understanding the divine order and origin of human be ings, and the resolution of assigning evil as purely divine and not human or psycho logical are not the actual reasons why the writer prefers the Indian religions’ view over the Judeo-Christian perspective. Option A is the correct choice to take. The existence of notions such as Karma and the cycle of death and rebirth based on this Karma is the core reason why the essayist would highly recommend the view of India’s religions and subsequent ly decline the view of Judeo-Christian authority.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 106,
    "passage": "  Etymologically, the word philosophy comes from two Greek words—Philos, lover (or friend), and Sophia, wisdom. Philosophy then is ‘a love of wisdom’, and the philosopher is a friend or a lover of it. Some important conclusions can already be drawn from this fact. Philosophy is not the possession of wisdom; a philosopher is NOT a proud Mr Know-It-All, who has all of the answers to everyone’s questions. He is a quester after truth, profoundly in love with Sophia, pursuing her, but never quite able to comprehend her elusive person. At most, he touches her with his fingertips, but she soon escapes his grasp. I want to see the image of lover and the beloved frequently in this text, and Sophia is a very common girls’ name in many languages. From this, we could emphasise that humanity would be the first necessary qualification of any philosopher worth his/her salt. A philosopher treks a weary, but ever so existing and adventure, way along paths less trod to an ever-receding horizon. The truth is there but is always, tantalizingly, just beyond his/ her reach. A good philosopher leads us, but one step nearer to the truth but is never so smug as to claim that we have ensured Dame Sophia once and for all in the meshes of finite human intelligence. We might even go on to add that philosophy must be a community project. There is only so much that an individual human mind can grasp. Reality is far too rich, far too complex to be stuffed into the slender limits of one individual brain, bet it that of Madame Curie or Professor Einstein. Besides, each of us approaches persons and things from our particular perspective (some have called this the ‘pre-understanding’), which comprises, among other things, our culture, our mother tongue, family upbringing, religious background (even if we think we have rejected it long age). All these, somehow or the other, influence (if not prejudice) our perceptions. It is impossible to take a natural, unbiased view of things: at best, we can try to become progressively more aware of our ‘pre-understating’ and give up a native assumption about objectivity. I am, rather, asking us to be on guard against hasty and presumptions assertions that we have come to plain, unvarnished, and objective visions of reality. Whatever, it should be quite clear that none of us deliberately and willfully admits prejudices into our perceptional make-up. People hold prejudices unconsciously, as a rule: once they become conscious that they have been nourishing prejudices, they give them up (assuming they have the honesty and courage to do so). But how can we become aware of our prejudices? Only by dialoguing with people of other backgrounds (other nations, other cultures, other creeds). If I isolate myself with people who think as I do and never venture to meet people with other worldviews, my gang and I will simply confirm each other in way favourite prejudices and narrow-mindedness.",
    "ImageID": "",
    "question": "What is the writer’s purpose of using the analogy of love in the first paragraph to explain the meaning of philosophy to the reader?",
    "options": {
      "a": "To arouse emotions and pictures in the mind of the reader.",
      "b": "To describe the complex relation of the absolute truth and the quester. It is as elusive as the human relation ships of love can be.",
      "c": "To highlight the difficulty of love re lationships between a man and a woman.",
      "d": "To highlight the feminine nature of the word Sophia, a common girls’ name in most cultures."
    },
    "answer": "b",
    "explanation": "This inquiry’s scope and range are most ly concerned with the vivid picturisation presented in the first paragraph. More specifically, beginning at the fourth line of the first paragraph and ending with the final line of the same. Point of reference: He is a quester after truth, profoundly in love with Sophia, pursuing her, but never quite able to comprehend her elusive person. At most, he touches her with his fingertips, but she soon escapes his grasp. I want to see the image of lover and the beloved frequently in this text, and Sophia, be ing a very common girls’ name in many languages. Options A, C, and D are incomplete al ternatives. The arousal of images and emotions in the reader’s mind, the some times-difficult nature and understanding regarding love between men and women, and the feminine nature of the widely ac cepted girls’ name Sophia are just merely surface implications drawn from the pur pose of using such kind of creative writing. Option B is the right choice to opt for. It highlights the complex relationship between the absolute truth and the quester, and simultaneously through the application of a common example, de scribes the complexity of such a relation beautifully.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 107,
    "passage": "  Etymologically, the word philosophy comes from two Greek words—Philos, lover (or friend), and Sophia, wisdom. Philosophy then is ‘a love of wisdom’, and the philosopher is a friend or a lover of it. Some important conclusions can already be drawn from this fact. Philosophy is not the possession of wisdom; a philosopher is NOT a proud Mr Know-It-All, who has all of the answers to everyone’s questions. He is a quester after truth, profoundly in love with Sophia, pursuing her, but never quite able to comprehend her elusive person. At most, he touches her with his fingertips, but she soon escapes his grasp. I want to see the image of lover and the beloved frequently in this text, and Sophia is a very common girls’ name in many languages. From this, we could emphasise that humanity would be the first necessary qualification of any philosopher worth his/her salt. A philosopher treks a weary, but ever so existing and adventure, way along paths less trod to an ever-receding horizon. The truth is there but is always, tantalizingly, just beyond his/ her reach. A good philosopher leads us, but one step nearer to the truth but is never so smug as to claim that we have ensured Dame Sophia once and for all in the meshes of finite human intelligence. We might even go on to add that philosophy must be a community project. There is only so much that an individual human mind can grasp. Reality is far too rich, far too complex to be stuffed into the slender limits of one individual brain, bet it that of Madame Curie or Professor Einstein. Besides, each of us approaches persons and things from our particular perspective (some have called this the ‘pre-understanding’), which comprises, among other things, our culture, our mother tongue, family upbringing, religious background (even if we think we have rejected it long age). All these, somehow or the other, influence (if not prejudice) our perceptions. It is impossible to take a natural, unbiased view of things: at best, we can try to become progressively more aware of our ‘pre-understating’ and give up a native assumption about objectivity. I am, rather, asking us to be on guard against hasty and presumptions assertions that we have come to plain, unvarnished, and objective visions of reality. Whatever, it should be quite clear that none of us deliberately and willfully admits prejudices into our perceptional make-up. People hold prejudices unconsciously, as a rule: once they become conscious that they have been nourishing prejudices, they give them up (assuming they have the honesty and courage to do so). But how can we become aware of our prejudices? Only by dialoguing with people of other backgrounds (other nations, other cultures, other creeds). If I isolate myself with people who think as I do and never venture to meet people with other worldviews, my gang and I will simply confirm each other in way favourite prejudices and narrow-mindedness.",
    "ImageID": "",
    "question": "Which of the following is an apt heading for the passage?",
    "options": {
      "a": "Philosophy: A true and meaningful community project.",
      "b": "Philosophy: The art of finding truth and the purpose of knowledge. ",
      "c": "Philosophy: A tale of seduction be tween the quester and Sophia.",
      "d": "Philosophy: The art of knowing everything and still proclaiming of knowing nothing."
    },
    "answer": "c",
    "explanation": "The most suited heading of the passage will be the alternative that can touch the passage’s essence and not cover the secondary highlights of the passage. The passage began with a romanticised ex planation of the absolute truth and the quester, and then by the end of it high lights the true purpose and meaning be hind philosophy. Point of reference: The entire passage. Options A, B, and D must be rejected conclusively to arrive at the right answer. The true and meaningful community pro ject, the art of finding the absolute truth, and the beautiful mastery of knowing everything are just covering general defi nitions one might opt for when describ ing philosophy. Option C is the right choice to make. The romanticised version of the quest that the philosopher takes to find the true absolute knowledge or Sophia, as said in Latin, is the theme observed in the pas sage. This personification is also present in the last line of the second paragraph, ‘Secured Dame Sophia once and for all.’",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 108,
    "passage": "  Etymologically, the word philosophy comes from two Greek words—Philos, lover (or friend), and Sophia, wisdom. Philosophy then is ‘a love of wisdom’, and the philosopher is a friend or a lover of it. Some important conclusions can already be drawn from this fact. Philosophy is not the possession of wisdom; a philosopher is NOT a proud Mr Know-It-All, who has all of the answers to everyone’s questions. He is a quester after truth, profoundly in love with Sophia, pursuing her, but never quite able to comprehend her elusive person. At most, he touches her with his fingertips, but she soon escapes his grasp. I want to see the image of lover and the beloved frequently in this text, and Sophia is a very common girls’ name in many languages. From this, we could emphasise that humanity would be the first necessary qualification of any philosopher worth his/her salt. A philosopher treks a weary, but ever so existing and adventure, way along paths less trod to an ever-receding horizon. The truth is there but is always, tantalizingly, just beyond his/ her reach. A good philosopher leads us, but one step nearer to the truth but is never so smug as to claim that we have ensured Dame Sophia once and for all in the meshes of finite human intelligence. We might even go on to add that philosophy must be a community project. There is only so much that an individual human mind can grasp. Reality is far too rich, far too complex to be stuffed into the slender limits of one individual brain, bet it that of Madame Curie or Professor Einstein. Besides, each of us approaches persons and things from our particular perspective (some have called this the ‘pre-understanding’), which comprises, among other things, our culture, our mother tongue, family upbringing, religious background (even if we think we have rejected it long age). All these, somehow or the other, influence (if not prejudice) our perceptions. It is impossible to take a natural, unbiased view of things: at best, we can try to become progressively more aware of our ‘pre-understating’ and give up a native assumption about objectivity. I am, rather, asking us to be on guard against hasty and presumptions assertions that we have come to plain, unvarnished, and objective visions of reality. Whatever, it should be quite clear that none of us deliberately and willfully admits prejudices into our perceptional make-up. People hold prejudices unconsciously, as a rule: once they become conscious that they have been nourishing prejudices, they give them up (assuming they have the honesty and courage to do so). But how can we become aware of our prejudices? Only by dialoguing with people of other backgrounds (other nations, other cultures, other creeds). If I isolate myself with people who think as I do and never venture to meet people with other worldviews, my gang and I will simply confirm each other in way favourite prejudices and narrow-mindedness.",
    "ImageID": "",
    "question": "What kind of image does the writer have for the philosophers?",
    "options": {
      "a": "Hopeless and madly in love with the idea of an abstract figure, who goes by the name of Sophia.",
      "b": "A warm and restoring take on the philosophers’ overall image, which humanises their many positive traits.",
      "c": "As a person who can show the path but does not lead the traveller to their true destination.",
      "d": "The people who are very much against the ‘Doxa’ and examine pub lic opinions carefully before jumping to a conclusion."
    },
    "answer": "b",
    "explanation": "The philosophers’ overall image present ed in this passage is a warm and human ised perspective on philosophers’ pursuit of knowledge. The inference of this can be drawn from the third line of the first paragraph and the second paragraph’s f irst line. Point of reference: Third line, first paragraph Philosophy is not the possession of wis dom; a philosopher is NOT a proud Mr Know-It-All, who has the answers to everyone’s question First line, second paragraph. From this, we could emphasise that humanity would be the first necessary qualification of any philosopher worth his/her salt. Options A, C, and D are inaccurate por trayals of philosophers. The hopeless lovers in pursuit of Sophia, the guides who show the path but do not accompa ny the individual to their destination, and the very sceptic people against ‘Doxa’ are more in line with surface inferenc es a person can draw from reading the passage.  175",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 109,
    "passage": "  Etymologically, the word philosophy comes from two Greek words—Philos, lover (or friend), and Sophia, wisdom. Philosophy then is ‘a love of wisdom’, and the philosopher is a friend or a lover of it. Some important conclusions can already be drawn from this fact. Philosophy is not the possession of wisdom; a philosopher is NOT a proud Mr Know-It-All, who has all of the answers to everyone’s questions. He is a quester after truth, profoundly in love with Sophia, pursuing her, but never quite able to comprehend her elusive person. At most, he touches her with his fingertips, but she soon escapes his grasp. I want to see the image of lover and the beloved frequently in this text, and Sophia is a very common girls’ name in many languages. From this, we could emphasise that humanity would be the first necessary qualification of any philosopher worth his/her salt. A philosopher treks a weary, but ever so existing and adventure, way along paths less trod to an ever-receding horizon. The truth is there but is always, tantalizingly, just beyond his/ her reach. A good philosopher leads us, but one step nearer to the truth but is never so smug as to claim that we have ensured Dame Sophia once and for all in the meshes of finite human intelligence. We might even go on to add that philosophy must be a community project. There is only so much that an individual human mind can grasp. Reality is far too rich, far too complex to be stuffed into the slender limits of one individual brain, bet it that of Madame Curie or Professor Einstein. Besides, each of us approaches persons and things from our particular perspective (some have called this the ‘pre-understanding’), which comprises, among other things, our culture, our mother tongue, family upbringing, religious background (even if we think we have rejected it long age). All these, somehow or the other, influence (if not prejudice) our perceptions. It is impossible to take a natural, unbiased view of things: at best, we can try to become progressively more aware of our ‘pre-understating’ and give up a native assumption about objectivity. I am, rather, asking us to be on guard against hasty and presumptions assertions that we have come to plain, unvarnished, and objective visions of reality. Whatever, it should be quite clear that none of us deliberately and willfully admits prejudices into our perceptional make-up. People hold prejudices unconsciously, as a rule: once they become conscious that they have been nourishing prejudices, they give them up (assuming they have the honesty and courage to do so). But how can we become aware of our prejudices? Only by dialoguing with people of other backgrounds (other nations, other cultures, other creeds). If I isolate myself with people who think as I do and never venture to meet people with other worldviews, my gang and I will simply confirm each other in way favourite prejudices and narrow-mindedness.",
    "ImageID": "",
    "question": "Why does the writer believe that it is im possible to take an unbiased view on any matter?",
    "options": {
      "a": "Reality can be subject to perception at times, and the limit of one brain to take in all kinds of knowledge can be excruciating.",
      "b": "The pre-understanding of an indi vidual can already be polluted with many beliefs, which to the individual may appear as truths. They are just value-based judgements.",
      "c": "Giving up a native assumption about objectivity is next to impossible, giv en that a human being is a socially cohesive animal.",
      "d": "Perceptions or the lifeworld of the individual do not follow a set pat tern. Progressive awareness of its fragile nature can only make the per son understand and appreciate his surroundings."
    },
    "answer": "b",
    "explanation": "The paragraph of interest for this query is the third paragraph. Unbiased views are impossible to occur since the pre-under standing of an individual is already pol luted with lots of beliefs, which for the individual are truths, but on the contrary, they are just judgements. These judge ments are nothing more than the echo of their own beliefs. Point of reference: All these, somehow or the other, influence (if not prejudice) our perceptions. Options A, C, and D are invalid arguments presented for the impossible acceptance of an unbiased view. The limits of the hu man brain to acquire knowledge and to stay inquisitive, the cohesive nature of human beings in social aspects, and pro gressive awareness of the fragile nature of how beliefs are formed are not the true reasons why the writer believes that an unbiased view cannot be obtained on matters of concern. Option B states the fragile nature of pre-understanding, which is easily pol luted through prejudices and personal likes and dislikes. This address of pre-un derstanding makes it the right choice. 176 The final paragraph is concerned with the fragile nature of our beliefs and sup positions of the world surrounding us. The writer provides the method through which a person can ideally become aware of his flaws and prejudices. Point of reference: ‘But how can we be come aware of our prejudices? Only by dialoguing with people of other back grounds (other nations, other cultures, other creeds)’. Options A, C, and D can be rejected as the answer. The gang-like mentality of the masses that only affirm our preju dices, the view of looking at things away from the restrictions of the present time and gaining empowerment through re sponsibility are only covering the sec ondary highlights of the final paragraph. Option B is the correct alternative to se lect. The act of gaining insight through conversation and concluding with sound definitions and rationally founded be liefs is the main inference of the final paragraph.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 110,
    "passage": "  Etymologically, the word philosophy comes from two Greek words—Philos, lover (or friend), and Sophia, wisdom. Philosophy then is ‘a love of wisdom’, and the philosopher is a friend or a lover of it. Some important conclusions can already be drawn from this fact. Philosophy is not the possession of wisdom; a philosopher is NOT a proud Mr Know-It-All, who has all of the answers to everyone’s questions. He is a quester after truth, profoundly in love with Sophia, pursuing her, but never quite able to comprehend her elusive person. At most, he touches her with his fingertips, but she soon escapes his grasp. I want to see the image of lover and the beloved frequently in this text, and Sophia is a very common girls’ name in many languages. From this, we could emphasise that humanity would be the first necessary qualification of any philosopher worth his/her salt. A philosopher treks a weary, but ever so existing and adventure, way along paths less trod to an ever-receding horizon. The truth is there but is always, tantalizingly, just beyond his/ her reach. A good philosopher leads us, but one step nearer to the truth but is never so smug as to claim that we have ensured Dame Sophia once and for all in the meshes of finite human intelligence. We might even go on to add that philosophy must be a community project. There is only so much that an individual human mind can grasp. Reality is far too rich, far too complex to be stuffed into the slender limits of one individual brain, bet it that of Madame Curie or Professor Einstein. Besides, each of us approaches persons and things from our particular perspective (some have called this the ‘pre-understanding’), which comprises, among other things, our culture, our mother tongue, family upbringing, religious background (even if we think we have rejected it long age). All these, somehow or the other, influence (if not prejudice) our perceptions. It is impossible to take a natural, unbiased view of things: at best, we can try to become progressively more aware of our ‘pre-understating’ and give up a native assumption about objectivity. I am, rather, asking us to be on guard against hasty and presumptions assertions that we have come to plain, unvarnished, and objective visions of reality. Whatever, it should be quite clear that none of us deliberately and willfully admits prejudices into our perceptional make-up. People hold prejudices unconsciously, as a rule: once they become conscious that they have been nourishing prejudices, they give them up (assuming they have the honesty and courage to do so). But how can we become aware of our prejudices? Only by dialoguing with people of other backgrounds (other nations, other cultures, other creeds). If I isolate myself with people who think as I do and never venture to meet people with other worldviews, my gang and I will simply confirm each other in way favourite prejudices and narrow-mindedness.",
    "ImageID": "",
    "question": "What inference can be drawn from the final paragraph of the passage?",
    "options": {
      "a": "The people who only affirm and re-confirm our biases and prejudic es on certain matters harbour a gang mentality.",
      "b": "The act of becoming aware of our own prejudices requires self-assess ment and insight gained from inter acting and conversing with various people.",
      "c": "Isolating oneself with their views and ideas provides a view away from the here and now and more into a perspective termed ‘sub specie aeternitatis’.",
      "d": "Taking responsibility for our preju dices is the first step to gaining em powerment in life."
    },
    "answer": "b",
    "explanation": "Option B is the correct answer. A human ised way of looking at philosophers is as people who are not smug, arrogant, and boastful of their knowledge.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 111,
    "passage": " For quite some time, especially since the advent of the scientific age, philosophy has had bad press. In fact, many philosophers themselves (including the ‘father of modern philosophy, Rene Descartes (1596–1650) lamented because philosophy lacked the precision and certainty of themselves. At the turn of the last century Edmund Husserl (1859—1938) was still dreaming of a philosophy that would be an ‘exact science’, yielding unquestionable certainty based on indubitable evidence and proofs. And it does look as if philosophy is a kind of third-rate disciple, since—as we have said above—it cannot give us guaranteed ‘once and for all’ exact answers. But is this really such a blemish? Let us take a closer look at the issue. If I may borrow an insight from the contemporary French existentialist thinker, Gabriel Marcel (1889–1973), we should make a clear distinction between problems and mysteries (even though, in popular speech, we use them almost interchangeably): a problem is a question of which I am not a part, whereas a mystery is a question of which I am a part. For example, take the question, ‘What is the chemical composition of table salt?’ I am not part of that question, so it is a problem. However, the question, ‘Is there such a thing as true love?’ or ‘Is there life after death?’- are mystery questions because they concern me, personally. True love and life after death are issues with which my life is intimately bound up. Even the question, ‘Does God exist?’ or even, ‘What is God like?’ are mystery-questions—not because I am trying to say that I am part of God, but because if God exists then, I would somehow be very intimately linked with the divinity. So far, we’ve noted how problem and mystery differ from the point of view of the kind of question they ask. Let us move on to their answers. Precisely because I am not part of a problem question, I can detach myself from it, observe it objectively, submit it to experiments in the laboratory or elsewhere and, given enough time and equipment, work out a final, exhaustive, once-and-for-all answer. But I cannot do that with a mystery question; in as much as I am part of it, I cannot detach myself from it any more than I can detach myself from myself. That is why I cannot, in principle, ever work out that kind of answer for a mystery. Science is busy with problems: that is why science can attain a high level of certainty and demonstration or proof (though even scientists, nowadays, are not so cocksure about their ‘certainties). Philosophy (like theology and religion) is busy with mysteries, and that is why it can, at best, throw some more light on the complexities of the issue; no more, It should be clear, critical, and coherent. But this does not mean that philosophy (or theology, or religion) are irresponsible and whimsical subjects to be pursued by dilettantes according to their fads and fancies. Even if its responses cannot partake of that level of absolute certainty that the positive sciences (allegedly) claim, it must be orderly, painstaking, and observant as any other study. It has to be critical of its pre-suppositions and pre-understanding, submit all its reasoning to the strict canons of logic, and so on. Philosophy is not a science, but it is a systematic scientific discipline.",
    "ImageID": "",
    "question": "Which of the following is the most suit able heading for the passage?",
    "options": {
      "a": "Philosophy and religion.",
      "b": "Philosophy and science.",
      "c": "Philosophy: A systematic discipline.",
      "d": "Philosophy: The difference between problem and mystery."
    },
    "answer": "b",
    "explanation": "The apt heading is generally the alter native which can describe the crux in a nutshell. Point of reference: The entire passage. Options A, C, and D can be rejected as the answer. Philosophy is being discussed in the passage but not by making a direct comparison with religion. Philosophy, a systematic discipline, as stated in op tion C, is an incomplete assertion. It is, in fact, a systematic scientific discipline. Finally, understanding the difference be tween a problem and a mystery through philosophy is only touching the surface meaning of the paragraph. Option B is the right choice. Philosophy and science are discussed in the pas sage side by side, making this the best heading.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 112,
    "passage": " For quite some time, especially since the advent of the scientific age, philosophy has had bad press. In fact, many philosophers themselves (including the ‘father of modern philosophy, Rene Descartes (1596–1650) lamented because philosophy lacked the precision and certainty of themselves. At the turn of the last century Edmund Husserl (1859—1938) was still dreaming of a philosophy that would be an ‘exact science’, yielding unquestionable certainty based on indubitable evidence and proofs. And it does look as if philosophy is a kind of third-rate disciple, since—as we have said above—it cannot give us guaranteed ‘once and for all’ exact answers. But is this really such a blemish? Let us take a closer look at the issue. If I may borrow an insight from the contemporary French existentialist thinker, Gabriel Marcel (1889–1973), we should make a clear distinction between problems and mysteries (even though, in popular speech, we use them almost interchangeably): a problem is a question of which I am not a part, whereas a mystery is a question of which I am a part. For example, take the question, ‘What is the chemical composition of table salt?’ I am not part of that question, so it is a problem. However, the question, ‘Is there such a thing as true love?’ or ‘Is there life after death?’- are mystery questions because they concern me, personally. True love and life after death are issues with which my life is intimately bound up. Even the question, ‘Does God exist?’ or even, ‘What is God like?’ are mystery-questions—not because I am trying to say that I am part of God, but because if God exists then, I would somehow be very intimately linked with the divinity. So far, we’ve noted how problem and mystery differ from the point of view of the kind of question they ask. Let us move on to their answers. Precisely because I am not part of a problem question, I can detach myself from it, observe it objectively, submit it to experiments in the laboratory or elsewhere and, given enough time and equipment, work out a final, exhaustive, once-and-for-all answer. But I cannot do that with a mystery question; in as much as I am part of it, I cannot detach myself from it any more than I can detach myself from myself. That is why I cannot, in principle, ever work out that kind of answer for a mystery. Science is busy with problems: that is why science can attain a high level of certainty and demonstration or proof (though even scientists, nowadays, are not so cocksure about their ‘certainties). Philosophy (like theology and religion) is busy with mysteries, and that is why it can, at best, throw some more light on the complexities of the issue; no more, It should be clear, critical, and coherent. But this does not mean that philosophy (or theology, or religion) are irresponsible and whimsical subjects to be pursued by dilettantes according to their fads and fancies. Even if its responses cannot partake of that level of absolute certainty that the positive sciences (allegedly) claim, it must be orderly, painstaking, and observant as any other study. It has to be critical of its pre-suppositions and pre-understanding, submit all its reasoning to the strict canons of logic, and so on. Philosophy is not a science, but it is a systematic scientific discipline.",
    "ImageID": "",
    "question": "What is the biggest qualm that many philosophers have with philosophy?",
    "options": {
      "a": "That unquestionable certainty can not be stated in the absence of evi dence and proof.",
      "b": "Philosophy ended up as a C-grade discipline, despite its numerous con tributions to modern thinking. ",
      "c": "It cannot answer the ultimate ques tions of human life, such as ‘Does God exist?’ or ‘Does true love exist?’",
      "d": "Philosophy got popularised as the subject of delinquents who pursue it according to their fads and fancies."
    },
    "answer": "a",
    "explanation": "This query’s resolution is established in the opening first line of the passage— specifically, the first line of the first paragraph. Point of reference: Rene Descartes (1596 1650) lamented that philosophy lacked precision and certainty. Options B, C, and D are invalid options. The reduction of philosophy despite its contribution, not being able to answer major life questions, and the populari sation of philosophy as a subject of de linquents are not the biggest grievances that philosophers had with philosophy. Option A is the right choice to take. Philosophy lacks the attack of unques tionable certainty as some of its as sumptions lack evidence and proof.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 113,
    "passage": " For quite some time, especially since the advent of the scientific age, philosophy has had bad press. In fact, many philosophers themselves (including the ‘father of modern philosophy, Rene Descartes (1596–1650) lamented because philosophy lacked the precision and certainty of themselves. At the turn of the last century Edmund Husserl (1859—1938) was still dreaming of a philosophy that would be an ‘exact science’, yielding unquestionable certainty based on indubitable evidence and proofs. And it does look as if philosophy is a kind of third-rate disciple, since—as we have said above—it cannot give us guaranteed ‘once and for all’ exact answers. But is this really such a blemish? Let us take a closer look at the issue. If I may borrow an insight from the contemporary French existentialist thinker, Gabriel Marcel (1889–1973), we should make a clear distinction between problems and mysteries (even though, in popular speech, we use them almost interchangeably): a problem is a question of which I am not a part, whereas a mystery is a question of which I am a part. For example, take the question, ‘What is the chemical composition of table salt?’ I am not part of that question, so it is a problem. However, the question, ‘Is there such a thing as true love?’ or ‘Is there life after death?’- are mystery questions because they concern me, personally. True love and life after death are issues with which my life is intimately bound up. Even the question, ‘Does God exist?’ or even, ‘What is God like?’ are mystery-questions—not because I am trying to say that I am part of God, but because if God exists then, I would somehow be very intimately linked with the divinity. So far, we’ve noted how problem and mystery differ from the point of view of the kind of question they ask. Let us move on to their answers. Precisely because I am not part of a problem question, I can detach myself from it, observe it objectively, submit it to experiments in the laboratory or elsewhere and, given enough time and equipment, work out a final, exhaustive, once-and-for-all answer. But I cannot do that with a mystery question; in as much as I am part of it, I cannot detach myself from it any more than I can detach myself from myself. That is why I cannot, in principle, ever work out that kind of answer for a mystery. Science is busy with problems: that is why science can attain a high level of certainty and demonstration or proof (though even scientists, nowadays, are not so cocksure about their ‘certainties). Philosophy (like theology and religion) is busy with mysteries, and that is why it can, at best, throw some more light on the complexities of the issue; no more, It should be clear, critical, and coherent. But this does not mean that philosophy (or theology, or religion) are irresponsible and whimsical subjects to be pursued by dilettantes according to their fads and fancies. Even if its responses cannot partake of that level of absolute certainty that the positive sciences (allegedly) claim, it must be orderly, painstaking, and observant as any other study. It has to be critical of its pre-suppositions and pre-understanding, submit all its reasoning to the strict canons of logic, and so on. Philosophy is not a science, but it is a systematic scientific discipline.",
    "ImageID": "",
    "question": "What is the author’s intention behind stating examples such as ‘What is the chemical composition of salt?’",
    "options": {
      "a": "To ask the reader about the chemical composition of salt.",
      "b": "To lead to a bigger question, such as ‘Does God exist’?",
      "c": "To make the reader understand the limitations of science.",
      "d": "To make the reader comprehend the criticism that philosophy faces and the reason for it."
    },
    "answer": "d",
    "explanation": "The example of salt’s chemical compo sition can be found in the third line of the second paragraph. This example in its application mentions the difference between a problem and a mystery and addresses why philosophy, out of all dis ciplines, faces so much flak without the awareness of understanding this sub stantial difference between a problem and a mystery. Point of reference: For example, take the question, ‘What is the chemical compo sition of table salt?’ I am not part of that question, so it is a problem. However, the question, ‘Is there such a thing as true love?’ or ‘Is there life after death?’—are mystery questions because they concern me, personally. Options A, B, and C should be rejected as the answer. Asking the chemical com position, leading to bigger questions, and highlighting the limitations of science are superficial, irrelevant, and do not find a mention in the passage. Option D is the answer. It makes the reader understand the criticism of phi losophy and the kind of questions that philosophy addresses.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 114,
    "passage": " For quite some time, especially since the advent of the scientific age, philosophy has had bad press. In fact, many philosophers themselves (including the ‘father of modern philosophy, Rene Descartes (1596–1650) lamented because philosophy lacked the precision and certainty of themselves. At the turn of the last century Edmund Husserl (1859—1938) was still dreaming of a philosophy that would be an ‘exact science’, yielding unquestionable certainty based on indubitable evidence and proofs. And it does look as if philosophy is a kind of third-rate disciple, since—as we have said above—it cannot give us guaranteed ‘once and for all’ exact answers. But is this really such a blemish? Let us take a closer look at the issue. If I may borrow an insight from the contemporary French existentialist thinker, Gabriel Marcel (1889–1973), we should make a clear distinction between problems and mysteries (even though, in popular speech, we use them almost interchangeably): a problem is a question of which I am not a part, whereas a mystery is a question of which I am a part. For example, take the question, ‘What is the chemical composition of table salt?’ I am not part of that question, so it is a problem. However, the question, ‘Is there such a thing as true love?’ or ‘Is there life after death?’- are mystery questions because they concern me, personally. True love and life after death are issues with which my life is intimately bound up. Even the question, ‘Does God exist?’ or even, ‘What is God like?’ are mystery-questions—not because I am trying to say that I am part of God, but because if God exists then, I would somehow be very intimately linked with the divinity. So far, we’ve noted how problem and mystery differ from the point of view of the kind of question they ask. Let us move on to their answers. Precisely because I am not part of a problem question, I can detach myself from it, observe it objectively, submit it to experiments in the laboratory or elsewhere and, given enough time and equipment, work out a final, exhaustive, once-and-for-all answer. But I cannot do that with a mystery question; in as much as I am part of it, I cannot detach myself from it any more than I can detach myself from myself. That is why I cannot, in principle, ever work out that kind of answer for a mystery. Science is busy with problems: that is why science can attain a high level of certainty and demonstration or proof (though even scientists, nowadays, are not so cocksure about their ‘certainties). Philosophy (like theology and religion) is busy with mysteries, and that is why it can, at best, throw some more light on the complexities of the issue; no more, It should be clear, critical, and coherent. But this does not mean that philosophy (or theology, or religion) are irresponsible and whimsical subjects to be pursued by dilettantes according to their fads and fancies. Even if its responses cannot partake of that level of absolute certainty that the positive sciences (allegedly) claim, it must be orderly, painstaking, and observant as any other study. It has to be critical of its pre-suppositions and pre-understanding, submit all its reasoning to the strict canons of logic, and so on. Philosophy is not a science, but it is a systematic scientific discipline.",
    "ImageID": "",
    "question": "What do you infer from the prob lem-mystery connection that Marcel presented in the context of philosophy?",
    "options": {
      "a": "The variation of questions asked and topics dealt with in respective disciplines.",
      "b": "The questions that we are intrinsi cally a part of cannot be answered with an objective mindset.",
      "c": "Philosophy is like religion; it is busy with mysteries and can only throw some light on the issue’s complexities.",
      "d": "Philosophy is a discipline of system atic scientific study."
    },
    "answer": "a",
    "explanation": "The conclusion that can be drawn from the problem-mystery situation that Marcel discussed is to present why sci ence can give answers with the precision it is known for, and why philosophy, to a large extent, cannot give the same level of precision because it is dealing with a much heavier topic, mysteries. Point of reference: Paragraphs 2 and 3. Option A is correct. The difference in topics covered in both disciplines is the main reason for the biased and unfair criticism that philosophy faces.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 115,
    "passage": " For quite some time, especially since the advent of the scientific age, philosophy has had bad press. In fact, many philosophers themselves (including the ‘father of modern philosophy, Rene Descartes (1596–1650) lamented because philosophy lacked the precision and certainty of themselves. At the turn of the last century Edmund Husserl (1859—1938) was still dreaming of a philosophy that would be an ‘exact science’, yielding unquestionable certainty based on indubitable evidence and proofs. And it does look as if philosophy is a kind of third-rate disciple, since—as we have said above—it cannot give us guaranteed ‘once and for all’ exact answers. But is this really such a blemish? Let us take a closer look at the issue. If I may borrow an insight from the contemporary French existentialist thinker, Gabriel Marcel (1889–1973), we should make a clear distinction between problems and mysteries (even though, in popular speech, we use them almost interchangeably): a problem is a question of which I am not a part, whereas a mystery is a question of which I am a part. For example, take the question, ‘What is the chemical composition of table salt?’ I am not part of that question, so it is a problem. However, the question, ‘Is there such a thing as true love?’ or ‘Is there life after death?’- are mystery questions because they concern me, personally. True love and life after death are issues with which my life is intimately bound up. Even the question, ‘Does God exist?’ or even, ‘What is God like?’ are mystery-questions—not because I am trying to say that I am part of God, but because if God exists then, I would somehow be very intimately linked with the divinity. So far, we’ve noted how problem and mystery differ from the point of view of the kind of question they ask. Let us move on to their answers. Precisely because I am not part of a problem question, I can detach myself from it, observe it objectively, submit it to experiments in the laboratory or elsewhere and, given enough time and equipment, work out a final, exhaustive, once-and-for-all answer. But I cannot do that with a mystery question; in as much as I am part of it, I cannot detach myself from it any more than I can detach myself from myself. That is why I cannot, in principle, ever work out that kind of answer for a mystery. Science is busy with problems: that is why science can attain a high level of certainty and demonstration or proof (though even scientists, nowadays, are not so cocksure about their ‘certainties). Philosophy (like theology and religion) is busy with mysteries, and that is why it can, at best, throw some more light on the complexities of the issue; no more, It should be clear, critical, and coherent. But this does not mean that philosophy (or theology, or religion) are irresponsible and whimsical subjects to be pursued by dilettantes according to their fads and fancies. Even if its responses cannot partake of that level of absolute certainty that the positive sciences (allegedly) claim, it must be orderly, painstaking, and observant as any other study. It has to be critical of its pre-suppositions and pre-understanding, submit all its reasoning to the strict canons of logic, and so on. Philosophy is not a science, but it is a systematic scientific discipline.",
    "ImageID": "",
    "question": "Why does the writer conclude that philosophy is a systematic scientific discipline?",
    "options": {
      "a": "Like any other discipline, philoso phy is limited in its application and meaning.",
      "b": "It takes one step beyond covering the phenomena of life that science cannot.",
      "c": "Compared to science, philosophy is critical of its pre-suppositions, thus making it painstaking.",
      "d": "The writer, by intention, is wary of science and to praise Philosophy de clares it as a systematic scientific discipline."
    },
    "answer": "c",
    "explanation": "The query finds the solution in the last paragraph. The final paragraph makes it evident why philosophy is a systemat ic scientific discipline. The level of cer tainty that other positive sciences claim,  although missing from philosophy, takes the painstaking effort of being intro duced and well versed with the basics of the subject. Unlike science, the pre-sup positions of philosophy can always be questioned. The strict subjection of every fundamental to logic makes it a scientif ic, systematic discipline. Point of reference: The entirety of the fi nal paragraph. Option C is the right choice. The constant placement of its ‘established’ pre-sup positions in the witness box under con tinuous criticism is why Philosophy is a systematic scientific discipline.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 116,
    "passage": "  Plato (429–347 BCE) is one of the most dazzling thinkers in the Western philosophical tradition and one of the most penetrating, wide-ranging, and influential authors in the history of philosophy. An Athenian citizen of high status, he displays his absorption in the political events and intellectual movements of his time in his works. The questions he raises are profound. The strategies he uses for solving them are suggestive and provocative that fascinated educated readers of nearly every period. Most Western philosophers have in some way been influenced by him, and in practically every age, there have been philosophers who regard themselves as Platonists. He was not the first thinker or writer to whom the word ‘philosopher’ should be applied. Plato was so self-conscious about how philosophy should contribute and what its scope and ambitions properly are. He transformed the intellectual currents of his and modern times in the way he grappled, with the subject of philosophy as a rigorous and systematic examination of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method that can be called his invention. Plato (speaking on behalf of Socrates) divided human beings based on their innate intelligence, strength, and courage. Those who are not overly bright, or strong, or brave are suited to various productive professions: farming, smithing, building, and so on. Those who are somewhat bright, strong, and incredibly courageous are suited to defensive and policing professions. Those who are extraordinarily intelligent, virtuous, and brave are suited to run the state itself; that is, Plato’s ideal state is an aristocracy, a Greek word which means ‘rule by the best’. The lower end of human society, which, as far as Plato is concerned, consists of an overwhelming majority of people in a state, he calls the ‘producers’, since they are most suited for productive work. The middle section of society, a smaller but still large number of people, make up the army and the police and are called ‘Auxiliaries’. The best and the brightest, a very small and rarefied group, are in complete control of their virtue and can act as the role model for society. Plato called these people ‘Guardians’. In the ideal state, ‘courage’ characterises the Auxiliaries; ‘wisdom’ displays itself in the Guardians’ lives and government. A state may have ‘temperance’ if the Auxiliaries obey the Guardians and the Producers obey the Auxiliaries and Guardians in all things. A state may be intemperate if any of the lower groups do not obey one of the higher groups. A state may be said to be just if the Auxiliaries do not simply obey the Guardians, but enjoy doing so, that is, they do not grumble about the authority being exercised over them; a just state would require that the Producers not only obey the Auxiliaries and Guardians but that they do so willingly. When the analogy is extended to the individual human being, Plato identifies the intellect as Guardians, the spirit or emotions with the Auxiliaries, and the bodily appetites with the Producers, something like the caste system in India. Therefore, an individual is courageous if his or her spirit is courageous, and an individual is wise if his or her intellect is wise. Temperance occurs when the emotions are ruled over by the intellect, and the emotions and especially the intellect rule over the bodily appetites. An individual may be said to be just when the bodily appetites and emotions are not only ruled over by the intellect but do so willingly and without coercion.",
    "ImageID": "",
    "question": "Why is Plato regarded by many as the most critical thinker of Western Philosophy?",
    "options": {
      "a": "Plato had the most dazzling and sparkling ideas that the world had ever seen. ",
      "b": "Plato’s insight on various topics and themes has influenced many gener ations of thinkers.",
      "c": "His absorption of matters of social and political nature made him the f irst-ever utopian thinker.",
      "d": "He was critical and quite receptive to the affairs of the society and simul taneously of philosophy itself."
    },
    "answer": "b",
    "explanation": "One of the key reasons why Plato is re garded by many as one of the significant thinkers of Western philosophy is the numerous contributions made by him to western philosophy in general—going as far as influencing the many next gener ations of thinkers to be considered as Platonists. Point of reference: Second last line, first paragraph. ‘The strategies he uses for solving them are suggestive and provocative that ed ucated readers of nearly every period. Most of the Western philosophers have in some way been influenced by him, and in practically every age, there have been philosophers who regard themselves Platonists’. Options A, C, and D are incomplete rea sons for the accolades Plato receives. Plato’s dazzling ideas, the absorption of political and social natured concerns, and his critical perception of philosophy are merely the secondary highlights for Plato being considered one of the most significant thinkers in human history. Option B is the exact reason. Plato’s in sight on various topics, covering numer ous matters of interest, almost made him an all-rounder of a thinker so much so as to influence many generations of thinkers after him.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 117,
    "passage": "  Plato (429–347 BCE) is one of the most dazzling thinkers in the Western philosophical tradition and one of the most penetrating, wide-ranging, and influential authors in the history of philosophy. An Athenian citizen of high status, he displays his absorption in the political events and intellectual movements of his time in his works. The questions he raises are profound. The strategies he uses for solving them are suggestive and provocative that fascinated educated readers of nearly every period. Most Western philosophers have in some way been influenced by him, and in practically every age, there have been philosophers who regard themselves as Platonists. He was not the first thinker or writer to whom the word ‘philosopher’ should be applied. Plato was so self-conscious about how philosophy should contribute and what its scope and ambitions properly are. He transformed the intellectual currents of his and modern times in the way he grappled, with the subject of philosophy as a rigorous and systematic examination of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method that can be called his invention. Plato (speaking on behalf of Socrates) divided human beings based on their innate intelligence, strength, and courage. Those who are not overly bright, or strong, or brave are suited to various productive professions: farming, smithing, building, and so on. Those who are somewhat bright, strong, and incredibly courageous are suited to defensive and policing professions. Those who are extraordinarily intelligent, virtuous, and brave are suited to run the state itself; that is, Plato’s ideal state is an aristocracy, a Greek word which means ‘rule by the best’. The lower end of human society, which, as far as Plato is concerned, consists of an overwhelming majority of people in a state, he calls the ‘producers’, since they are most suited for productive work. The middle section of society, a smaller but still large number of people, make up the army and the police and are called ‘Auxiliaries’. The best and the brightest, a very small and rarefied group, are in complete control of their virtue and can act as the role model for society. Plato called these people ‘Guardians’. In the ideal state, ‘courage’ characterises the Auxiliaries; ‘wisdom’ displays itself in the Guardians’ lives and government. A state may have ‘temperance’ if the Auxiliaries obey the Guardians and the Producers obey the Auxiliaries and Guardians in all things. A state may be intemperate if any of the lower groups do not obey one of the higher groups. A state may be said to be just if the Auxiliaries do not simply obey the Guardians, but enjoy doing so, that is, they do not grumble about the authority being exercised over them; a just state would require that the Producers not only obey the Auxiliaries and Guardians but that they do so willingly. When the analogy is extended to the individual human being, Plato identifies the intellect as Guardians, the spirit or emotions with the Auxiliaries, and the bodily appetites with the Producers, something like the caste system in India. Therefore, an individual is courageous if his or her spirit is courageous, and an individual is wise if his or her intellect is wise. Temperance occurs when the emotions are ruled over by the intellect, and the emotions and especially the intellect rule over the bodily appetites. An individual may be said to be just when the bodily appetites and emotions are not only ruled over by the intellect but do so willingly and without coercion.",
    "ImageID": "",
    "question": "Why does modern philosophy owe a lot to the words of Socrates and the writ ings of Plato?",
    "options": {
      "a": "His absorption of the time’s politi cal events, which are still a matter of concern in modern times.",
      "b": "Philosophers of modern generations were inspired by Plato and rightly could be declared as Platonists.",
      "c": "The consideration of philosophy as a subject that holds critical exami nation and sceptic by the method of ethics, politics, and metaphysics can contribute to Plato’s work.",
      "d": "The suggestive and provocative methods of Plato find relevance and resonance in the post-modern era."
    },
    "answer": "c",
    "explanation": "The influence Plato had on the intellec tual environment of his time in ancient Greece and simultaneously on the mod ern thinkers is quite evident. The chal lenging subject matters such as ethics, politics, metaphysics, and epistemology are all now accessible due to their sys tematic arrangement by Plato. Point of reference: Second line, second paragraph. ‘He transformed the intellectual currents of his and modern times, in the way he grappled, with the subject of philosophy as a rigorous and systematic examina tion of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method that can be called his invention’. Options A, B, and D are incomplete con siderations. Plato’s absorption of politi cal events, which are still to this day, of grave concern, the similarities observed in the work of modern thinkers inspired by Plato in gargantuan amounts, and the provocative methods of Plato, are not sufficient alternatives to justify the significance of Plato in modern western philosophy. Option C, on the other hand, is the ac curate alternative. The sceptic view of delving into challenging topics such as ethics, and establishing a systematic nomenclature in the process, is entirely due to Plato.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 118,
    "passage": "  Plato (429–347 BCE) is one of the most dazzling thinkers in the Western philosophical tradition and one of the most penetrating, wide-ranging, and influential authors in the history of philosophy. An Athenian citizen of high status, he displays his absorption in the political events and intellectual movements of his time in his works. The questions he raises are profound. The strategies he uses for solving them are suggestive and provocative that fascinated educated readers of nearly every period. Most Western philosophers have in some way been influenced by him, and in practically every age, there have been philosophers who regard themselves as Platonists. He was not the first thinker or writer to whom the word ‘philosopher’ should be applied. Plato was so self-conscious about how philosophy should contribute and what its scope and ambitions properly are. He transformed the intellectual currents of his and modern times in the way he grappled, with the subject of philosophy as a rigorous and systematic examination of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method that can be called his invention. Plato (speaking on behalf of Socrates) divided human beings based on their innate intelligence, strength, and courage. Those who are not overly bright, or strong, or brave are suited to various productive professions: farming, smithing, building, and so on. Those who are somewhat bright, strong, and incredibly courageous are suited to defensive and policing professions. Those who are extraordinarily intelligent, virtuous, and brave are suited to run the state itself; that is, Plato’s ideal state is an aristocracy, a Greek word which means ‘rule by the best’. The lower end of human society, which, as far as Plato is concerned, consists of an overwhelming majority of people in a state, he calls the ‘producers’, since they are most suited for productive work. The middle section of society, a smaller but still large number of people, make up the army and the police and are called ‘Auxiliaries’. The best and the brightest, a very small and rarefied group, are in complete control of their virtue and can act as the role model for society. Plato called these people ‘Guardians’. In the ideal state, ‘courage’ characterises the Auxiliaries; ‘wisdom’ displays itself in the Guardians’ lives and government. A state may have ‘temperance’ if the Auxiliaries obey the Guardians and the Producers obey the Auxiliaries and Guardians in all things. A state may be intemperate if any of the lower groups do not obey one of the higher groups. A state may be said to be just if the Auxiliaries do not simply obey the Guardians, but enjoy doing so, that is, they do not grumble about the authority being exercised over them; a just state would require that the Producers not only obey the Auxiliaries and Guardians but that they do so willingly. When the analogy is extended to the individual human being, Plato identifies the intellect as Guardians, the spirit or emotions with the Auxiliaries, and the bodily appetites with the Producers, something like the caste system in India. Therefore, an individual is courageous if his or her spirit is courageous, and an individual is wise if his or her intellect is wise. Temperance occurs when the emotions are ruled over by the intellect, and the emotions and especially the intellect rule over the bodily appetites. An individual may be said to be just when the bodily appetites and emotions are not only ruled over by the intellect but do so willingly and without coercion.",
    "ImageID": "",
    "question": "“It will never be right in the king dom”, Plato said, “Until kings become Philosophers, and Philosophers become kings”. With this quote from Plato in mind, which sect would be the most fit ting to rule the kingdom?",
    "options": {
      "a": "Aristocrats (best rulers)",
      "b": "Producers",
      "c": "Auxiliaries",
      "d": "Guardians"
    },
    "answer": "d",
    "explanation": "As per the insight of Plato, the befitting ruler of the kingdom would belong to the Guardians sect. The hint of Guardians being fitting enough to rule the kingdom is observed in the third paragraph’s final line. Point of reference: Final second line, third paragraph. The best and the brightest, a very small and rarefied group, are those who are in complete control of their virtue and can act as the role model for the society. Plato called these people Guardians. Options A, B, and C are not good enough to rule society. The aristocrats are not a sect, but a wordy meaning that states’ best rule’ in Latin, the producers are not brave or wise enough to fit this role, and the auxiliaries are modestly wise and  brave to be the heart and soul of the so ciety, but not the brain. Option D is the sect that is the proper candidate for this role. In Plato’s view, these are wise men. The best and bright est who can act as role models for the other sects of the society and are more f itting to rule the kingdom.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 119,
    "passage": "  Plato (429–347 BCE) is one of the most dazzling thinkers in the Western philosophical tradition and one of the most penetrating, wide-ranging, and influential authors in the history of philosophy. An Athenian citizen of high status, he displays his absorption in the political events and intellectual movements of his time in his works. The questions he raises are profound. The strategies he uses for solving them are suggestive and provocative that fascinated educated readers of nearly every period. Most Western philosophers have in some way been influenced by him, and in practically every age, there have been philosophers who regard themselves as Platonists. He was not the first thinker or writer to whom the word ‘philosopher’ should be applied. Plato was so self-conscious about how philosophy should contribute and what its scope and ambitions properly are. He transformed the intellectual currents of his and modern times in the way he grappled, with the subject of philosophy as a rigorous and systematic examination of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method that can be called his invention. Plato (speaking on behalf of Socrates) divided human beings based on their innate intelligence, strength, and courage. Those who are not overly bright, or strong, or brave are suited to various productive professions: farming, smithing, building, and so on. Those who are somewhat bright, strong, and incredibly courageous are suited to defensive and policing professions. Those who are extraordinarily intelligent, virtuous, and brave are suited to run the state itself; that is, Plato’s ideal state is an aristocracy, a Greek word which means ‘rule by the best’. The lower end of human society, which, as far as Plato is concerned, consists of an overwhelming majority of people in a state, he calls the ‘producers’, since they are most suited for productive work. The middle section of society, a smaller but still large number of people, make up the army and the police and are called ‘Auxiliaries’. The best and the brightest, a very small and rarefied group, are in complete control of their virtue and can act as the role model for society. Plato called these people ‘Guardians’. In the ideal state, ‘courage’ characterises the Auxiliaries; ‘wisdom’ displays itself in the Guardians’ lives and government. A state may have ‘temperance’ if the Auxiliaries obey the Guardians and the Producers obey the Auxiliaries and Guardians in all things. A state may be intemperate if any of the lower groups do not obey one of the higher groups. A state may be said to be just if the Auxiliaries do not simply obey the Guardians, but enjoy doing so, that is, they do not grumble about the authority being exercised over them; a just state would require that the Producers not only obey the Auxiliaries and Guardians but that they do so willingly. When the analogy is extended to the individual human being, Plato identifies the intellect as Guardians, the spirit or emotions with the Auxiliaries, and the bodily appetites with the Producers, something like the caste system in India. Therefore, an individual is courageous if his or her spirit is courageous, and an individual is wise if his or her intellect is wise. Temperance occurs when the emotions are ruled over by the intellect, and the emotions and especially the intellect rule over the bodily appetites. An individual may be said to be just when the bodily appetites and emotions are not only ruled over by the intellect but do so willingly and without coercion.",
    "ImageID": "",
    "question": "What is the striking similarity one can infer between Plato’s hierarchy of the re public and the Indian society?",
    "options": {
      "a": "The mechanics of the republic are akin to a human body.",
      "b": "The Wisemen and the just ruling the kingdom and providing guidance to their subjects.",
      "c": "The division of the society into mul tiple sects or castes based on their nature and subsequent assigning of roles in the society.",
      "d": "The aristocratic rule lets people ex plore many sides of their life not based on their nature but instead on their birth right."
    },
    "answer": "c",
    "explanation": "A similarity in the society that the read er can infer in Plato’s work is his classi f ication of various sects based on their nature, or in other words, the degree of their virtue and values. This finds reso nance with the caste system, which had the same purpose behind its inception. Point of reference: First line, final paragraph. ‘When the analogy is extended to the in dividual human being, Plato identifies the intellect with the Guardians, the spir it or emotions with the Auxiliaries, and the bodily appetites with the Producers, something like the caste system in India’. Options A, B, and D are not the similari ties between Ancient Greece and Indian society. The structure of the society being like a human being, the rule of the king dom by wise men, and the aristocratic rule letting people explore multiple fac ets of their life are not the parallels one can observe between the two. Option C is the correct answer. The very idea that society’s proper functioning re lies on the efficient categorisation of its habitants can be stated as one of the sa lient features of Indian society.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  },
  {
    "id": 120,
    "passage": "  Plato (429–347 BCE) is one of the most dazzling thinkers in the Western philosophical tradition and one of the most penetrating, wide-ranging, and influential authors in the history of philosophy. An Athenian citizen of high status, he displays his absorption in the political events and intellectual movements of his time in his works. The questions he raises are profound. The strategies he uses for solving them are suggestive and provocative that fascinated educated readers of nearly every period. Most Western philosophers have in some way been influenced by him, and in practically every age, there have been philosophers who regard themselves as Platonists. He was not the first thinker or writer to whom the word ‘philosopher’ should be applied. Plato was so self-conscious about how philosophy should contribute and what its scope and ambitions properly are. He transformed the intellectual currents of his and modern times in the way he grappled, with the subject of philosophy as a rigorous and systematic examination of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method that can be called his invention. Plato (speaking on behalf of Socrates) divided human beings based on their innate intelligence, strength, and courage. Those who are not overly bright, or strong, or brave are suited to various productive professions: farming, smithing, building, and so on. Those who are somewhat bright, strong, and incredibly courageous are suited to defensive and policing professions. Those who are extraordinarily intelligent, virtuous, and brave are suited to run the state itself; that is, Plato’s ideal state is an aristocracy, a Greek word which means ‘rule by the best’. The lower end of human society, which, as far as Plato is concerned, consists of an overwhelming majority of people in a state, he calls the ‘producers’, since they are most suited for productive work. The middle section of society, a smaller but still large number of people, make up the army and the police and are called ‘Auxiliaries’. The best and the brightest, a very small and rarefied group, are in complete control of their virtue and can act as the role model for society. Plato called these people ‘Guardians’. In the ideal state, ‘courage’ characterises the Auxiliaries; ‘wisdom’ displays itself in the Guardians’ lives and government. A state may have ‘temperance’ if the Auxiliaries obey the Guardians and the Producers obey the Auxiliaries and Guardians in all things. A state may be intemperate if any of the lower groups do not obey one of the higher groups. A state may be said to be just if the Auxiliaries do not simply obey the Guardians, but enjoy doing so, that is, they do not grumble about the authority being exercised over them; a just state would require that the Producers not only obey the Auxiliaries and Guardians but that they do so willingly. When the analogy is extended to the individual human being, Plato identifies the intellect as Guardians, the spirit or emotions with the Auxiliaries, and the bodily appetites with the Producers, something like the caste system in India. Therefore, an individual is courageous if his or her spirit is courageous, and an individual is wise if his or her intellect is wise. Temperance occurs when the emotions are ruled over by the intellect, and the emotions and especially the intellect rule over the bodily appetites. An individual may be said to be just when the bodily appetites and emotions are not only ruled over by the intellect but do so willingly and without coercion.",
    "ImageID": "",
    "question": "If arranged in a mathematical equation, what would be the premier arrangement of rule in the format of 1 + 2 + 3 = ? (Here 1 is the upper sect and 3 is the lower sect.)",
    "options": {
      "a": "Aristocrats + Producers + Guardians= Democracy",
      "b": "Auxiliaries + Producers + Democrats= Demagoguery",
      "c": "Guardians + Auxiliaries + Producers = Aristocracy",
      "d": "Guardians + Aristocrats + Auxiliaries = Republic"
    },
    "answer": "c",
    "explanation": "According to Plato, the ideal or premium arrangement of society would involve the three sects in a structure, which would place Guardians in the upper echelon, the auxiliaries in the middle, and the producers in the lower position. Such a rule, when placed in this order, would make way for Aristocracy. The hint of such an arrangement can be detected in the fourth paragraph. Point of reference: Second line, fourth paragraph. Options A, B, and D are not the correct formations of the variables. Aristocrats are not supposed to rule over the other sects of the society; The discussion of demagoguery does not find any footing in the passage. The auxiliaries at the lower position are the wrong combinations and utilisation of the society’s multiple sects. Option C is the correct equation. The es tablishment of the Aristocrat rule and proper positioning of the three sects of society make this the accurate answer.",
    "topic": "Reading Comprehension ",
    "section": "VARC"
  }











  



  
]